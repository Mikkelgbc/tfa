[["index.html", "Tools for Analytics (TFA) Course notes Module 1 Introduction to the book 1.1 Learning outcomes 1.2 Purpose for the book 1.3 R vs Excel/VBA 1.4 How a computer works 1.5 How this book is organized 1.6 Acknowledgements", " Tools for Analytics (TFA) Course notes Lars Relund Nielsen 2021-08-13 Module 1 Introduction to the book This site/book contains course notes for the course “Tools for Analytics” held at Aarhus BSS. The book show the learning path for each week and contain. The course is an introductory course at the Operations and Supply Chain Analytics programme and intended to give knowledge about IT tools for Analytics. You can expect the book to be updated when the course runs. The date listed above is the last time the book was updated. Learning path diagram Click/hover the nodes to follow links and see details. 1.1 Learning outcomes By the end of this module, you are expected to: Memorize the purpose of the book. Describe what the term Business Analytics mean. Identify pros and cons of using Excel, VBA and R. Describe how a computer works. Describe what an algorithm is. Know how the book is organized. The learning outcomes relate to the overall learning goals number 1, 3 and 5 of the course. 1.2 Purpose for the book Since the amount of available data has increased extensively in many companies, there is a need for analysts with the ability to do tasks within Analytics. For instance, extract relevant data and perform valid quantitative analysis. Clearly, it is also important that the analyst can communicate the results of the analysis to their surroundings. This requires for the analyst to be particularly qualified in handling IT based tools beyond e.g. basic Excel. Business Analytics (BA) (or just Analytics) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem and the creation of business value by integration of concepts, methods and data. As a process, it can be characterized by descriptive, predictive, and prescriptive model building using data sources. For a full definition see the appendix. Within a Business Analytics (BA) framework the course focuses on giving you an introduction to programming, handeling data and doing descriptive analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (key performance indicators (KPIs), what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive and prescriptive analytics are covered in other courses of the programme. Analytics may be seen as a data driven process: Figure 1.1: Analytics as a data driven process. For doing data driven analytics you first must import your data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. In brief, when your data is tidy, each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (e.g. the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The next step is to do a simple exploration of you data such as calculating a set of summary statistics (like counts, means or KPIs). A good way to get an overview over your data is by visualization. A good visualisation will show you things that you did not expect, raise new questions about the data or confirm your hypothesis. A good visualization might also hint that you’re asking the wrong question, or you need to collect different data. Exploration and visualization are descriptive analytics and used to answer questions such as: What happened? How many, how often, where? Where exactly is the problem? What actions are needed? Models are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. A model is a description of a system using mathematical concepts and a simplification of the real system. That is, the results of a model are based on a set of assumptions. Models for statistical analysis, forecasting, system behavior are predictive analytics and answer questions like: Why is this happening? What if these trends continue? What will happen next? Models for prescriptive analytics use optimization and other decision modeling techniques to suggest decision options with the goal of improving business performance and answer questions like: What is the best that can happen? Exploration, visualization and modeling may be seen as different steps which can be used for analyzing the data and answer the overall questions. This course will focus on the two first steps. Given an analysis, communication is an absolutely critical part. It does not matter how well your models and visualization have led you to understand the data unless you can also communicate your results to decision makers. Note that analytics is not a one-way process, it is common that you several times have to tidy and transform your data, explore and visualize based on the results of a model, rerun the model based on feedback from the decision makers etc. Common connections are visualized using directed arrows in Figure 1.1. Surrounding the process is programming. Programming is the Swiss army knife you use during parts of the process. An introduction to programming is given using both VBA in Excel and the programming language and free software environment R. Programming focus on writing algorithms. An algorithm is a finite sequence of well-defined instructions to solve a specific problem or to perform a computation. That is, we use a programming language to program an algorithm that solves a specific task, e.g. find the best route, sort words, make a plot, etc. 1.3 R vs Excel/VBA This course gives you an introduction to programming using both VBA and R. The two programming languages are different and here are some comparisons: Excel Pros: Initial learning curve is quite minimal. Analysis can be done via point-and-click. Useful for fast analysis (you can change a cell and see effects on other cells, plots etc.) It is not exceedingly hard to make basic graphs and charts. Data can be stored inside the sheets. Cons: The mixture of data entries, analysis, and visualization makes it easy to confuse cells that contain raw data from those that are the product of analysis. The analysis directly manipulates the only copy of the raw data. Using mouse clicks means that a mistaken click or drag action can lead to errors or the overwriting of data. Do not handle non-tabular data well. VBA VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. Pros: Can be used inside MS Office applications e.g. Excel. Already contained in Excel, i.e. if you have Excel installed you can start coding. The VBA code is stored within the spreadsheet, allowing any user with access to the spreadsheet to easily run the code. VBA is easy to learn. Especially if you are already experienced in Excel. Good for automating tasks in Excel. Still used in many companies. Cons: A programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Since a compiled language, compiling code may take time. Powerful inside Excel but other programming languages are better to learn for general tasks. An old programming language (Microsoft stopped investing in VBA in 2008). R R is an interpreted language with step-by-step execution of source code (no pre-runtime translation takes place) from the command line or using a script file. Pros: There is a clear division between data entry and analysis. You import the data, create an object that is a copy of the raw data and do manipulations on this copy. That is, the original data are never altered in any way and there is no way to mess up the raw data. Manipulating a copy of the data enables you to experiment. A line of code that fails to produce the expected result can be tweaked and rerun. All manipulations can be done in code. The process of analysis are easily reproduced by the code. That is, the use of code for data analysis enables the creation of more reproducible research. With code all analysis is documented instead of being hidden behind mouse clicks. Saving analysis in code has the immediate benefit that it can be easily rerun anytime that new data is added or the code can also be applied to a completely new data set. Free and with a large community that promotes sharing of libraries for data analysis. Can produce complex and advanced data visualizations. Cons: R is a programming language, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. 1.4 How a computer works As a prerequisite for this course you need some basic knowledge about what a computer is. Have a look at these slides or this video. 1.5 How this book is organized Module 1 (this module) gives a short introduction to the book. Next, the book consists of different parts each containing teaching modules about specific topics: Part I Gives you an introduction to VBA and how to program it in Excel. Old: Part I focuses on helping you install the needed programs on your computer (Module 9) and gives you a short introduction to R (Module 10). Part II gives you an overview over programming in R including loops and conditionals (Module 11) and functions (Module 12). Part III the focus is on import/export, tidy and transformation of data. Module 13 first gives you an introduction to the tidyverse packages and introduces you to literal programming using R Markdown. Next, Module 14 shows you how to export and import data. Finally, Module 15 focuses on transformation of data. Part IV considers visualization of data in R (Module 16). Part V presents your mandatory R project. Part VI contains extra modules not part of the curriculum in this course. But it may be useful during your study. The appendix contains different modules that may be helpful for you including hints on how to work in groups, how to get help if you are stuck and how to annotate the course notes. 1.6 Acknowledgements Some of the materials in this book are taken from various places The bookdown skeleton and some notes are based on the Stat545 course. Some parts in Module 1 are inspired by Chapter 1 in H. Wickham (2017). The VBA modules are inspired by the book Wøhlk (2010). This holds also the some of the exercises. Module 9 is inspired by Chapter 1 in Bryan (2017). Module 10 is using some text and images from Chapter 1 in Ismay and Kim (2020) and Chapter 2 in Bryan (2017). A few exercises are inspired by Chapter 2 in Irizarry (2020). Notes about git and GitHub in the appendix are based on Bryan, STAT 545 TAs, and Hester (2020). Exercise 15.6.1 is a revision of Chapters 6-7 in Bryan (2017). Exercise 15.6.2 is a revision of Session 3 in the Welcome to the tidyverse course. Exercise 16.7.1 is a revision of Chapter 9 in Irizarry (2020). Exercise 16.7.3 is inspired by the COVID19 application exercise at the data science in a box course. Exercise 16.7.4 is inspired by the Lego homework exercise at the data science in a box course. Exercise 15.6.4 is inspired by the Fisheries application exercise at the data science in a box course. I would like to thank all for their inspiration. Also thanks to Solveig for proofreading the draft. This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC BY-NC-SA 4.0. References "],["sec-vba-intro.html", "Module 2 An introduction to VBA 2.1 Learning outcomes 2.2 What is VBA 2.3 Your first program 2.4 The macro recorder 2.5 A short overview 2.6 Recap 2.7 Exercises", " Module 2 An introduction to VBA This module gives a short introduction to VBA. In general syllabus will point to chapters in Wøhlk (2010); however, there is a lot for videos about VBA online such as courses 30 for 30 Excel VBA Absolute Beginner Course and 14-Hour VBA Course - WATCH THESE VIDEOS TO LEARN VBA!. You may have a look at these videos instead if you prefer a different learning style. In the learning path diagram links to alternative online content will be pointed out. Note this is alternatives to the standard learning path that you may use instead. The learning path may also have extra content that is not a part of syllabus you can have a look at. Since Excel change as new versions arrive and it work on different operating systems, the look in the screenshots and videos might be a bit different from your version. However, you still should be able to understand it. Learning path diagram Click/hover the nodes to follow links and see details. 2.1 Learning outcomes By the end of this module, you are expected to: Describe what VBA is. Setup Excel for VBA. Know how the macro recorder works. Made your first program. The learning outcomes relate to the overall learning goals number 2 and 4 of the course. 2.2 What is VBA Visual Basic for Applications (VBA) is an implementation of the BASIC programming language intended to control and automate Microsoft Office applications, developed by Microsoft. For instance, you can automatically create sheets, delete objects, create user-defined functions or read/write data to a sheet. It is not a standalone program, it can only run in the host application. In this course we will focus on running VBA from Excel. VBA is widely used in the industry (specially linked to Excel) and easy to learn. Microsoft stopped investing in VBA in 2008. It only update it for small changes. However, VBA is still a vital part of desktop Office applications, and will continue to be so in the future. VBA is a compiled language implemented using compilers (translators that generate machine code from source code). That is, code need to be compiled first before running it. You can only run VBA using the desktop version of Excel. That is, you can’t create, run, or edit VBA in Excel for the web. With VBA you can extend Excel and automate tasks by coding different algorithms that for instance can be run by pressing a button. Since VBA is a programming language, the initial learning curve is steeper compared to Excel. However, you will get started fast because you already know Excel. 2.3 Your first program We will use the book VBA Programming in Business Economics by Wøhlk (2010). Read Chapter 1 in Wøhlk (2010). You may also have a look at the alternative videos instead as listed in the learning path diagram (select only one of the video paths). 2.4 The macro recorder It is possible to use the Macro recorder to turn your actions in Excel into VBA code. This can be particularly useful if you have forgotten the code for a specific color or the name of a function. Unfortunately, you cannot record if-statements or loops, so the recorder is not an easy way out of learning to code. But it is a handy tool. Read Chapter 2 in Wøhlk (2010). You may also have a look at the alternative videos instead as listed in the learning path diagram (select only one of the video paths). 2.5 A short overview Read Chapter 3 in Wøhlk (2010) which gives a short overview over VBA so you can get started coding. 2.6 Recap To do 2.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 2.7.1 Exercise - Hello Based on Chapter 1 in Wøhlk (2010), create your own “Hello World” macro. Create a new procedure Public Sub MyHello() Dim name as String Name = InputBox(&quot;Type your name:&quot;) MsgBox(&quot;Hello &quot; &amp; Name) End Sub Run it using a button and using the shortcut F5. 2.7.2 Exercise - Record a macro Do the following steps: Type My name is: in cell A1. Type you name in cell B1 and activate it (click on it). Start the macro recorder and call the macro ChangeLayout. Change the color to blue and font size to 14. Stop the macro recorder. Activate cell A1 and run the macro. Open the VBA editor and inspect the macro. Cleanup the macro so only stuff about color and size are maintained. Add a button to run the macro. Add numbers to cells A3:D3, select the cells and run the macro. Modify the macro in the editor so the font size is 10 and test it. 2.7.3 Exercise - User input Write a procedure (sub) CheckNumber that: Ask for a number using an input box. Make a message box telling if the number is above 10. Write the number to cell a cell. Remember to save the file as a macro-enabled workbook (xlsm). 2.7.4 Exercise - Max and min number The file contains a procedure to generate 40 random numbers. × Hint Sub FindMax() Dim m As Integer m = 0 For r = 1 To 40 If Cells(r, 1) ___ m Then m = ___ End If Next Range(&quot;D1&quot;) = ___ End Sub Close Hint Create a procedure that finds the maximum number and write it to cell D1. Assign the procedure to button Find max. Create a procedure that finds the minimum number and write it to cell D2. Assign the procedure to button Find min. Create a procedure that finds the number range and write it to cell D3. Assign the procedure to button Find range. Given two numbers m1 and m2, you can concatenate them to a string using &amp; e.g. \"[\" &amp; m1 &amp; \",\" &amp; m2 &amp; \"]\". Create a procedure that count the number of positives and write it to cell D4. Assign the procedure to button Count positives. It may often be nice to know the row number of the minimum and maximum values. Create a procedure that finds the maximum row number and write it to cell D5. Assign the procedure to button Find max row. Create a procedure that finds the minimum row number and write it to cell D6. Assign the procedure to button Find min row. The procedure RunAll which is already linked to button Run All, runs all the procedures. Have a look at the code and try it out. References "],["data-types-varables.html", "Module 3 Data types - Varables 3.1 Learning outcomes", " Module 3 Data types - Varables 3.1 Learning outcomes By the end of this module, you are expected to have: "],["procedures-and-functions.html", "Module 4 Procedures and functions 4.1 Learning outcomes", " Module 4 Procedures and functions 4.1 Learning outcomes By the end of this module, you are expected to have: "],["loops-and-conditionals.html", "Module 5 Loops and conditionals 5.1 Learning outcomes", " Module 5 Loops and conditionals 5.1 Learning outcomes By the end of this module, you are expected to have: "],["object-model.html", "Module 6 Object model 6.1 Learning outcomes", " Module 6 Object model 6.1 Learning outcomes By the end of this module, you are expected to have: "],["generating-random-values.html", "Module 7 Generating random values 7.1 Learning outcomes", " Module 7 Generating random values 7.1 Learning outcomes By the end of this module, you are expected to have: "],["file-management.html", "Module 8 File management 8.1 Learning outcomes", " Module 8 File management 8.1 Learning outcomes By the end of this module, you are expected to have: "],["sec-install.html", "Module 9 Install R and RStudio 9.1 Learning outcomes 9.2 Install R and RStudio 9.3 Test your installation 9.4 Add-on packages 9.5 Different learning paths", " Module 9 Install R and RStudio 9.1 Learning outcomes By the end of this module, you are expected to have: Installed R. Installed RStudio. Tested R and RStudio. Installed some packages. The learning outcomes relate to the overall learning goal number 5 of the course. 9.2 Install R and RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). To run R you need to install it on your computer. Moreover, you need the IDE (integrated development environment) RStudio to save your work. Install R from CRAN (Comprehensive R Archive Network). Install the latest precompiled binary distribution for your operating system (use the links up at the top of the CRAN page). Install the desktop version of RStudio, a powerful user interface for R. Under Windows it is a good idea to always open R with administrator rights: Add a shortcut for RStudio (e.g. to the taskbar or desktop). Ctrl+Shift+Right-Click the shortcut and choose Properties: Choose Properties Under Shortcut click Advanced and set Run as administrator You now always can open RStudio with this shortcut. If you have a pre-existing installation of R and/or RStudio, reinstall both to the latest versions. It can be considerably harder to run old software than new. To update your R version you may use the intallr package. 9.3 Test your installation Do whatever is appropriate for your OS to launch RStudio. You should get a window similar to the screenshot you have here, but yours will be more boring because you have not written any code or made any figures yet. Put your cursor in the pane labeled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. If yes, you have succeeded in installing R and RStudio. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code inside of it. 9.4 Add-on packages R is an extensible system and many people share useful codes they have developed as a package via CRAN and GitHub. To install a package from CRAN, for example the dplyr package for data manipulation, one way to do it is in the R console. install.packages(&quot;dplyr&quot;, dependencies = TRUE) By including dependencies = TRUE, we are being explicit and extra careful to install any additional packages the target package, dplyr in the example above is dependent on. Install the package tidyverse which is in fact a bundle of packages by running (note this operation may take a long time): install.packages(&quot;tidyverse&quot;, dependencies = TRUE) Check if you have successfully installed tidyverse by loading the package: library(tidyverse) If your install was unsuccessful try to install the packages who fails one by one. You may also see this short video explaining what packages are. 9.5 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Intro 2R has a set of introductory videos about R. Of special interest are A video about installing R and RStudio. A video giving an introduction to RStudio. A video about installing new packages. References "],["sec-r-basics.html", "Module 10 R basics and workflows Learning path diagramme 10.1 Learning outcomes 10.2 Working with R at the command line in RStudio 10.3 Your first DataCamp course 10.4 Pipes 10.5 RStudio projects 10.6 Global options 10.7 Working directory 10.8 Different learning paths 10.9 Recap 10.10 Exercises", " Module 10 R basics and workflows Learning path diagramme 10.1 Learning outcomes By the end of this module, you are expected to have: Tried R and RStudio. Learned how the RStudio IDE works. Finished your first course on DataCamp. Solved your first exercises. The learning outcomes relate to the overall learning goals number 2, 5, 6, 8, 11, 13 and 15 of the course. 10.2 Working with R at the command line in RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for data analysis. To run R you need to install it on your computer. Throughout this book, we will assume that you are using R via RStudio. First time users often confuse the two. At its simplest, R is like a car’s engine while RStudio is like a car’s dashboard as illustrated in Figure 10.1. Figure 10.1: Analogy of difference between R and RStudio. More precisely, R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well. Compared to Excel, the benefit of using Excel is that the initial learning curve is quite minimal, and most analysis can be done via point-and-click on the top panel. Once a user imports their data into the program, it’s not exceedingly hard to make basic graphs and charts. R is a programming language, however, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Luckily, using R can quickly become second-nature with practice. For a detailed comparison you may see Excel vs R: A Brief Introduction to R by Jesse Sadler. Compared to VBA, R is an interpreted language; users typically access it through a command-line or script file. To run VBA you need to compile and execute it. Recall our car analogy from earlier. As we do not drive a car by interacting directly with the engine but rather by interacting with elements on the car’s dashboard, we will not be using R directly but rather we will use RStudio’s interface. After you install R and RStudio on your computer, you will have two new programs (also called applications) you can open. We will always work in RStudio (except when you do online courses) and not in the R application. Figure 10.2 shows what icon you should be clicking on your computer. Figure 10.2: Icons of R versus RStudio on your computer. Launch RStudio and consider the panes: Console (left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: Customizing RStudio. Now that you are set up with R and RStudio, you are probably asking yourself, “OK - now how do I use R?”. The first thing to note is that unlike other software programs like Excel or SPSS that provide point-and-click interfaces, R is an interpreted language. This means you have to type in commands written in R code. In other words, you have to code/program in R. Note that we will use the terms “coding” and “programming” interchangeably in this book. Go into the Console, where we interact with the live R process. Make an assignment and then inspect the object you just created: x &lt;- 3 * 4 x #&gt; [1] 12 All R statements where you create objects – “assignments” – have this form: object_name &lt;- value and in my head I hear, e.g., “x equals 12”. You will make lots of assignments and the operator &lt;- is a pain to type. Do not be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudio’s keyboard shortcut: Alt+- (the minus sign). Note that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Give your eyes a break and use spaces. RStudio offers many handy keyboard shortcuts. Also, Alt+Shift+K brings up a keyboard shortcut reference card. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You are advised to adopt a naming convention; some use snake case others use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. this_is_snake_case # note you do not use capital letters here thisIsCamelCase # you start each word with a capital letter Make another assignment: this_is_a_long_name &lt;- 2.5 To inspect this, try out RStudio’s completion facility: type the first few characters, press TAB, add characters until you agree, then press return. In VBA you have procedures and functions. In R we only use functions which always return an object. R has a mind-blowing collection of built-in functions that are accessed like so: function_name(arg1 = val1, arg2 = val2, ...) Let’s try function seq() which makes regular sequences of numbers and at the same time demo more helpful features of RStudio. Type se and hit TAB. A pop-up shows you possible completions. Specify seq() by typing more or use the up/down arrows to select. Note the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and note the automatic addition of the closing parenthesis and the placement of the cursor in the middle. Type the arguments 1, 10 and hit return. seq(1, 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. Type seq and press F1 or type: ?seq The Help tab of the lower right pane will show the help documentation of function seq with a description of usage, arguments, return value etc. Note all function arguments have names. You can always specify arguments using name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we did not specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. Note since the default value for from is 1, the same result is obtained by typing: seq(to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 Make this assignment and note similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just create an assignment, you do not see the value. You may see the value by: yo # same as print(yo) #&gt; [1] &quot;hello world&quot; print(yo) #&gt; [1] &quot;hello world&quot; Now look at your Environment tab in the upper right pane where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIcon&quot; &quot;addSolution&quot; &quot;create_learning_path&quot; #&gt; [5] &quot;ctrSol&quot; &quot;g&quot; &quot;strExercises&quot; &quot;strLPath&quot; #&gt; [9] &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; ls() #&gt; [1] &quot;add_graph_legend&quot; &quot;addIcon&quot; &quot;addSolution&quot; &quot;create_learning_path&quot; #&gt; [5] &quot;ctrSol&quot; &quot;g&quot; &quot;strExercises&quot; &quot;strLPath&quot; #&gt; [9] &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; If you want to remove the object named yo, you can do this: rm(yo) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. 10.3 Your first DataCamp course DataCamp is an online platform for learning data science. We are going to use the platform for online lessons and exercises. You should already be signed up to the organization Tools for analytics at DataCamp, otherwise sign up using your university e-mail here. DataCamp runs all the courses in your browser. That is, R is run on a server and you do not use RStudio here. The first course gives an Introduction to R. You are expected to have completed the course before continuing this module! 10.4 Pipes Most functions support the pipe operator which is a powerful tool for clearly expressing a sequence of multiple operations. The pipe operator %&gt;%, comes from the magrittr package and is loaded automatically when you load tidyverse. You may use the RStudio keyboard shortcut Ctrl+Shift+M. Consider the following code: # calculate x as a sequence of operations x &lt;- 16 x &lt;- sqrt(x) x &lt;- log2(x) x #&gt; [1] 2 # same as y &lt;- log2(sqrt(16)) y #&gt; [1] 2 Note we here calculate x using a sequence of operations: \\[ \\mbox{original data (x)} \\rightarrow \\mbox{ sqrt } \\rightarrow \\mbox{ log2 }. \\] That is, we take what is left of the arrow (the object x) and put it into the function on the right of the arrow. These operations can be done using the pipe operator: x &lt;- 16 x &lt;- x %&gt;% sqrt() %&gt;% log2() x #&gt; [1] 2 In general, the pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. That is, you may have other arguments in your functions: 16 %&gt;% sqrt() %&gt;% log2() #&gt; [1] 2 16 %&gt;% sqrt() %&gt;% log(base = 2) # equivalent #&gt; [1] 2 The above example is simple but illustrates that you can use pipes to skip intermediate assignment operations. Later you will do more complex pipes when we consider data wrangling. For instance, mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4, cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and gears. For a more detailed introduction to pipes see Chapter 18 in H. Wickham (2017). 10.5 RStudio projects Let us return to RStudio. One day you will need to quit R, do something else and return to your analysis later. One day you will have multiple analyses going that use R and you want to keep them separate. One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world. To handle these real life situations, you need to store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). RStudio has built-in support for this via its [projects][rstudio-using-projects]. You may think of a project as a folder where you store all you work. Let us create one to use for the rest of this module. Do this: File &gt; New Project… &gt; New Directory &gt; New Project &gt;. The directory name you choose here will be the project name. Call it whatever you want (or follow me for convenience). I used tfa_testing in my tmp directory (that is tfa_testing is now a subfolder of tmp. You now need a way to store R code in your project. We will use 2 ways of storing your code. An R script file or an R Markdown document. Normally you store lines of R code in a script file that you need to run. R Markdown provides an easy way to produce a rich, fully-documented reproducible analysis. Here you combine text, figures and metadata needed to reproduce the analysis from the beginning to the end in a single file. R Markdown compiles to nicely formatted HTML, PDF, or Word. We are going to use R Markdown for larger projects (e.g. the mandatory R report in week 48). We will come back to R Markdown later. 10.5.1 Storing your code in a script file R code can be stored in a script file with file suffix .R. A script file contains a line for each R command to run (think of each line as a command added to the console). Create a new script file File &gt; New File &gt; R Script. Let us add some R code to the file: # this is a comment a &lt;- 2 b &lt;- -3 sig_sq &lt;- 0.5 x &lt;- runif(40) y &lt;- a + b * x + rnorm(40, sd = sqrt(sig_sq)) (avg_x &lt;- mean(x)) write(avg_x, &quot;avg_x.txt&quot;) plot(x, y) abline(a, b, col = &quot;purple&quot;) dev.print(pdf, &quot;toy_line_plot.pdf&quot;) Save the file as testing.R Now run each line by setting the cursor at the first line, hit Ctrl+Enter (runs the line in the Console and moves the cursor to the next line). Repeat Ctrl+Enter until you have run all the lines. Alternatively you may select all the code and hit Ctrl+Enter. Change some things in your code. For instance set a sample size n at the top, e.g. n &lt;- 40, and then replace all the hard-wired 40’s with n. Change some other minor, but detectable, stuff, e.g. alter the sample size n, the slope of the line b, the color of the line etc. Practice the different ways to rerun the code: Walk through line by line by keyboard shortcut (Ctrl+Enter) or mouse (click “Run” in the upper right corner of editor pane). Source the entire document by entering source('testing.R') in the Console or use keyboard shortcut (Shift+Ctrl+S) or mouse (click “Source” in the upper right corner of editor pane or select from the mini-menu accessible from the associated down triangle). Source with echo from the Source mini-menu. Try to get an overview of the different planes and tabs. For instance in the Files tab (lower right plane) you can get an overview of your project files. You may also see this video about projects. 10.6 Global options Quit RStudio. Inspect the folder associated with your project if you wish. Maybe view the PDF in an external viewer. Restart RStudio. Note that things, by default, restore to where we were earlier. Check the Environment tap (top-right plane). The environment should be empty. If it contains objects you defined before you closed R, it is because they have been restored. This is in general not advisable and should be changed by opening Tools &gt; Global Options …. Under General set the check marks as: Quit RStudio and reopen it. The Environment tab should now be empty. 10.7 Working directory Any process running on your computer has a notion of its “working directory”. In R, this is where R will look, by default, for files you ask it to load. It is also where, by default, any files you write to disk will go. Chances are your current working directory is the directory we inspected above, i.e. the one where RStudio wanted to save the workspace. You can explicitly check your working directory with: getwd() It is also displayed at the top of the RStudio console. In general it should be the directory of your R project. You can set R’s working directory at the command line like so: setwd(&quot;./subfolder&quot;) # sets the working dir to a subfolder of you project folder You can also use RStudio’s Files pane to navigate to a directory and then set it as working directory from the menu: Session &gt; Set Working Directory &gt; To Files Pane Location. 10.8 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Roger Peng has a lot of videos on YouTube about R. Of special interest are An introduction to the R language (Part 1, Part 2, Part 3) including data types and basic operations. An introduction to subsetting in R. A detailed description af data types. An introduction to R is given in Chapter 4 of Peng (2018). A detailed tutorial on subsetting is given in Chapter 9 of Peng (2018). A longer tutorial to factors is given in Chapter 15 of H. Wickham (2017). For a more detailed introduction to pipes see Chapter 18 in H. Wickham (2017). For a detailed introduction to strings (see exercise below) check out the DataCamp course String Manipulation with stringr in R. An introduction to good coding conventions in given in Chapter 16 of Stauffer, Simon, and Zeileis (2020). 10.9 Recap R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. Adopt a naming convention. Either use snake case or use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. Store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). You may think of a project as a folder where you store all your work. This workflow will serve you well in the future: Create an RStudio project for an analytical project Keep inputs there (we will soon talk about importing) Keep scripts there; edit them, run them in bits or as a whole from there Keep outputs there (like the PDF written above) Avoid using the mouse for pieces of your analytical workflow, such as loading a dataset or saving a figure. This is extremely important for the reproducibility and for making it possible to retrospectively determine how a numerical table or PDF was actually produced. Learn and use shortcuts as much as possible. For instance Alt+- for the assignment operator and Ctrl+Shift+M for the pipe operator. A reference card of shortcuts can be seen using Alt+Shift+K. Store your R commands in a script file and R scripts with a .R suffix. Comments start with one or more # symbols. Use them. RStudio helps you (de)comment selected lines with Ctrl+Shift+C (Windows and Linux) or Cmd+Shift+C (Mac). Values saved in R are stored in Objects. The interactive DataCamp course gave an introduction to some basic programming concepts and terminology: Data types: integers, doubles/numerics, logicals, and characters. Integers are values like -1, 0, 2, 4092. Doubles or numerics are a larger set of values containing both the integers but also fractions and decimal values like -24.932 and 0.8. Logicals are either TRUE or FALSE while characters are text such as “Hamilton”, “The Wire is the greatest TV show ever”, and “This ramen is delicious.” Note that characters are often denoted with the quotation marks around them. Vectors: a series of values. These are created using the c() function, where c() stands for “combine” or “concatenate.” For example, c(6, 11, 13, 31, 90, 92) creates a six element series of positive integer values . Factors: categorical data are commonly represented in R as factors. Categorical data can also be represented as strings. Data frames: rectangular spreadsheets. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. It is not even required that these objects are related to each other in any way. Comparison operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. A pipe (%&gt;%) sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Use pipes if you have many intermediate assignment operations. 10.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). 10.10.1 Exercise (group work) You are not expected to start solving this exercise before you meet in your group. You have all been allocated into groups. During the course, you are expected to solve the R exercises in these groups. Before you start, it is a good idea to agree on a set of group rules: It is a good idea to have a shared place for your code. Have a look at the section Working in groups and decide on a place to share your code. Create a shared folder and project for your group. Agree on a coding convention. Agree about the rules of how to meet etc. 10.10.2 Exercise (install packages) This exercise is done from the Console in RStudio (under Windows, remember to have admin rights). × Solution install.packages(&quot;devtools&quot;) Close Solution Install the package devtools using function install.packages. Note you can always get help/see documentation of a function by typing ?install.packages or typing install.packages and press F1. You now have installed the package from the default repository (CRAN). You may also install packages from other repositories (e.g. GitHub): Have a look at the documentation for function install_github in the package devtools. This can be done in different ways: library(devtools) # we here load all the functions in devtools ?install_github ?devtools::install_github # we here use the namespace devtools to load only one function Install the package tfa from GitHub using path bss-osca/tfa/tfa-package. 10.10.3 Exercise (piping) Solve this exercise using a script file (e.g. exercises/pipe.R). Remember that you can run a line in the file using Ctrl+Enter. The pipe %&gt;% can be used to perform operations sequentially without having to define intermediate objects (Ctrl+Shift+M). Have a look at the dataset mtcars: head(mtcars) ?mtcars The pipe library(tidyverse) mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4 &amp; cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and (operator &amp;) gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet 4 Drive 21.4 110 0 3 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Toyota Corona 21.5 97 0 3 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Porsche 914-2 26.0 91 1 5 #&gt; Lotus Europa 30.4 113 1 5 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars %&gt;% select(___, ___, ___, ___) Close Hint Create a pipe that selects columns related to miles, horsepower, transmission and gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20, gear == 4) #&gt; mpg hp am gear #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 Close Solution × Hint mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(___, ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 and 4 gears. × Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20 | gear == 4) #&gt; mpg hp am gear #&gt; Mazda RX4 21.0 110 1 4 #&gt; Mazda RX4 Wag 21.0 110 1 4 #&gt; Datsun 710 22.8 93 1 4 #&gt; Hornet Sportabout 18.7 175 0 3 #&gt; Valiant 18.1 105 0 3 #&gt; Duster 360 14.3 245 0 3 #&gt; Merc 240D 24.4 62 0 4 #&gt; Merc 230 22.8 95 0 4 #&gt; Merc 280 19.2 123 0 4 #&gt; Merc 280C 17.8 123 0 4 #&gt; Merc 450SE 16.4 180 0 3 #&gt; Merc 450SL 17.3 180 0 3 #&gt; Merc 450SLC 15.2 180 0 3 #&gt; Cadillac Fleetwood 10.4 205 0 3 #&gt; Lincoln Continental 10.4 215 0 3 #&gt; Chrysler Imperial 14.7 230 0 3 #&gt; Fiat 128 32.4 66 1 4 #&gt; Honda Civic 30.4 52 1 4 #&gt; Toyota Corolla 33.9 65 1 4 #&gt; Dodge Challenger 15.5 150 0 3 #&gt; AMC Javelin 15.2 150 0 3 #&gt; Camaro Z28 13.3 245 0 3 #&gt; Pontiac Firebird 19.2 175 0 3 #&gt; Fiat X1-9 27.3 66 1 4 #&gt; Ford Pantera L 15.8 264 1 5 #&gt; Ferrari Dino 19.7 175 1 5 #&gt; Maserati Bora 15.0 335 1 5 #&gt; Volvo 142E 21.4 109 1 4 Close Solution × Hint mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(___ | ___) Close Hint Given the answer in 1), filter so cars have miles less than 20 or 4 gears. The “or” operator in R is |. × Solution mtcars %&gt;% filter(mpg &lt; 20, gear == 4) %&gt;% select(wt, vs) #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint mtcars %&gt;% filter(mpg &lt; 20, gear == 4) %&gt;% select(___, ___) Close Hint Create a pipe that filters the cars having miles less than 20 and 4 gears and selects columns related to weight and engine. × Solution dat &lt;- mtcars dat &lt;- filter(dat, mpg &lt; 20, gear == 4) dat &lt;- select(dat, wt, vs) dat #&gt; wt vs #&gt; Merc 280 3.44 1 #&gt; Merc 280C 3.44 1 Close Solution × Hint dat &lt;- mtcars dat &lt;- filter(dat, ___) dat &lt;- select(dat, ___) dat Close Hint Solve Question 4 without the pipe operator. 10.10.4 Exercise (working dir) Do this exercise from the Console in RStudio. When reading and writing to local files, your working directory becomes important. You can get and set the working directory using functions getwd and setwd. Set the working directory to the project directory using the menu: Session &gt; Set Working Directory &gt; To Project Directory. Now let us create some files: dir.create(&quot;subfolder&quot;, showWarnings = FALSE) write_file(&quot;Some text in a file&quot;, path = &quot;test1.txt&quot;) write_file(&quot;Some other text in a file&quot;, path = &quot;subfolder/test2.txt&quot;) Which folders and files have been created? You may have a look in the Files tab in RStudio. We can read the file again using: read_file(&quot;test1.txt&quot;) #&gt; [1] &quot;Some text in a file&quot; × Solution read_file(&quot;subfolder/test2.txt&quot;) #&gt; [1] &quot;Some other text in a file&quot; Close Solution × Hint read_file(&quot;subfolder/___&quot;) Close Hint Read the file test2.txt. Set the working directory to subfolder using function setwd. Note that setwd supports relative paths. Check that you are in the right working directory using getwd. You may also have a look at the files in the directory using function list.files. × Solution setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../test1.txt&quot;) #&gt; [1] &quot;Some text in a file&quot; read_file(&quot;test2.txt&quot;) #&gt; [1] &quot;Some other text in a file&quot; Close Solution × Hint setwd(&quot;subfolder&quot;) # done in Q3 read_file(&quot;../___&quot;) read_file(&quot;___&quot;) Close Hint Read files test1.txt and test2.txt. Note that in relative paths ../ means going to the parent folder. What is different compared to Question 2? 10.10.5 Exercise (vectors) Solve this exercise using a script file. × Solution n &lt;- 100 n * (n+1) / 2 #&gt; [1] 5050 Close Solution What is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum? × Solution n &lt;- 1000 n * (n+1) / 2 #&gt; [1] 5e+05 Close Solution Now use the same formula to compute the sum of the integers from 1 through 1000. × Solution The answer is b). Close Solution Look at the result of typing the following code into R: n &lt;- 1000 x &lt;- seq(1, n) sum(x) Based on the result, what do you think the functions seq and sum do? You can use e.g help(\"sum\") or ?sum. sum creates a list of numbers and seq adds them up. seq creates a list of numbers and sum adds them up. seq creates a random list and sum computes the sum of 1 through 1,000. sum always returns the same number. × Solution Sample 30 integers in the range [1, 100]. Close Solution Run code. What does sample.int do? set.seed(123) v &lt;- sample.int(100,30) v #&gt; [1] 31 79 51 14 67 42 50 43 97 25 90 69 57 9 72 26 7 95 87 36 78 93 76 15 32 84 82 41 23 27 × Solution sum(v) #&gt; [1] 1598 mean(v) #&gt; [1] 53.3 sd(v) #&gt; [1] 28.8 Close Solution What is the sum, mean, and standard deviation of v? × Solution v[c(1, 6, 4, 15)] #&gt; [1] 31 42 14 72 Close Solution × Hint v[c(1, ___, ___, ___)] Close Hint Select elements 1, 6, 4, and 15 of v. × Solution v[v &gt; 50] #&gt; [1] 79 51 67 97 90 69 57 72 95 87 78 93 76 84 82 Close Solution Select elements with value above 50. × Solution v[v &gt; 75 | v &lt; 25] #&gt; [1] 79 14 97 90 9 7 95 87 78 93 76 15 84 82 23 Close Solution × Hint v[___ | ___] Close Hint Select elements with value above 75 or below 25. × Solution v[v == 43] #&gt; [1] 43 Close Solution Select elements with value 43. × Solution v[is.na(v)] #&gt; integer(0) Close Solution × Hint v[is.na(___)] Close Hint Select elements with value NA. × Solution which(v &gt; 75 | v &lt; 25) #&gt; [1] 2 4 9 11 14 17 18 19 21 22 23 24 26 27 29 Close Solution × Hint which(___ | ___) Close Hint Which elements have value above 75 or below 25? Hint: see the documentation of function which (?which). 10.10.6 Exercise (matrices) Solve this exercise using a script file. Consider matrices m1 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3) m2 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3, byrow = TRUE) m3 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), ncol = 3) What is the difference between the three matrices (think/discuss before running the code). × Solution rowSums(m1, na.rm = T) #&gt; [1] 169 75 294 colSums(m2, na.rm = T) #&gt; [1] 171 151 154 62 Close Solution × Hint rowSums(___, na.rm = ___) colSums(___, na.rm = ___) Close Hint Calculate the row sums of m1 and column sums of m2 ignoring NA values. Hint: have a look at the documentation of rowSums. × Solution rbind(m1, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 NA 86 46 #&gt; [2,] 8 50 NA 17 #&gt; [3,] 51 97 84 62 #&gt; [4,] 1 2 3 4 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as last row to m1. × Solution rbind(c(1, 2, 3, 4), m1) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 2 3 4 #&gt; [2,] 37 NA 86 46 #&gt; [3,] 8 50 NA 17 #&gt; [4,] 51 97 84 62 Close Solution × Hint rbind(___, ___) Close Hint Add row c(1, 2, 3, 4) as first row to m1. × Solution cbind(m3, c(1, 2, 3, 4)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 37 50 84 1 #&gt; [2,] 8 97 46 2 #&gt; [3,] 51 86 17 3 #&gt; [4,] NA NA 62 4 Close Solution × Hint cbind(___, ___) Close Hint Add column c(1, 2, 3, 4) as last column to m3. × Solution m1[2,4] #&gt; [1] 17 Close Solution Select the element in row 2 and column 4 of m1. × Solution m1[2:3,1:2] #&gt; [,1] [,2] #&gt; [1,] 8 50 #&gt; [2,] 51 97 Close Solution × Hint m1[2:3,___] Close Hint Select elements in rows 2-3 and columns 1-2 of m1. × Solution m1[3, c(1,3,4)] #&gt; [1] 51 84 62 Close Solution × Hint m1[3,___] Close Hint Select elements in row 3 and columns 1, 3 and 4 of m1. × Solution m1[3,] #&gt; [1] 51 97 84 62 Close Solution Select elements in row 3 of m1. × Solution m2[is.na(m2)] #&gt; [1] NA NA Close Solution × Hint m2[is.na(___)] Close Hint Select all NA elements in m2. × Solution m2[m2 &gt; 50] #&gt; [1] 84 97 51 86 NA NA 62 Close Solution Select all elements greater that 50 in m2. 10.10.7 Exercise (data frames) Solve this exercise using a script file. Data frames may be seen as cell blocks in Excel. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. We consider the data frame mtcars: str(mtcars) glimpse(mtcars) ?mtcars Use the head and tail functions to have a look at the data. × Solution mtcars[,4] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars[,&quot;hp&quot;] #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 mtcars$hp #&gt; [1] 110 110 93 110 175 105 245 62 95 123 123 180 180 180 205 215 230 66 52 65 97 150 150 245 #&gt; [25] 175 66 91 113 264 175 335 109 Close Solution × Hint mtcars[,___] mtcars[,&quot;___&quot;] mtcars$___ Close Hint Select column hp using index (column 4), its name, and the $ operator. × Solution mtcars &lt;- rbind(mtcars, c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3)) rownames(mtcars)[33] &lt;- &quot;Phantom XE&quot; Close Solution × Hint mtcars &lt;- rbind(mtcars, ___) rownames(mtcars)[___] &lt;- &quot;Phantom XE&quot; Close Hint Update mtcars by adding row c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3). Name the row ‘Phantom XE’. × Solution col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) mtcars &lt;- cbind(mtcars, col) class(mtcars$col) #&gt; [1] &quot;character&quot; Close Solution × Hint col &lt;- c(NA, &quot;green&quot;, ......) mtcars &lt;- cbind(mtcars, ___) class(mtcars$___) Close Hint Update mtcars by adding column: col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) What class is column col? × Solution mtcars[mtcars$vs == 0,] #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Duster 360 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 green #&gt; Merc 450SE 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 green #&gt; Merc 450SL 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 blue #&gt; Merc 450SLC 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 blue #&gt; Cadillac Fleetwood 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 green #&gt; Lincoln Continental 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 red #&gt; Chrysler Imperial 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 red #&gt; Dodge Challenger 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 red #&gt; AMC Javelin 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 red #&gt; Camaro Z28 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 &lt;NA&gt; #&gt; Pontiac Firebird 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 green #&gt; Porsche 914-2 26.0 4 120 91 4.43 2.14 16.7 0 1 5 2 blue #&gt; Ford Pantera L 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 green #&gt; Ferrari Dino 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 red #&gt; Maserati Bora 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 green Close Solution × Hint mtcars[mtcars$___ == 0,] Close Hint Select cars with a V-shaped engine. 10.10.8 Exercise (lists) Solve this exercise using a script file. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. Let us define a list: lst &lt;- list(45, &quot;Lars&quot;, TRUE, 80.5) lst #&gt; [[1]] #&gt; [1] 45 #&gt; #&gt; [[2]] #&gt; [1] &quot;Lars&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE #&gt; #&gt; [[4]] #&gt; [1] 80.5 Elements can be accessed using brackets: x &lt;- lst[2] x #&gt; [[1]] #&gt; [1] &quot;Lars&quot; y &lt;- lst[[2]] y #&gt; [1] &quot;Lars&quot; × Solution class(x) #&gt; [1] &quot;list&quot; class(y) #&gt; [1] &quot;character&quot; Close Solution × Hint class(___) class(___) Close Hint What is the class of the two objects x and y? What is the difference between using one or two brackets? × Solution names(lst) &lt;- c(&quot;age&quot;, &quot;name&quot;, &quot;male&quot;, &quot;weight&quot;) lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $male #&gt; [1] TRUE #&gt; #&gt; $weight #&gt; [1] 80.5 Close Solution × Hint names(lst) &lt;- c(&quot;age&quot;, ___, ___, ___) lst Close Hint Add names age, name, male and weight to the 4 components of the list. × Solution lst$name #&gt; [1] &quot;Lars&quot; Close Solution Extract the name component using the $ operator. You can add/change/remove components using: lst$height &lt;- 173 # add component lst$name &lt;- list(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) # change the name component lst$male &lt;- NULL # remove male component lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; $name$first #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $name$last #&gt; [1] &quot;Nielsen&quot; #&gt; #&gt; #&gt; $weight #&gt; [1] 80.5 #&gt; #&gt; $height #&gt; [1] 173 × Solution lst$name$last #&gt; [1] &quot;Nielsen&quot; Close Solution × Hint lst$name$___ Close Hint Extract the last name component using the $ operator. 10.10.9 Exercise (string management) Strings in R can be defined using single or double quotes: str1 &lt;- &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business.&quot; str2 &lt;- &#39;BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&#39; str3 &lt;- c(str1, str2) # vector of strings The stringr package in tidyverse provides many useful functions for string manipulation. We will consider a few. str4 &lt;- str_c(str1, str2, &quot;As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot;, sep = &quot; &quot;) # join strings str4 #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot; str_c(str3, collapse = &quot; &quot;) # collapse vector to a string #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) # replace first occurrence #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace_all(str2, &quot;the&quot;, &quot;a&quot;) # replace all occurrences #&gt; [1] &quot;BA can both be seen as a complete decision making process for solving a business problem or as a set of methodologies that enable a creation of business value.&quot; str_remove(str1, &quot; for making better decisions in business&quot;) #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight.&quot; str_detect(str2, &quot;BA&quot;) # detect a pattern #&gt; [1] TRUE × Solution str_detect(str1, &quot;Business&quot;) #&gt; [1] TRUE str_detect(str2, &quot;Business&quot;) #&gt; [1] FALSE Close Solution × Hint str_detect(str1, ___) str_detect(___, ___) Close Hint Is Business (case sensitive) contained in str1 and str2? × Solution str5 &lt;- str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; Close Solution × Hint str5 &lt;- str_replace(str2, ___, ___) Close Hint Define a new string that replace BA with Business Analytics in str2 × Solution str5 &lt;- str_remove(str5, &quot; or as a set of methodologies that enable the creation of business value&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem.&quot; Close Solution × Hint str5 &lt;- str_remove(str5, ___) Close Hint In the string from Question 2, remove or as a set of methodologies that enable the creation of business value. × Solution str5 &lt;- str_c(str5, &quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive analytics.&quot; Close Solution × Hint str5 &lt;- str_c(str5, ___, sep= ___) Close Hint In the string from Question 3, add This course will focus on programming and descriptive analytics.. × Solution str5 &lt;- str_replace(str5, &quot;analytics&quot;, &quot;business analytics&quot;) str5 #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str5 &lt;- str_replace(str5, ___, ___) Close Hint In the string from Question 4, replace analytics with business analytics. × Solution str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) %&gt;% str_remove(&quot; or as a set of methodologies that enable the creation of business value&quot;) %&gt;% str_c(&quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) %&gt;% str_replace(&quot;analytics&quot;, &quot;business analytics&quot;) #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem. This course will focus on programming and descriptive business analytics.&quot; Close Solution × Hint str_replace(str2, ___, ___) %&gt;% str_remove(___) %&gt;% str_c(___) %&gt;% str_replace(___) Close Hint Do all calculations in Question 2-5 using pipes. References "],["sec-loops.html", "Module 11 Loops and conditionals Learning path diagramme 11.1 Learning outcomes 11.2 Conditionals and control flow 11.3 Loops 11.4 Different learning paths 11.5 Recap 11.6 Exercises", " Module 11 Loops and conditionals Learning path diagramme This module considers programming with loops and conditional statements. 11.1 Learning outcomes By the end of this module, you are expected to be able to: Formulate conditional statements. Use functions any and all. Formulate loops in R using for and while statements. Use function if_else. The learning outcomes relate to the overall learning goals number 2, 4 and 10 of the course. 11.2 Conditionals and control flow An excellent introduction to conditionals and if statements is given in Chapter 1 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. Some functions are also useful for comparing logical data types. Consider this example: x &lt;- c(1, 3, 5, 10, 2, 17, 11, NA, 4) x &gt; 10 # are the elements greater that 10 #&gt; [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE NA FALSE any(x &gt; 10) # are any of the elements greater that 10 #&gt; [1] TRUE all(x &gt; 10) # are all of the elements greater that 10 #&gt; [1] FALSE all(x &lt; 20) # are all of the elements greater that 20 #&gt; [1] NA all(x &lt; 20, na.rm = TRUE) # are all of the elements greater that 20 #&gt; [1] TRUE That is, functions any and all can be used to join logical values in vectors. Some if statements can be written alternatively using function if_else: if_else(condition, true, false, missing = NULL) For example: x &lt;- c(-5:5, NA) x #&gt; [1] -5 -4 -3 -2 -1 0 1 2 3 4 5 NA ## using if and for res &lt;- rep(&quot;&quot;, length(x)) for (i in seq_along(x)) { if (is.na(x[i])) res[i] &lt;- &quot;missing&quot; else if (x[i] &lt; 0) res[i] &lt;- &quot;negative&quot; else res[i] &lt;- &quot;positive&quot; } res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## implicit if statement res &lt;- rep(&quot;&quot;, length(x)) res #&gt; [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; res[x &lt; 0] &lt;- &quot;negative&quot; res[x &gt;= 0] &lt;- &quot;positive&quot; res[is.na(x)] &lt;- &quot;missing&quot; res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## using if_else res &lt;- if_else(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;, &quot;missing&quot;) res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; 11.3 Loops An excellent introduction to conditionals and if statements is given in Chapter 2 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. Loops in R may be slow. However, not if you follow some golden rules: Do not use a loop when a vectorized alternative exists. Do not grow objects (via c, cbind, etc) during the loop - R has to create a new object and copy across the information just to add a new element or row/column. Instead, allocate an object to hold the results and fill it in during the loop. As an example, consider the for loop with 4 iterations: i_val &lt;- c(1,2,6,9) res &lt;- rep(NA,4) res #&gt; [1] NA NA NA NA for (idx in 1:length(i_val)) { res[idx] &lt;- 6 * i_val[idx] + 9 } res #&gt; [1] 15 21 45 63 Note we allocate memory for the result vector before the loop so we do not have to grow the result object. Next, we calculate results \\(6i+9\\) using a loop. Be careful here! This is not the same: res &lt;- rep(NA,4) for (i in i_val) { res[i] &lt;- 6 * i + 9 } res #&gt; [1] 15 21 NA NA NA 45 NA NA 63 In this example, however, we can use a vectorized alternative: res &lt;- 6 * i_val + 9 res #&gt; [1] 15 21 45 63 where the operation is applied to each element in the vector. Nested for loops is also possible. A simple example of a nested loop: for (i in 1:3) { for (j in 1:2) { cat(str_c(&quot;i =&quot;, i, &quot; j = &quot;,j, &quot;\\n&quot;)) } } #&gt; i =1 j = 1 #&gt; i =1 j = 2 #&gt; i =2 j = 1 #&gt; i =2 j = 2 #&gt; i =3 j = 1 #&gt; i =3 j = 2 We here use the function cat to print out a string (\\n indicates new line). Note how the nested loops are executed: Set i = 1 (outer loop) Set j = 1 (inner loop), i stays 1 Set j = 2 (inner loop), i stays 1 Inner loop finishes, proceed with outer loop. Increase i = 2 (outer loop) Set j = 1 (inner loop), i stays 2 Set j = 2 (inner loop), i stays 2 Inner loop finishes, proceed with outer loop. Increase i = 3 (outer loop) Set j = 1 (inner loop), i stays 3 Set j = 2 (inner loop), i stays 3 Inner loop finishes, proceed with outer loop. Outer loop finishes as well (we looped over i in 1:3). Job done. Nested loops can be used to iterate over matrices or data frames: mat &lt;- matrix(NA, nrow = 2, ncol = 3) mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] NA NA NA for (i in 1:nrow(mat)) { for (j in 1:ncol(mat)) { mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Often you can replace nested loops with a single loop by using expand_grid: library(tidyverse) # load function expand_grid mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 1:2, j=1:3) ite #&gt; # A tibble: 6 × 2 #&gt; i j #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 1 #&gt; 2 1 2 #&gt; 3 1 3 #&gt; 4 2 1 #&gt; 5 2 2 #&gt; 6 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Note expand_grid creates a data frame with all combinations. This way of looping is a more flexible approach since you can nest more loops by adding more columns to ite, add different values in each column. For instance, if you only want to calculate values for row 2 and columns 1 and 3 the code becomes: mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 2, j = c(1,3)) ite #&gt; # A tibble: 2 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 #&gt; 2 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] 4 NA 6 11.4 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Roger Peng has a video An introduction to control structures including if, for and while. Hefin Rhys has a video Conditional statements and loops in R doing examples in RStudio. For a more detailed introduction to loops see Chapter 21 in H. Wickham (2017). Loops can also be created using the apply family of functions. An introduction is given in Chapter 4 of the interactive DataCamp course Intermediate R. 11.5 Recap Comparison/relational operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. Logical operators known to R are: &amp; and, | or, ! not. If you use &amp;&amp; and || only the first element in vectors are compared. In general this is used rarely. Useful functions that return a logical are any and all which can be used to join logical values in vectors. Conditional Statements can be constructed using for instance if and while statements. Moreover, function if_else is a vectorized alternative. Loops can be created using for and while statements. You can break out of a loop using break and jump to the next iteration (skipping the remainder of the code in the loop) using next. Do not use a loop when a vectorized alternative exists. Do not grow objects during the loop. Instead, allocate an object to hold the results and fill it in during the loop. Nested loops are possible in R. However, often they can be converted into a single loop by defining a data frame having the values of the nested loops in each row. Here function expand_grid may be useful to create the data frame. 11.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 11.6.1 Exercise (conditional expressions) Solve this exercise using a script file Consider object x: x &lt;- c(1,2,-3,4) What will this conditional expression return? if(all(x&gt;0)){ print(&quot;All Postives&quot;) } else { print(&quot;Not all positives&quot;) } What will the following expressions return? x &lt;- c(TRUE, FALSE, TRUE, TRUE) all(x) any(x) any(!x) all(!x) Which of the expressions above is always FALSE when at least one entry of a logical vector x is TRUE? Consider vector: library(tidyverse) x &lt;- 1:15 x #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 × Solution if_else(x &lt; 7, as.integer(0), x) #&gt; [1] 0 0 0 0 0 0 7 8 9 10 11 12 13 14 15 Close Solution × Hint if_else(x &lt; 7, as.integer(___), ___) Close Hint Use the if_else function to set elements with value below 7 to 0. × Solution if_else(x &lt; 7 | x &gt; 10, NA_integer_, x) #&gt; [1] NA NA NA NA NA NA 7 8 9 10 NA NA NA NA NA Close Solution × Hint if_else(___, NA_integer_, ___) Close Hint Use the if_else function to set elements with value below 7 or above 10 to NA_integer_ (which is the NA/missing value of an integer). × Solution x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- &quot;missing&quot; } else if (x %% 2 == 0) { y &lt;- &quot;even&quot; } else if (x %% 2 == 1) { y &lt;- &quot;odd&quot; } else if (x %% 1 &gt; 0) { y &lt;- &quot;decimal&quot; } x #&gt; [1] 7 y #&gt; [1] &quot;odd&quot; Close Solution × Hint x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- ___ } else if (x %% 2 == 0) { ___ } else if (___) { ___ } else if (___) { y &lt;- &quot;decimal&quot; } x y Close Hint Consider code x &lt;- sample(c(1:10,NA,5.5), 1) x #&gt; [1] 7 which generates a number from the vector c(1:10,NA,5.5). Write code which set object y equal to “even” if x is even, “odd” if x is odd, “decimal” if x has a decimal not zero and “missing” if x is NA. Hint: have a look at ?'%%' (the modulo operator). 11.6.2 Exercise (loops) × Solution x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- 2 * i + 4 } x #&gt; [1] 6 8 10 12 Close Solution × Hint x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- ___ } x Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=1\\ldots 4\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- 2 * i_val[idx] + 4 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- ___ } Close Hint Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=2,5,6,12\\). × Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- 2 * i_val[idx] + 4 idx &lt;- idx + 1 } Close Solution × Hint i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- ___ idx &lt;- ___ } Close Hint Solve Question 2 using a while loop. × Solution 2 * 1:4 + 4 # Q1 #&gt; [1] 6 8 10 12 2* c(2, 5, 6, 12) + 4 # Q2 #&gt; [1] 8 14 16 28 Close Solution × Hint 2 * ___ + 4 # Q1 ___ # Q2 Close Hint Solve Questions 1 and 2 using a vectorized alternative. 11.6.3 Exercise (calculating distances) Consider zip codes in Jutland: # remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;, upgrade = FALSE) # run to upgrade library(tidyverse) library(tfa) zips #&gt; # A tibble: 376 × 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; #&gt; 6 8592 &quot;Anholt&quot; #&gt; 7 8643 &quot;Ans By&quot; #&gt; 8 6823 &quot;Ansager&quot; #&gt; 9 9510 &quot;Arden&quot; #&gt; 10 5466 &quot;Asperup&quot; #&gt; # … with 366 more rows We want to calculate distances between a subset of zip areas: idx &lt;- 1:5 dat &lt;- zips[idx,] dat #&gt; # A tibble: 5 × 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) colnames(distanceMat) &lt;- str_c(dat$Zip[idx], dat$Area[idx], sep = &quot; &quot;) rownames(distanceMat) &lt;- colnames(distanceMat) distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup NA NA NA NA NA #&gt; 6753 Agerb\\xe6k NA NA NA NA NA #&gt; 6534 Agerskov NA NA NA NA NA #&gt; 8961 Alling\\xe5bro NA NA NA NA NA #&gt; 6051 Almind NA NA NA NA NA We can find average distances between two zip codes (here rows 1 and 2 in dat) using Bing maps: key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[1], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[2], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) library(jsonlite) lst &lt;- jsonlite::fromJSON(url) dist &lt;- lst$resourceSets$resources[[1]]$travelDistance dist #&gt; [1] 138 lst$statusCode #&gt; [1] 200 lst$statusDescription #&gt; [1] &quot;OK&quot; Note we call the Bing maps API with the two zip codes. A json file is returned and stored in a list. To get the average travel distance we access travelDistance. The status code should be 200 if the calculation returned is okay. × Solution key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(distanceMat)) { if (i&gt;j) {distanceMat[i,j] &lt;- distanceMat[j,i]; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance } } } distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup 0.0 137.7 143 215 86.2 #&gt; 6753 Agerb\\xe6k 137.7 0.0 108 180 59.4 #&gt; 6534 Agerskov 142.7 108.4 0 206 65.0 #&gt; 8961 Alling\\xe5bro 215.2 180.4 206 0 149.2 #&gt; 6051 Almind 86.2 59.4 65 149 0.0 Close Solution × Hint key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(___)) { if (i&gt;j) {distanceMat[i,j] &lt;- ___; next} # assume symmetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- ___; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == ___) { distanceMat[i,j] &lt;- ___ } } } distanceMat Close Hint Use nested for loops to fill distanceMat with distances. Assume that the distance from a to b is the same as from b to a. That is, you only have to call the API once for two zip codes. Use an if statement to check if the status code is okay. 11.6.4 Exercise (expand_grid) × Solution ite &lt;- expand_grid(i = c(1,5), j = 2:3) ite #&gt; # A tibble: 4 × 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 1 3 #&gt; 3 5 2 #&gt; 4 5 3 key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance distanceMat[j,i] &lt;- distanceMat[i,j] } } distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup 0.0 137.7 142.7 215 86.2 #&gt; 6753 Agerb\\xe6k 137.7 0.0 108.4 180 58.8 #&gt; 6534 Agerskov 142.7 108.4 0.0 206 63.8 #&gt; 8961 Alling\\xe5bro 215.2 180.4 205.7 0 149.2 #&gt; 6051 Almind 86.2 58.8 63.8 149 0.0 Close Solution × Hint ite &lt;- expand_grid(i = ___, j = ___) ite key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == ___) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance distanceMat[j,i] &lt;- ___ } } distanceMat Close Hint Consider the solution of Exercise 11.6.3 and assume that you only want to calculate the distance from rows 1 and 5 to rows 2 and 3 in dat. Modify the solution using expand_grid so only one loop is used. References "],["sec-functions.html", "Module 12 Functions 12.1 Learning outcomes 12.2 DataCamp course 12.3 Functions returning multiple objects 12.4 The ... argument 12.5 Documenting your functions 12.6 Different learning paths 12.7 Recap 12.8 Exercises", " Module 12 Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. John Chambers Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that needs to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). 12.1 Learning outcomes By the end of this module, you are expected to be able to: Call a function. Formulate a function with different input arguments. Describe why functions are important in R. Set defaults for input arguments. Return values from functions. Explain how variable scope and precedence works. Document functions. The learning outcomes relate to the overall learning goals number 2, 3, 4 and 10 of the course. 12.2 DataCamp course An excellent introduction to functions is given in Chapter 3 in the DataCamp course Intermediate R. Please complete the chapter before continuing. 12.3 Functions returning multiple objects Functions in R only return a single object. However, note that the object may be a list. That is, if you want to return multiple arguments, store them in a list. A simple example: test &lt;- function() { # the function does some stuff and calculate some results res1 &lt;- 45 res2 &lt;- &quot;Success&quot; res3 &lt;- c(4, 7, 9) res4 &lt;- list(cost = 23, profit = 200) lst &lt;- list(days = res1, run = res2, id = res3, money = res4) return(lst) } test() #&gt; $days #&gt; [1] 45 #&gt; #&gt; $run #&gt; [1] &quot;Success&quot; #&gt; #&gt; $id #&gt; [1] 4 7 9 #&gt; #&gt; $money #&gt; $money$cost #&gt; [1] 23 #&gt; #&gt; $money$profit #&gt; [1] 200 12.4 The ... argument The special argument ... indicates a variable number of arguments and is usually used to pass arguments to nested functions used inside the function. Consider example: my_name &lt;- function(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) { str_c(first, last, sep = &quot; &quot;) } my_name() #&gt; [1] &quot;Lars Nielsen&quot; cite_text &lt;- function(text, ...) { str_c(text, &#39;, -&#39;, my_name(...)) } cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Nielsen&quot; cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;, last = &quot;Relund&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Relund&quot; cite_text(&quot;To be or not to be&quot;, first = &quot;Shakespeare&quot;, last = &quot;&quot;) #&gt; [1] &quot;To be or not to be, -Shakespeare &quot; Note in the first function run, we use the defaults in my_name. In the second run, we change the default last name and in the last run, we change both arguments. If you need to retrieve/capture the content of the ... argument, put it in a list: test &lt;- function(...) { return(list(...)) } test(x = 4, y = &quot;hey&quot;, z = 1:5) #&gt; $x #&gt; [1] 4 #&gt; #&gt; $y #&gt; [1] &quot;hey&quot; #&gt; #&gt; $z #&gt; [1] 1 2 3 4 5 12.5 Documenting your functions It is always a good idea to document your functions. This is in fact always done in functions of a package. For instance try ?mutate and see the documentation in the Help tab. Assume that you have written a function subtract &lt;- function(x, y) { return(x-y) } In RStudio you can insert a Roxygen documentation skeleton by having the cursor at the first line of the function and go to Code &gt; Insert Roxygen Skeleton (Ctrl+Alt+Shift+R): #&#39; Title #&#39; #&#39; @param x #&#39; @param y #&#39; #&#39; @return #&#39; @export #&#39; #&#39; @examples subtract &lt;- function(x, y) { return(x-y) } You now can modify your documentation to #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; #&#39; @return The difference. #&#39; @export #&#39; #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } Note Parameters/function arguments are documented using the @param tag. Return value is documented using the @return tag. Under the @examples tag you can insert some examples. Ignore the @export tag. This is used if you include your function in your own package. Package development is beyond the scope of this course. If you are interested, have a look at the book Hadley Wickham (2015). A list of further tags can be seen in the vignette Rd (documentation) tags. 12.6 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! For a more detailed interactive tutorial about functions see the DataCamp course Introduction to Writing Functions in R. Hefin Rhys has a video about Writing functions in R giving examples in RStudio. An introduction to functions is also given in Chapter 14 of Peng (2018). A detailed tutorial on functions is given in Chapters 18, 19 and 20 of Bryan (2017). 12.7 Recap Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that need to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style of how code is written. Rather than repeating the code, functions and control structures allow one to build code in blocks. As a result, your code becomes more structured, more readable and much easier to maintain and debug (find errors). Functions can be defined using the function() directive. The named arguments (input values) can have default values. Moreover, R passes arguments by value. That is, an R function cannot change the variable that you input to that function. A function can be called using its name and its arguments can be specified by name or by position in the argument list. Functions always return the last expression evaluated in the function body or when you use the return flow control statement (good coding practice). Scoping refers to the rules R use to look up the value of variables. A function will first look inside the body of the function to identify all the variables. If all variables exist, no further search is required. Otherwise, R will look one level up to see if the variable exists. Functions can be assigned to R objects just like any other R object. Document your functions using the Roxygen skeleton! 12.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 12.8.1 Exercise (defining functions) Solve this exercise using a script file. × Solution #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(sum(1:n)) } sum_n(5000) #&gt; [1] 12502500 Close Solution × Hint #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(___) } sum_n(5000) Close Hint Create a function sum_n that for any given value, say \\(n\\), computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5000. Document your function too. × Solution #&#39; Computes the sum S_n = 1^2 + 2^2 + 3^2 + ... + n^2 #&#39; #&#39; @param n Max input in sum. #&#39; #&#39; @return S_n compute_s_n &lt;- function(n) { return(sum((1:n)^2)) } compute_s_n(10) #&gt; [1] 385 Close Solution Write a function compute_s_n that for any given \\(n\\) computes the sum \\(S_n = 1^2 + 2^2 + 3^2 + \\dots + n^2\\). Report the value of the sum when \\(n=10\\). × Solution 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- compute_s_n(n) } s_n #&gt; [1] 1 5 14 30 55 91 140 204 285 385 506 650 819 1015 1240 1496 1785 2109 2470 #&gt; [20] 2870 3311 3795 4324 4900 5525 Close Solution 1 × Hint 1 s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- ___ } s_n Close Hint 1 × Solution 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*(2*n+1)/6) } for (n in 1:25) { if (s_n[n] != compute_s_n_alt(n)) { cat(&#39;Error!&#39;) break } } Close Solution 2 × Hint 2 compute_s_n_alt &lt;- function(n) { return(n*(n+1)*___) } for (n in 1:25) { if (s_n[n] != ___) { cat(&#39;Error!&#39;) break } } Close Hint 2 Define an empty numerical vector s_n of size 25 using s_n &lt;- vector(\"numeric\", 25) and store in the results of \\(S_1, S_2, \\dots S_{25}\\) using a for-loop. Confirm that the formula for the sum is \\(S_n= n(n+1)(2n+1)/6\\) for \\(n = 1, \\ldots, 25\\). × Solution biggest &lt;- function(a, b) { if (a &gt; b) return(1) return(0) } biggest(3,4) #&gt; [1] 0 biggest(3,3) #&gt; [1] 0 biggest(8,2) #&gt; [1] 1 Close Solution × Hint biggest &lt;- function(a, b) { if (a &gt; b) ___ return(0) } Close Hint Write a function biggest which takes two integers as arguments. Let the function return 1 if the first argument is larger than the second and return 0 otherwise. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } shipping_cost(450) #&gt; [1] 45 Close Solution × Hint shipping_cost &lt;- function(total) { return(___) } Close Hint Write a function that returns the shipping cost as 10% of the total cost of an order (input argument). × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } shipping_cost(450) #&gt; [1] 45 shipping_cost(450, pct = 0.2) #&gt; [1] 90 Close Solution × Hint shipping_cost &lt;- function(total, pct = ___) { ___ } Close Hint Given Question 5, rewrite the function so the percentage is an input argument with a default of 10%. × Solution shipping_cost &lt;- function(total) { return(0.1 * total) } gasoline_cost &lt;- function(total) { return(shipping_cost(total) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 Close Solution × Hint gasoline_cost &lt;- function(total) { return(shipping_cost(___) * ___) } Close Hint Given Question 5, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost as input argument and calculate the gasoline cost and use the function defined in Question 5 inside it. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } gasoline_cost(450) #&gt; [1] 22.5 gasoline_cost(450, pct = 0.2) #&gt; [1] 45 Close Solution × Hint gasoline_cost &lt;- function(total, ...) { return(shipping_cost(___) * ___) } Close Hint Given Question 6, the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost a input argument and calculate the gasoline cost and use the function defined in Question 6 inside it. Hint: Use the ... argument to pass arguments to shipping_cost. × Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = total, shipping = shipping_cost(total, ...), gasoline = gasoline_cost(total, ...)) return(lst) } costs(450) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 45 #&gt; #&gt; $gasoline #&gt; [1] 22.5 costs(450, pct = 0.15) #&gt; $total #&gt; [1] 450 #&gt; #&gt; $shipping #&gt; [1] 67.5 #&gt; #&gt; $gasoline #&gt; [1] 33.8 Close Solution × Hint shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = ___, shipping = ___, gasoline = ___) return(lst) } Close Hint Given Question 8, write a function costs that, given total cost, returns the total cost, shipping cost and gasoline cost. 12.8.2 Exercise (scope) × Solution That value is still 3 since x defined inside the function is a local variable. Close Solution After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 5 return(y + 5) } my_func(7) × Solution The code runs. But it is not good coding practice to call global variables inside a function (x). Instead x should have been an argument to the function. Close Solution Is there any problems with the following code? x &lt;- 3 my_func &lt;- function(y){ return(y + x) } my_func(7) × Solution That value is still 3 since my_func has not been called yet. Close Solution Have a look at the documentation for operator &lt;&lt;- (run ?'&lt;--'). After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + 5) } × Solution That value of x is 5 since &lt;&lt;- is used to look at the parent environment. The function call returns 11 since the x used is the local variable. In general avoid using &lt;&lt;- and give local variables different names compared to global ones. Close Solution After running the code below, what is the value of variable x and output of the function call? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + x) } my_func(7) 12.8.3 Exercise (job sequencing) Solve this exercise using a script file. This exercise is based on Exercise 6.12 in Wøhlk (2010). Consider a problem of determining the best sequencing of jobs on a machine. A set of startup costs are given for 5 machines: startup_costs &lt;- c(27, 28, 32, 35, 26) startup_costs #&gt; [1] 27 28 32 35 26 Moreover, when changing from one job to another job, the setup costs are given as: setup_costs &lt;- matrix(c( NA, 35, 22, 44, 12, 49, NA, 46, 38, 17, 46, 12, NA, 29, 41, 23, 37, 31, NA, 26, 17, 23, 28, 34, NA), byrow = T, nrow = 5) setup_costs #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA 35 22 44 12 #&gt; [2,] 49 NA 46 38 17 #&gt; [3,] 46 12 NA 29 41 #&gt; [4,] 23 37 31 NA 26 #&gt; [5,] 17 23 28 34 NA The goal of the problem is to determine a sequence of jobs which minimizes the total setup cost including the startup cost. One possible way to find a sequence is the use a greedy strategy: Greedy Algorithm Step 0: Start with the job which has minimal startup cost. Step 1: Select the next job as the job not already done with minimal setup cost given current job. Step 2: Set next job in Step 1 to current job and go to Step 1 if not all jobs are done. In R the greedy algorithm can be implemented as: greedy &lt;- function(startup, setup) { jobs &lt;- nrow(setup) cur_job &lt;- which.min(startup) cost &lt;- startup[cur_job] # cat(&quot;Start job:&quot;, cur_job, &quot;\\n&quot;) job_seq &lt;- cur_job setup[, cur_job] &lt;- NA for (i in 1:(jobs-1)) { next_job &lt;- which.min(setup[cur_job, ]) # cat(&quot;Next job:&quot;, next_job, &quot;\\n&quot;) cost &lt;- cost + setup[cur_job, next_job] job_seq &lt;- c(job_seq, next_job) cur_job &lt;- next_job setup[, cur_job] &lt;- NA } # print(setup) return(list(seq = job_seq, cost = cost)) } greedy(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 5 1 3 2 4 #&gt; #&gt; $cost #&gt; [1] 115 First, the job with minimum startup cost is found using function which.min and we define cost as the startup cost. We use cat to make some debugging statements and initialize job_seq with the first job. Next, we have to find a way of ignoring jobs already done. We do that here by setting the columns of setup cost equal to NA for jobs already done. Hence, they will not be selected by which.min. The for loop runs 4 times and selects jobs and accumulate the total cost. A well-known better strategy is to: Better Algorithm Step 0: Subtract minimum of startup and setup cost for each job from setup and startup costs (that is columnwise) Step 1: Call the greedy algorithm with the modified costs. Note that the total cost returned has to be modified a bit. × Solution better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(rbind(startup, setup), 2, min, na.rm = T) startup &lt;- startup - min_col_val min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = jobs, byrow = T) setup &lt;- setup - min_mat lst &lt;- greedy(startup, setup) lst$cost &lt;- lst$cost + sum(min_col_val) return(lst) } better(startup_costs, setup_costs) #&gt; $seq #&gt; [1] 4 1 3 2 5 #&gt; #&gt; $cost #&gt; [1] 109 Close Solution × Hint 2 better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(rbind(startup, setup), 2, min, na.rm = T) startup &lt;- startup - min_col_val min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = jobs, byrow = T) setup &lt;- setup - ___ lst &lt;- greedy(startup, setup) lst$cost &lt;- lst$cost + sum(___) return(lst) } better(startup_costs, setup_costs) Close Hint 2 × Hint 1 better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(___) startup &lt;- startup - ___ min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = ___, byrow = T) setup &lt;- setup - ___ lst &lt;- greedy(___, ___) lst$cost &lt;- lst$cost + ___ return(lst) } better(startup_costs, setup_costs) Close Hint 1 Implement a better function calculating a better strategy. Hint: to find the minimum column costs, you may use apply(rbind(startup, setup), 2, min, na.rm = T). References "],["sec-tidy-intro.html", "Module 13 Introduction to tidyverse and R Markdown 13.1 Learning outcomes 13.2 The tidyverse package 13.3 Writing reproducible reports 13.4 Tibbles 13.5 Different learning paths 13.6 Recap 13.7 Exercises", " Module 13 Introduction to tidyverse and R Markdown 13.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what the tidyverse package is. Explain the ideas behind reproducible reports and literal programming. Create your first R Markdown document and add some code and text. The learning outcomes relate to the overall learning goals number 7, 17 and 18 of the course. 13.2 The tidyverse package The tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The core tidyverse includes the packages that you are likely to use in everyday data analyses. In tidyverse 1.3.0, the following packages are included in the core tidyverse: dplyr provides a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges. We are going to use dplyr in Module 15. ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. We are going to use ggplot in Module 16. tidyr provides a set of functions that help you get to tidy data. Tidy data is data with a consistent form: in brief, every variable goes in a column, and every column is a variable. readr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes. We are going to use dplyr in Module 14. purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. Once you master the basic concepts, purrr allows you to replace many for loops with code that is easier to write and more expressive. This package is not covered in this course. tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what has not. Tibbles are data frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code. We are going to use tibbles in Module 15. stringr provides a cohesive set of functions designed to make working with strings as easy as possible. You have already worked a bit with stringr in Exercise 10.10.9 forcats provides a suite of useful tools that solve common problems with factors. R uses factors to handle categorical variables, variables that have a fixed and known set of possible values. This package is not covered in this course. Small introductions (with examples) to the packages are given on their documentation pages (follow the links above). The tidyverse also includes many other packages with more specialized usage. They are not loaded automatically with library(tidyverse), so you will need to load each one with its own call to library(). 13.3 Writing reproducible reports The concept of literate programming was originally introduced by Donald Knuth in 1984. In a nutshell, Knuth envisioned a new programming paradigm where computer scientists focus on weaving code together with text as documentation. That is, when we do an Analytics project, we are interested in writing reports containing both R code for importing data, wrangling and analysis. Moreover, at the same time, the document should contain our comments about the code, plots, analysis, results, etc. The document is then rendered to an output format such as html, pdf or Word which is presented to the decision maker. Note the document can be seen as the “the source code” for the report communicated to the decision maker. Some developers have created tools to enable others to write better literate programs. They use a markup language made for authoring. We are going to focus on R Markdown. In R Markdown documents you can weave R code together with text (written in Markdown) to produce elegantly formatted output. In fact this book is written in R Markdown by using a set of R Markdown documents bound together as a collection using the bookdown package, rendered to a web page using RStudio, shared on GitHub, built by GitHub Actions, and published on GitHub Pages. This may seem complicated at first. However, after setup, it makes life much easier, since we can update the book easier, share and collaborate on the book easier, update the web page automatically, keep history of the book source, keep the book source at a single location. R Markdown documents are reproducible. Anybody who works with data has at some point heard a colleague say ‘Well, it works on my computer’, expressing dismay at the fact that you cannot reproduce their results. Ultimately, reproducible means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. For instance, people may be using a different operating system, other versions of the software, etc. That is, there are different levels of reproducibility. In this course, we will focus on R Markdown only. See Section 13.5 for more info about levels of reproducibility. An introduction to R Markdown is given in Chapters 3 and 4 of the DataCamp course Communicating with Data in the Tidyverse. Note that you may skip Chapters 1 and 2 and still understand most of the questions in Chapters 3 and 4 (otherwise just see the solution). You are expected to have completed the chapters before continuing this module! 13.4 Tibbles Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Moreover, tibbles have an enhanced print method and can have columns that are lists. Let us see a few examples: tbl1 &lt;- tibble(name = c(&quot;Lars&quot;, &quot;Susan&quot;, &quot;Hans&quot;), age = c(23, 56, 45)) tbl1 #&gt; # A tibble: 3 × 2 #&gt; name age #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Lars 23 #&gt; 2 Susan 56 #&gt; 3 Hans 45 tbl2 &lt;- tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) tbl2 #&gt; # A tibble: 3 × 2 #&gt; x y #&gt; &lt;int&gt; &lt;list&gt; #&gt; 1 1 &lt;int [5]&gt; #&gt; 2 2 &lt;int [10]&gt; #&gt; 3 3 &lt;int [20]&gt; tbl3 &lt;- as_tibble(mtcars) tbl3 #&gt; # A tibble: 33 × 12 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 green #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 red #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 blue #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 green #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 blue #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 red #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 red #&gt; # … with 23 more rows tbl4 &lt;- tribble( ~x, ~y, ~z, #--|--|---- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) tbl4 #&gt; # A tibble: 2 × 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 2 3.6 #&gt; 2 b 1 8.5 Note that we can always coerce a data frame to a tibble (tbl3) or create it directly using tibble. Another way to create a tibble is with tribble. Here column headings are defined by formulas (i.e. they start with ~), and entries are separated by commas. This makes it possible to lay out small amounts of data in easy to read form. Tibbles have a refined print method that shows only the first 10 rows along with the number of columns that will fit on your screen. This makes it much easier to work with large data. In addition to its name, each column reports its type. Hence, your console is not overwhelmed with data. To see a full view of the data, you can use RStudio’s built-in data viewer: View(tbl3) 13.5 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Chapter 4 in Ismay and Kennedy (2019) gives an overview of R Markdown with videos included. You may also do the interactive DataCamp Reporting with R Markdown which is a bit longer than the suggested course. If Help &gt; Markdown Quick Reference not is enough, then try out this interactive markdown tutorial. The R Markdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. Glenn Moncrieff gives a nice detailed overview on how to create reproducible projects. If you are interested in trying Git and GitHub, see Bryan, STAT 545 TAs, and Hester (2020) for detailed help. All chunk options for R code can be seen here. An introduction to tibbles and differences to data frames is given in the video Working with tibbles in R by Hefin Rhys. Chapter 10 in H. Wickham (2017) gives an introduction to tibbles. 13.6 Recap tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. R Markdown is an example of literate programming. The core tidyverse includes the packages that you are likely to use in everyday data analyses. The concept of literate programming is a programming paradigm which focuses on weaving code together with text as documentation. That is, we are interested in writing reports containing both text and R code for importing data, wrangling and analysis. Reproducibility means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. That is, there are different levels of reproducibility. R Markdown documents are an attempt to make reproducible documents and combine R code and markdown text. Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. Tibbles have an enhanced print method and can have columns that are lists. 13.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 13.7.1 Exercise (your first R Markdown exercise) Load the tfa package: # remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;, upgrade = FALSE) # run to upgrade library(tfa) The package contains templates for exercises etc. Go to File &gt; New File &gt; R Markdown…. In the pop-up box select From template in the left column and then TFA Exercise. Press Ok and a new R Markdown document will be opened. Change the meta text (e.g. the title and add your name) in the yaml. Render/compile the document by pressing the Knit button (or Ctrl+Shift+K). × Solution All the code is now hidden. But not the output. Close Solution Change echo = TRUE to echo = FALSE in the first chunk setup and render the document. What has happened? You can easily go to a chunk using the navigation in the bottom left of the source window. Try to change fig.asp = 0.25 to e.g. 0.5 in Chunk 10. What happens? Create a new section ## Question 4 and add text in italic: What is the sum of all setup costs? × Solution total &lt;- sum(setup_costs) Close Solution Add a code chunk solving Question 5 above. × Solution The sum of all setup costs are ̀r total ̀. Close Solution Add a line of text with the result. 13.7.2 Exercise (tibbles) Solve this exercise using an R script file. × Solution airquality %&gt;% as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # … with 143 more rows Close Solution Convert the dataset airquality to a tibble. × Solution airquality %&gt;% as_tibble() #&gt; # A tibble: 153 × 6 #&gt; Ozone Solar.R Wind Temp Month Day #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; # … with 143 more rows airquality #&gt; Ozone Solar.R Wind Temp Month Day #&gt; 1 41 190 7.4 67 5 1 #&gt; 2 36 118 8.0 72 5 2 #&gt; 3 12 149 12.6 74 5 3 #&gt; 4 18 313 11.5 62 5 4 #&gt; 5 NA NA 14.3 56 5 5 #&gt; 6 28 NA 14.9 66 5 6 #&gt; 7 23 299 8.6 65 5 7 #&gt; 8 19 99 13.8 59 5 8 #&gt; 9 8 19 20.1 61 5 9 #&gt; 10 NA 194 8.6 69 5 10 #&gt; 11 7 NA 6.9 74 5 11 #&gt; 12 16 256 9.7 69 5 12 #&gt; 13 11 290 9.2 66 5 13 #&gt; 14 14 274 10.9 68 5 14 #&gt; 15 18 65 13.2 58 5 15 #&gt; 16 14 334 11.5 64 5 16 #&gt; 17 34 307 12.0 66 5 17 #&gt; 18 6 78 18.4 57 5 18 #&gt; 19 30 322 11.5 68 5 19 #&gt; 20 11 44 9.7 62 5 20 #&gt; 21 1 8 9.7 59 5 21 #&gt; 22 11 320 16.6 73 5 22 #&gt; 23 4 25 9.7 61 5 23 #&gt; 24 32 92 12.0 61 5 24 #&gt; 25 NA 66 16.6 57 5 25 #&gt; 26 NA 266 14.9 58 5 26 #&gt; 27 NA NA 8.0 57 5 27 #&gt; 28 23 13 12.0 67 5 28 #&gt; 29 45 252 14.9 81 5 29 #&gt; 30 115 223 5.7 79 5 30 #&gt; 31 37 279 7.4 76 5 31 #&gt; 32 NA 286 8.6 78 6 1 #&gt; 33 NA 287 9.7 74 6 2 #&gt; 34 NA 242 16.1 67 6 3 #&gt; 35 NA 186 9.2 84 6 4 #&gt; 36 NA 220 8.6 85 6 5 #&gt; 37 NA 264 14.3 79 6 6 #&gt; 38 29 127 9.7 82 6 7 #&gt; 39 NA 273 6.9 87 6 8 #&gt; 40 71 291 13.8 90 6 9 #&gt; 41 39 323 11.5 87 6 10 #&gt; 42 NA 259 10.9 93 6 11 #&gt; 43 NA 250 9.2 92 6 12 #&gt; 44 23 148 8.0 82 6 13 #&gt; 45 NA 332 13.8 80 6 14 #&gt; 46 NA 322 11.5 79 6 15 #&gt; 47 21 191 14.9 77 6 16 #&gt; 48 37 284 20.7 72 6 17 #&gt; 49 20 37 9.2 65 6 18 #&gt; 50 12 120 11.5 73 6 19 #&gt; 51 13 137 10.3 76 6 20 #&gt; 52 NA 150 6.3 77 6 21 #&gt; 53 NA 59 1.7 76 6 22 #&gt; 54 NA 91 4.6 76 6 23 #&gt; 55 NA 250 6.3 76 6 24 #&gt; 56 NA 135 8.0 75 6 25 #&gt; 57 NA 127 8.0 78 6 26 #&gt; 58 NA 47 10.3 73 6 27 #&gt; 59 NA 98 11.5 80 6 28 #&gt; 60 NA 31 14.9 77 6 29 #&gt; 61 NA 138 8.0 83 6 30 #&gt; 62 135 269 4.1 84 7 1 #&gt; 63 49 248 9.2 85 7 2 #&gt; 64 32 236 9.2 81 7 3 #&gt; 65 NA 101 10.9 84 7 4 #&gt; 66 64 175 4.6 83 7 5 #&gt; 67 40 314 10.9 83 7 6 #&gt; 68 77 276 5.1 88 7 7 #&gt; 69 97 267 6.3 92 7 8 #&gt; 70 97 272 5.7 92 7 9 #&gt; 71 85 175 7.4 89 7 10 #&gt; 72 NA 139 8.6 82 7 11 #&gt; 73 10 264 14.3 73 7 12 #&gt; 74 27 175 14.9 81 7 13 #&gt; 75 NA 291 14.9 91 7 14 #&gt; 76 7 48 14.3 80 7 15 #&gt; 77 48 260 6.9 81 7 16 #&gt; 78 35 274 10.3 82 7 17 #&gt; 79 61 285 6.3 84 7 18 #&gt; 80 79 187 5.1 87 7 19 #&gt; 81 63 220 11.5 85 7 20 #&gt; 82 16 7 6.9 74 7 21 #&gt; 83 NA 258 9.7 81 7 22 #&gt; 84 NA 295 11.5 82 7 23 #&gt; 85 80 294 8.6 86 7 24 #&gt; 86 108 223 8.0 85 7 25 #&gt; 87 20 81 8.6 82 7 26 #&gt; 88 52 82 12.0 86 7 27 #&gt; 89 82 213 7.4 88 7 28 #&gt; 90 50 275 7.4 86 7 29 #&gt; 91 64 253 7.4 83 7 30 #&gt; 92 59 254 9.2 81 7 31 #&gt; 93 39 83 6.9 81 8 1 #&gt; 94 9 24 13.8 81 8 2 #&gt; 95 16 77 7.4 82 8 3 #&gt; 96 78 NA 6.9 86 8 4 #&gt; 97 35 NA 7.4 85 8 5 #&gt; 98 66 NA 4.6 87 8 6 #&gt; 99 122 255 4.0 89 8 7 #&gt; 100 89 229 10.3 90 8 8 #&gt; 101 110 207 8.0 90 8 9 #&gt; 102 NA 222 8.6 92 8 10 #&gt; 103 NA 137 11.5 86 8 11 #&gt; 104 44 192 11.5 86 8 12 #&gt; 105 28 273 11.5 82 8 13 #&gt; 106 65 157 9.7 80 8 14 #&gt; 107 NA 64 11.5 79 8 15 #&gt; 108 22 71 10.3 77 8 16 #&gt; 109 59 51 6.3 79 8 17 #&gt; 110 23 115 7.4 76 8 18 #&gt; 111 31 244 10.9 78 8 19 #&gt; 112 44 190 10.3 78 8 20 #&gt; 113 21 259 15.5 77 8 21 #&gt; 114 9 36 14.3 72 8 22 #&gt; 115 NA 255 12.6 75 8 23 #&gt; 116 45 212 9.7 79 8 24 #&gt; 117 168 238 3.4 81 8 25 #&gt; 118 73 215 8.0 86 8 26 #&gt; 119 NA 153 5.7 88 8 27 #&gt; 120 76 203 9.7 97 8 28 #&gt; 121 118 225 2.3 94 8 29 #&gt; 122 84 237 6.3 96 8 30 #&gt; 123 85 188 6.3 94 8 31 #&gt; 124 96 167 6.9 91 9 1 #&gt; 125 78 197 5.1 92 9 2 #&gt; 126 73 183 2.8 93 9 3 #&gt; 127 91 189 4.6 93 9 4 #&gt; 128 47 95 7.4 87 9 5 #&gt; 129 32 92 15.5 84 9 6 #&gt; 130 20 252 10.9 80 9 7 #&gt; 131 23 220 10.3 78 9 8 #&gt; 132 21 230 10.9 75 9 9 #&gt; 133 24 259 9.7 73 9 10 #&gt; 134 44 236 14.9 81 9 11 #&gt; 135 21 259 15.5 76 9 12 #&gt; 136 28 238 6.3 77 9 13 #&gt; 137 9 24 10.9 71 9 14 #&gt; 138 13 112 11.5 71 9 15 #&gt; 139 46 237 6.9 78 9 16 #&gt; 140 18 224 13.8 67 9 17 #&gt; 141 13 27 10.3 76 9 18 #&gt; 142 24 238 10.3 68 9 19 #&gt; 143 16 201 8.0 82 9 20 #&gt; 144 13 238 12.6 64 9 21 #&gt; 145 23 14 9.2 71 9 22 #&gt; 146 36 139 10.3 81 9 23 #&gt; 147 7 49 10.3 69 9 24 #&gt; 148 14 20 16.6 63 9 25 #&gt; 149 30 193 6.9 70 9 26 #&gt; 150 NA 145 13.2 77 9 27 #&gt; 151 14 191 14.3 75 9 28 #&gt; 152 18 131 8.0 76 9 29 #&gt; 153 20 223 11.5 68 9 30 Close Solution Print the tibble and the original data frame and compare the difference. × Solution # here misc is a list with lists dat &lt;- tibble(name = c(&quot;Hans&quot;, &quot;Ole&quot;), age = c(23, 45), misc = list( list(status = 1, comment = &quot;To young&quot;), list(comment = &quot;Potential candidate&quot;))) dat #&gt; # A tibble: 2 × 3 #&gt; name age misc #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 Hans 23 &lt;named list [2]&gt; #&gt; 2 Ole 45 &lt;named list [1]&gt; dat$misc[[1]] #&gt; $status #&gt; [1] 1 #&gt; #&gt; $comment #&gt; [1] &quot;To young&quot; Close Solution Create a tibble with 3 columns of data type string/character, double and list. References "],["sec-io.html", "Module 14 Importing and exporting data 14.1 Learning outcomes 14.2 CSV files 14.3 Excel 14.4 Google Sheets 14.5 Text files 14.6 R’s native binary format 14.7 Json 14.8 Different learning paths 14.9 Recap 14.10 Exercises", " Module 14 Importing and exporting data For doing data driven analytics, you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. Moreover, after processing data, you often want to export or store some of the results. This module introduces you to different ways of importing and exporting data. 14.1 Learning outcomes By the end of this module, you are expected to be able to: Import and export csv files in different formats. Import and export data from Excel. Import and export data from Google Sheets. Write to a text file. Save data using R’s native format. Read and write to a json file. 14.2 CSV files CSV files contain comma separated values (csv) in plain text and are often named using the file suffix .csv. Each line of the file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The CSV file format is not fully standardized. Different delimiters may be used, fields may be surrounded by quotation marks, text may contain escape characters and the encoding of the file may not be known. Despite these problems, CSV files are commonly used since they are easy to exchange and read. We will use the readr package for reading and writing. An overview over the functions can be seen in the cheatsheet. 14.2.1 Reading a CSV file In general use the following functions read_csv: Read a file with delimiter ,. read_csv2: Read a file with delimiter ;. read_delim: Read a file with a delimiter set by you. 14.2.1.1 Reading an unknown CSV file For importing a CSV file properly, you need to know the delimiter, if the files has headers and the encoding. If you are not sure, you may have a look on the file by opening it in a text editor or try to read some lines: csv_file &lt;- system.file(&quot;extdata/mtcars.csv&quot;, package = &quot;readr&quot;) # csv file lines &lt;- read_lines(csv_file, n_max = 3) lines #&gt; [1] &quot;\\&quot;mpg\\&quot;,\\&quot;cyl\\&quot;,\\&quot;disp\\&quot;,\\&quot;hp\\&quot;,\\&quot;drat\\&quot;,\\&quot;wt\\&quot;,\\&quot;qsec\\&quot;,\\&quot;vs\\&quot;,\\&quot;am\\&quot;,\\&quot;gear\\&quot;,\\&quot;carb\\&quot;&quot; #&gt; [2] &quot;21,6,160,110,3.9,2.62,16.46,0,1,4,4&quot; #&gt; [3] &quot;21,6,160,110,3.9,2.875,17.02,0,1,4,4&quot; cat(lines, sep = &quot;\\n&quot;) #&gt; &quot;mpg&quot;,&quot;cyl&quot;,&quot;disp&quot;,&quot;hp&quot;,&quot;drat&quot;,&quot;wt&quot;,&quot;qsec&quot;,&quot;vs&quot;,&quot;am&quot;,&quot;gear&quot;,&quot;carb&quot; #&gt; 21,6,160,110,3.9,2.62,16.46,0,1,4,4 #&gt; 21,6,160,110,3.9,2.875,17.02,0,1,4,4 It seems that the delimiter is a , and we may try to read the file using read_csv: dat &lt;- read_csv(csv_file) head(dat) #&gt; # A tibble: 6 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Consider another example: csv_file &lt;- system.file(&quot;extdata/massey-rating.txt&quot;, package = &quot;readr&quot;) lines &lt;- read_lines(csv_file, n_max = 3) cat(lines, sep = &quot;\\n&quot;) #&gt; UCC PAY LAZ KPK RT COF BIH DII ENG ACU Rank Team Conf #&gt; 1 1 1 1 1 1 1 1 1 1 1 Ohio St B10 #&gt; 2 2 2 2 2 2 2 2 4 2 2 Oregon P12 Here it is harder to guess the delimiter. It could be a space or a tabulator. Let us try to read it assuming a space or tabulator: read_tsv(csv_file) # assume tabulator (\\t) #&gt; # A tibble: 10 × 1 #&gt; `UCC PAY LAZ KPK RT COF BIH DII ENG ACU Rank Team Conf` #&gt; &lt;chr&gt; #&gt; 1 1 1 1 1 1 1 1 1 1 1 1 Ohio St B10 #&gt; 2 2 2 2 2 2 2 2 2 4 2 2 Oregon P12 #&gt; 3 3 4 3 4 3 4 3 4 2 3 3 Alabama SEC #&gt; 4 4 3 4 3 4 3 5 3 3 4 4 TCU B12 #&gt; 5 6 6 6 5 5 7 6 5 6 11 5 Michigan St B10 #&gt; 6 7 7 7 6 7 6 11 8 7 8 6 Georgia SEC #&gt; 7 5 5 5 7 6 8 4 6 5 5 7 Florida St ACC #&gt; 8 8 8 9 9 10 5 7 7 10 7 8 Baylor B12 #&gt; 9 9 11 8 13 11 11 12 9 14 9 9 Georgia Tech ACC #&gt; 10 13 10 13 11 8 9 10 11 9 10 10 Mississippi SEC read_delim(csv_file, delim = &quot; &quot;, trim_ws = T) # assume space #&gt; # A tibble: 10 × 27 #&gt; UCC PAY LAZ KPK ...5 RT ...7 ...8 COF BIH DII ENG ACU Rank Team ...16 #&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 NA NA 1 NA NA 1 NA NA 1 NA NA 1 NA NA 1 NA #&gt; 2 NA NA 2 NA NA 2 NA NA 2 NA NA 2 NA NA 2 NA #&gt; 3 NA NA 3 NA NA 4 NA NA 3 NA NA 4 NA NA 3 NA #&gt; 4 NA NA 4 NA NA 3 NA NA 4 NA NA 3 NA NA 4 NA #&gt; 5 NA NA 6 NA NA 6 NA NA 6 NA NA 5 NA NA 5 NA #&gt; 6 NA NA 7 NA NA 7 NA NA 7 NA NA 6 NA NA 7 NA #&gt; 7 NA NA 5 NA NA 5 NA NA 5 NA NA 7 NA NA 6 NA #&gt; 8 NA NA 8 NA NA 8 NA NA 9 NA NA 9 NA 10 NA NA #&gt; 9 NA NA 9 NA 11 NA NA 8 NA 13 NA 11 NA NA NA 11 #&gt; 10 NA 13 NA 10 NA 13 NA 11 NA NA 8 NA NA NA NA 9 #&gt; # … with 11 more variables: ...17 &lt;lgl&gt;, ...18 &lt;dbl&gt;, ...19 &lt;dbl&gt;, ...20 &lt;dbl&gt;, ...21 &lt;dbl&gt;, #&gt; # ...22 &lt;dbl&gt;, ...23 &lt;dbl&gt;, ...24 &lt;lgl&gt;, ...25 &lt;dbl&gt;, ...26 &lt;dbl&gt;, Conf &lt;chr&gt; The first function puts all data in one column. The second function works even though we have some warnings. CSV files should always be saved using encoding UTF-8. However, sometimes you may have encoding problems when you read a file: csv_file &lt;- system.file(&quot;extdata/persons.csv&quot;, package = &quot;tfa&quot;) read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &quot;Hans&quot; &quot;S\\xf8gaard&quot; #&gt; 2 &quot;\\xc5ge&quot; &quot;\\xd8kse&quot; #&gt; 3 &quot;Yvette&quot; &quot;L\\xe6ske&quot; Note that some of the characters are not converted correctly. This is usually because the file encoding is not UTF-8. In this case, try to guess the encoding using: guess_encoding(csv_file) #&gt; # A tibble: 1 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ISO-8859-1 0.27 dat &lt;- read_csv(csv_file, locale = locale(encoding = &quot;ISO-8859-1&quot;)) dat #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske 14.2.2 Writing to CSV files Given a tibble/data frame export it using write_csv: csv_file &lt;- &quot;testing.csv&quot; write_csv(dat, path = csv_file) You can now always import the data again using read_csv: read_csv(csv_file) #&gt; # A tibble: 3 × 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske guess_encoding(csv_file) #&gt; # A tibble: 3 × 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 UTF-8 1 #&gt; 2 windows-1252 0.31 #&gt; 3 windows-1250 0.25 Note that write_csv always saves the file using encoding UTF-8. In a few cases, you may need to save a CSV file that can be read by Excel. For this purpose use: write_excel_csv2(dat, csv_file) The CSV file can now be opened correctly in Excel. 14.3 Excel There are different packages in R for reading and writing to Excel. We will use the readxl package for reading Excel files which is a part of tidyverse. The package supports both the legacy .xls format and the modern xml-based .xlsx format. Let us use one of the example files provided by the package: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;) It is always a good idea to have a look at the file before you import from it. You can open it from R by using: browseURL(xlsx_file) Data can be read using: library(readxl) xlsx &lt;- read_excel(xlsx_file) # reads the first sheet xlsx #&gt; # A tibble: 150 × 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # … with 140 more rows xlsx &lt;- read_excel(xlsx_file, sheet = 2) # reads the second sheet xlsx #&gt; # A tibble: 32 × 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # … with 22 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;quakes&quot;) # reads a named sheet xlsx #&gt; # A tibble: 1,000 × 5 #&gt; lat long depth mag stations #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -20.4 182. 562 4.8 41 #&gt; 2 -20.6 181. 650 4.2 15 #&gt; 3 -26 184. 42 5.4 43 #&gt; 4 -18.0 182. 626 4.1 19 #&gt; 5 -20.4 182. 649 4 11 #&gt; 6 -19.7 184. 195 4 12 #&gt; 7 -11.7 166. 82 4.8 43 #&gt; 8 -28.1 182. 194 4.4 15 #&gt; 9 -28.7 182. 211 4.7 35 #&gt; 10 -17.5 180. 622 4.3 19 #&gt; # … with 990 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A5:G11&quot;, col_names = F) # reads a range colnames(xlsx) &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A1:G1&quot;, col_names = F) # reads the column names xlsx #&gt; # A tibble: 7 × 7 #&gt; mpg cyl disp hp drat wt qsec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21.4 6 258 110 3.08 3.22 19.4 #&gt; 2 18.7 8 360 175 3.15 3.44 17.0 #&gt; 3 18.1 6 225 105 2.76 3.46 20.2 #&gt; 4 14.3 8 360 245 3.21 3.57 15.8 #&gt; 5 24.4 4 147. 62 3.69 3.19 20 #&gt; 6 22.8 4 141. 95 3.92 3.15 22.9 #&gt; 7 19.2 6 168. 123 3.92 3.44 18.3 Writing to an Excel file can be done using the openxlsx package. To write to a new file use: library(openxlsx) dat &lt;- trees # test dataset head(dat) #&gt; Girth Height Volume #&gt; 1 8.3 70 10.3 #&gt; 2 8.6 65 10.3 #&gt; 3 8.8 63 10.2 #&gt; 4 10.5 72 16.4 #&gt; 5 10.7 81 18.8 #&gt; 6 10.8 83 19.7 write.xlsx(dat, &quot;test1.xlsx&quot;, sheetName = &quot;trees&quot;) # start at cell A1 write.xlsx(dat, &quot;test2.xlsx&quot;, sheetName = &quot;trees&quot;, startCol = &quot;C&quot;, startRow = 3) If you want to append a sheet to a file use: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;tfa&quot;) file.copy(xlsx_file, &quot;test.xlsx&quot;) # copy the file so can make some tests #&gt; [1] TRUE wb &lt;- loadWorkbook(file = &quot;test.xlsx&quot;) # read the workbook addWorksheet(wb = wb, sheetName = &quot;trees&quot;) writeData(wb, sheet = &quot;trees&quot;, x = dat) saveWorkbook(wb, file = &quot;test.xlsx&quot;, overwrite = TRUE) 14.4 Google Sheets You can import and export to Google sheets using the googlesheets4 package in tidyverse. To read and write data, in general, you need to be logged in as a Google user. The package will ask you when needed. However, if you only want to read data from a public sheet, you can use gs4_deauth to skip this: library(googlesheets4) gs4_deauth() To read data use: url &lt;- &quot;https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077&quot; read_sheet(url) read_sheet(url, sheet = 3) range_read(url, sheet = 2, n_max = 3) range_read(url, range = &quot;Africa!A5:C15&quot;) To write data to a new file use: gs4_auth() gs &lt;- gs4_create(&quot;test&quot;, sheets = c(&quot;Sheet 1&quot;, &quot;Sheet 2&quot;)) write_sheet(dat, ss = gs) range_write(gs, dat, sheet = &quot;Sheet 1&quot;, range = &quot;C4&quot;) gs4_browse(gs) # have a look at the file in a browser To see the results, have a look at your Google sheet test in your browser. 14.5 Text files You can read and write to plain text files using the readr package. However, mostly you want to write to a text file because you want to save some kind of log file when you run your script. Here sink is an excellent function to use, since it redirects your R output. To see the output without messages, errors and warnings use: sink(file = &quot;ex1.log&quot;, split = TRUE) # open the file for output cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file again # file.show(&quot;ex1.log&quot;) # to view in external viewer Let us have a look at the content of the file (run cat(read_file(\"ex1.log\"))): This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 [1] 1 1 1 1 Last line Note that messages, errors and warnings are not included in the output. If you want to include it use: zz &lt;- file(&quot;ex2.log&quot;, open = &quot;wt&quot;) sink(zz, type = &quot;output&quot;) # open the file for output sink(zz, type = &quot;message&quot;) # open the same file for messages, errors and warnings cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file for output sink() # close the file for messages, errors and warnings That is, we call sink two times. Let us have a look at the content of the file: This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 [1] 1 1 1 1 A message. Advarselsbesked: A warning. Fejl: objekt &#39;f&#39; blev ikke fundet Last line 14.6 R’s native binary format In general, we can differ between two main types of data/files. Information is either binary encoded (basically just 0’s and 1’s) or stored as text files. What we have considered so far is storing data in text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Furthermore, binary formats may be difficult to read and write using other programs. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which is optimized for speed and compression ratios. To save and read an R object use: dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = mtcars) saveRDS(dat, file = &quot;test.rds&quot;) readRDS(&quot;test.rds&quot;) #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 red #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 blue #&gt; Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 green #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 blue #&gt; Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 red #&gt; Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 red #&gt; Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 blue #&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 green #&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 blue #&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 blue #&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 green #&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 red #&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 red #&gt; Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 &lt;NA&gt; #&gt; Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 &lt;NA&gt; #&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 red #&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 green #&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 red #&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 red #&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 &lt;NA&gt; #&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 green #&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 &lt;NA&gt; #&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 blue #&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 green #&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 green #&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 red #&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 green #&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 blue #&gt; Phantom XE 34.0 3 87.0 112 4.50 1.51 167.0 1 1 5 3 &lt;NA&gt; Note we here have saved a non tabular R object (a list). 14.7 Json JavaScript Object Notation (json) is an open standard text file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It can be used to store non tabular data in text format. It is often used for data-exchange in web-apis. Let us try to read and write to a json file using the jsonlite package. library(jsonlite) dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = head(mtcars)) write_json(dat, &quot;test.json&quot;, pretty = T) lst &lt;- read_json(&quot;test.json&quot;, simplifyDataFrame = T, simplifyVector = T) lst #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 red #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 blue The content of the json file look likes: { &quot;x&quot;: [2, 5, 6], &quot;y&quot;: [&quot;A string&quot;], &quot;z&quot;: [ { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.62, &quot;qsec&quot;: 16.46, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4&quot; }, { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.875, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;col&quot;: &quot;green&quot;, &quot;_row&quot;: &quot;Mazda RX4 Wag&quot; }, { &quot;mpg&quot;: 22.8, &quot;cyl&quot;: 4, &quot;disp&quot;: 108, &quot;hp&quot;: 93, &quot;drat&quot;: 3.85, &quot;wt&quot;: 2.32, &quot;qsec&quot;: 18.61, &quot;vs&quot;: 1, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 1, &quot;col&quot;: &quot;blue&quot;, &quot;_row&quot;: &quot;Datsun 710&quot; }, { &quot;mpg&quot;: 21.4, &quot;cyl&quot;: 6, &quot;disp&quot;: 258, &quot;hp&quot;: 110, &quot;drat&quot;: 3.08, &quot;wt&quot;: 3.215, &quot;qsec&quot;: 19.44, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;col&quot;: &quot;red&quot;, &quot;_row&quot;: &quot;Hornet 4 Drive&quot; }, { &quot;mpg&quot;: 18.7, &quot;cyl&quot;: 8, &quot;disp&quot;: 360, &quot;hp&quot;: 175, &quot;drat&quot;: 3.15, &quot;wt&quot;: 3.44, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 2, &quot;_row&quot;: &quot;Hornet Sportabout&quot; }, { &quot;mpg&quot;: 18.1, &quot;cyl&quot;: 6, &quot;disp&quot;: 225, &quot;hp&quot;: 105, &quot;drat&quot;: 2.76, &quot;wt&quot;: 3.46, &quot;qsec&quot;: 20.22, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;col&quot;: &quot;blue&quot;, &quot;_row&quot;: &quot;Valiant&quot; } ] } 14.8 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Chapter 5 in Irizarry (2020) gives an alternative introduction to importing data. 14.9 Recap For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. CSV files contain delimiter separated values in plain text and are often named using the file suffix .csv. Each line of a csv file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The readxl package can be used to read Excel files. Writing to an Excel file can be done using the openxlsx package. You can import and export to Google sheets using the googlesheets4 package in tidyverse. Use sink to save output of you R script. There are two main types of data files. Information is either binary encoded or stored as text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Moreover they can be used to save non tabular data. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimized for speed and compression ratios. Json is an open standard text file format, and data interchange format. It can be used to store non tabular data in text format. It is often used for data-exchange in web-api’s. 14.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 14.10.1 Exercise (Statistikbanken) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). You can use the API from Statistikbanken to download a lot of data sets. Let us consider airports in Denmark (data set with table id FLYV41): url &lt;- &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&quot; Use cat(read_lines(url, n_max = 3), sep = \"\\n\") to have a look at the delimiter used. × Solution url &lt;- &#39;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&#39; dat &lt;- read_csv2(url) dat Close Solution Import the csv file. Try to retrieve information and get an overview over the data by running: library(jsonlite) url &lt;- &quot;https://api.statbank.dk/v1/tableinfo/FLYV41?lang=en&quot; lst &lt;- read_json(url, simplifyVector = T) View(lst) Note the data returned is in json format, so we use read_json to read the data into a list. × Solution info &lt;- function(tab_id) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) return(list(description = lst$description, unit = lst$unit, variables = lst$variables[,1:2])) } info(&quot;FLYV41&quot;) Close Solution × Hint 2 info &lt;- function(tab_id) { url &lt;- str_c(___) lst &lt;- read_json(___) return(list(description = lst$___, unit = ___, ___)) } info(&quot;FLYV41&quot;) Close Hint 2 × Hint 1 You can modify the code in Question 3 to return only parts of the list. Close Hint 1 Create a function info(tab_id) that returns a list with components description, unit and variables from the information for a data set with table id tab_id. Information about all the data sets can be retrieved using: url &lt;- &quot;https://api.statbank.dk/v1/tables?lang=en&quot; lst &lt;- jsonlite::read_json(url, simplifyVector = T) View(lst) Have a look at the row for FLYV41. × Solution get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() dat &lt;- read_csv2(url) return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Solution × Hint get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- ___ lst &lt;- ___ cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[___] url &lt;- ___ dat &lt;- ___ return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Hint Given the information about variables in a data set we can construct the url to retrieve the data in csv format: tab_id &lt;- &quot;FLYV41&quot; url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) col_id &lt;- c(1,3) # column ids in lst$variables$id cols &lt;- lst$variables$id[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() url #&gt; [1] &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&quot; Create a function get_data(tab_id, col_id) that retrieve a data set. × Solution dat &lt;- get_data(&quot;FOLK1A&quot;, c(2, 3, 5)) dat write_csv(dat, &quot;test.csv&quot;) Close Solution Use the function get_data to retrieve data for tab_id = \"FOLK1A\" and col_id = c(2, 3, 5) and save it as a csv file with a comma as delimiter. × Solution library(openxlsx) write.xlsx(dat, &quot;test.xlsx&quot;, sheetName = &quot;FOLK1A&quot;) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(dat, ss = gs, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Solution × Hint library(openxlsx) write.xlsx(___) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(___, ss = ___, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Hint Save the data in an Excel file and a Google sheet. 14.10.2 Exercise (tuples in OPL) In the algebraic modeling language OPL (Optimization Programming Language) used by IBM ILOG CPLEX Optimization Studio, you can define tuples to contain various information. For example consider tuples defined as: tuple nurse { string name; int experience; // higest best } tuple shift { string departmentName; string day; int startTime; int endTime; } A nurse tuple is then defined as &lt;\"Anne\", 11&gt; and a shift tuple as `&lt;“Consultation”, “Monday” 12, 18&gt;. A set of tuples can be defined using: {nurse} nurses = ...; {shift} shifts = ...; where the ... operator means that the sets are read from a data text file: nurses = { &lt;&quot;Anne&quot;, 11&gt;, &lt;&quot;Bethanie&quot;, 4&gt;, &lt;&quot;Betsy&quot;, 2&gt; }; shifts = { &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, &lt;&quot;Emergency&quot;, Monday 8 12 4 7&gt;, &lt;&quot;Emergency&quot;, &quot;Monday&quot; 12 18 2 5&gt; }; You can now use the sets to define decision variables \\(x_{ns}\\) equal one if nurse \\(n\\) is assigned to shift \\(s\\). In this exercise we will try to generate the data text file given tibbles with data. × Solution file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(&#39; &lt;&quot;Anne&quot;, 11&gt;&#39;, file, append = TRUE) write_lines(&#39;};&#39;, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt; #&gt; }; Close Solution × Hint file = &quot;test.dat&quot; write_lines(&quot;nurses = {&quot;, file) write_lines(___, ___, append = TRUE) write_lines(___, ___, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint Try to generate a text file named test.dat using function write_lines with content nurses = { &lt;&quot;Anne&quot;, 11&gt; }; Load datasets remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;, dependencies = FALSE) #&gt; checking for file ‘/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/Rtmptt6Kn0/remotes88711eb1f34d/bss-osca-tfa-7ac06e9/tfa-package/DESCRIPTION’ ... ✔ checking for file ‘/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/Rtmptt6Kn0/remotes88711eb1f34d/bss-osca-tfa-7ac06e9/tfa-package/DESCRIPTION’ #&gt; ─ preparing ‘tfa’: #&gt; checking DESCRIPTION meta-information ... ✔ checking DESCRIPTION meta-information #&gt; ─ checking for LF line-endings in source and make files and shell scripts #&gt; ─ checking for empty or unneeded directories #&gt; ─ building ‘tfa_0.5.4.tar.gz’ #&gt; #&gt; library(tidyverse) nurses &lt;- read_csv(system.file(&quot;extdata/nurses.csv&quot;, package = &quot;tfa&quot;)) shifts &lt;- read_csv(system.file(&quot;extdata/shifts.csv&quot;, package = &quot;tfa&quot;)) × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) #&gt; # A tibble: 32 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows Close Solution × Hint 2 nurses %&gt;% mutate(across(where(___), ~str_c(&#39;___&#39;, .x, &#39;___&#39;))) Close Hint 2 × Hint 1 v &lt;- c(&quot;foo&quot;, &quot;bar&quot;) str_c(&#39;&quot;&#39;, v, &#39;&quot;&#39;) # use of str_c to add &quot; #&gt; [1] &quot;\\&quot;foo\\&quot;&quot; &quot;\\&quot;bar\\&quot;&quot; str_c(v, collapse = &quot;, &quot;) # collapsing a vector #&gt; [1] &quot;foo, bar&quot; tbl &lt;- tribble( ~name, ~experience, &quot;Anne&quot;, 11, &quot;Bethanie&quot;, 4 ) tbl #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Anne 11 #&gt; 2 Bethanie 4 tbl %&gt;% mutate(across(where(is.character), # use across to find all character columns ~str_c(&#39;(&#39;, .x, &#39;)&#39;))) # str_c is applied to each column where .x is the column values #&gt; # A tibble: 2 × 2 #&gt; name experience #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 (Anne) 11 #&gt; 2 (Bethanie) 4 Close Hint 1 Transform all character columns in nurses so they start and end with \". Some hints are given in Hint 1. × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;\\&quot;Anne\\&quot;, 11&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;\\&quot;Bethanie\\&quot;, 4&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;\\&quot;Betsy\\&quot;, 2&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;\\&quot;Cathy\\&quot;, 2&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;\\&quot;Cecilia\\&quot;, 9&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;\\&quot;Chris\\&quot;, 11&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;\\&quot;Cindy\\&quot;, 5&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;\\&quot;David\\&quot;, 1&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;\\&quot;Debbie\\&quot;, 7&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;\\&quot;Dee\\&quot;, 3&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = ___, remove = ___) Close Hint Unite all columns into a new column named tuple where each column is separated with ,. Hint: have a look at the unite function. All columns can be selected using everything(). × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) #&gt; # A tibble: 32 × 3 #&gt; tuple name experience #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;&quot; &quot;\\&quot;Anne\\&quot;&quot; 11 #&gt; 2 &quot;&lt;\\&quot;Bethanie\\&quot;, 4&gt;&quot; &quot;\\&quot;Bethanie\\&quot;&quot; 4 #&gt; 3 &quot;&lt;\\&quot;Betsy\\&quot;, 2&gt;&quot; &quot;\\&quot;Betsy\\&quot;&quot; 2 #&gt; 4 &quot;&lt;\\&quot;Cathy\\&quot;, 2&gt;&quot; &quot;\\&quot;Cathy\\&quot;&quot; 2 #&gt; 5 &quot;&lt;\\&quot;Cecilia\\&quot;, 9&gt;&quot; &quot;\\&quot;Cecilia\\&quot;&quot; 9 #&gt; 6 &quot;&lt;\\&quot;Chris\\&quot;, 11&gt;&quot; &quot;\\&quot;Chris\\&quot;&quot; 11 #&gt; 7 &quot;&lt;\\&quot;Cindy\\&quot;, 5&gt;&quot; &quot;\\&quot;Cindy\\&quot;&quot; 5 #&gt; 8 &quot;&lt;\\&quot;David\\&quot;, 1&gt;&quot; &quot;\\&quot;David\\&quot;&quot; 1 #&gt; 9 &quot;&lt;\\&quot;Debbie\\&quot;, 7&gt;&quot; &quot;\\&quot;Debbie\\&quot;&quot; 7 #&gt; 10 &quot;&lt;\\&quot;Dee\\&quot;, 3&gt;&quot; &quot;\\&quot;Dee\\&quot;&quot; 3 #&gt; # … with 22 more rows Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(___, tuple, ___)) Close Hint Add &lt; and &gt; the start and end of the tuple column. × Solution nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n&quot;) #&gt; [1] &quot;&lt;\\&quot;Anne\\&quot;, 11&gt;,\\n&lt;\\&quot;Bethanie\\&quot;, 4&gt;,\\n&lt;\\&quot;Betsy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cathy\\&quot;, 2&gt;,\\n&lt;\\&quot;Cecilia\\&quot;, 9&gt;,\\n&lt;\\&quot;Chris\\&quot;, 11&gt;,\\n&lt;\\&quot;Cindy\\&quot;, 5&gt;,\\n&lt;\\&quot;David\\&quot;, 1&gt;,\\n&lt;\\&quot;Debbie\\&quot;, 7&gt;,\\n&lt;\\&quot;Dee\\&quot;, 3&gt;,\\n&lt;\\&quot;Gloria\\&quot;, 8&gt;,\\n&lt;\\&quot;Isabelle\\&quot;, 3&gt;,\\n&lt;\\&quot;Jane\\&quot;, 3&gt;,\\n&lt;\\&quot;Janelle\\&quot;, 4&gt;,\\n&lt;\\&quot;Janice\\&quot;, 2&gt;,\\n&lt;\\&quot;Jemma\\&quot;, 2&gt;,\\n&lt;\\&quot;Joan\\&quot;, 5&gt;,\\n&lt;\\&quot;Joyce\\&quot;, 8&gt;,\\n&lt;\\&quot;Jude\\&quot;, 4&gt;,\\n&lt;\\&quot;Julie\\&quot;, 6&gt;,\\n&lt;\\&quot;Juliet\\&quot;, 7&gt;,\\n&lt;\\&quot;Kate\\&quot;, 5&gt;,\\n&lt;\\&quot;Nancy\\&quot;, 8&gt;,\\n&lt;\\&quot;Nathalie\\&quot;, 9&gt;,\\n&lt;\\&quot;Nicole\\&quot;, 0&gt;,\\n&lt;\\&quot;Patricia\\&quot;, 1&gt;,\\n&lt;\\&quot;Patrick\\&quot;, 6&gt;,\\n&lt;\\&quot;Roberta\\&quot;, 3&gt;,\\n&lt;\\&quot;Suzanne\\&quot;, 5&gt;,\\n&lt;\\&quot;Vickie\\&quot;, 7&gt;,\\n&lt;\\&quot;Wendie\\&quot;, 5&gt;,\\n&lt;\\&quot;Zoe\\&quot;, 8&gt;&quot; Close Solution × Hint nurses %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(___) %&gt;% str_c(___) Close Hint Extract the tuple column and transform it into a string with collapse = \",\\n\". × Solution write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; Close Solution × Hint 2 write_tuple &lt;- function(dat, file) { write_lines(&quot;nurses = {&quot;, file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% ___ write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 2 × Hint 1 write_tuple &lt;- function(dat, file) { write_lines(___) ___ write_lines(&quot;};&quot;, ___, ___) } file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) cat(read_file(&quot;test.dat&quot;)) # to have a look Close Hint 1 Create a function write_tuple that takes nurses as input and write the tuples to a file. The name of an object can be extracted as a string using deparse(substitute(nurses)) #&gt; [1] &quot;nurses&quot; × Solution write_tuple &lt;- function(dat, file) { name &lt;- deparse(substitute(dat)) write_lines(str_c(name, &quot; = {&quot;), file, sep = &quot;\\n &quot;) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } file &lt;- &quot;test.dat&quot; write_tuple(shifts, file) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Modify write_tuple so it works if shifts are given as input instead of nurses. × Solution write_tuple &lt;- function(dat, file, append = FALSE) { name &lt;- deparse(substitute(dat)) write_lines(str_c(&quot;\\n&quot;, name, &quot; = {&quot;), file, sep = &quot;\\n &quot;, append = append) tuples &lt;- dat %&gt;% mutate(across(where(is.character), ~str_c(&#39;&quot;&#39;, .x, &#39;&quot;&#39;))) %&gt;% unite(&quot;tuple&quot;, everything(), sep = &quot;, &quot;, remove = FALSE) %&gt;% mutate(tuple = str_c(&quot;&lt;&quot;, tuple, &quot;&gt;&quot;)) %&gt;% pull(tuple) %&gt;% str_c(collapse = &quot;,\\n &quot;) write_lines(tuples, file, append = TRUE) write_lines(&quot;};&quot;, file, append = TRUE) } Close Solution Modify write_tuple with a new input argument append which is false by default. If true, then then the file is not overwritten. × Solution file &lt;- &quot;test.dat&quot; write_tuple(nurses, file) write_tuple(shifts, file, append = TRUE) cat(read_file(&quot;test.dat&quot;)) # to have a look #&gt; #&gt; nurses = { #&gt; &lt;&quot;Anne&quot;, 11&gt;, #&gt; &lt;&quot;Bethanie&quot;, 4&gt;, #&gt; &lt;&quot;Betsy&quot;, 2&gt;, #&gt; &lt;&quot;Cathy&quot;, 2&gt;, #&gt; &lt;&quot;Cecilia&quot;, 9&gt;, #&gt; &lt;&quot;Chris&quot;, 11&gt;, #&gt; &lt;&quot;Cindy&quot;, 5&gt;, #&gt; &lt;&quot;David&quot;, 1&gt;, #&gt; &lt;&quot;Debbie&quot;, 7&gt;, #&gt; &lt;&quot;Dee&quot;, 3&gt;, #&gt; &lt;&quot;Gloria&quot;, 8&gt;, #&gt; &lt;&quot;Isabelle&quot;, 3&gt;, #&gt; &lt;&quot;Jane&quot;, 3&gt;, #&gt; &lt;&quot;Janelle&quot;, 4&gt;, #&gt; &lt;&quot;Janice&quot;, 2&gt;, #&gt; &lt;&quot;Jemma&quot;, 2&gt;, #&gt; &lt;&quot;Joan&quot;, 5&gt;, #&gt; &lt;&quot;Joyce&quot;, 8&gt;, #&gt; &lt;&quot;Jude&quot;, 4&gt;, #&gt; &lt;&quot;Julie&quot;, 6&gt;, #&gt; &lt;&quot;Juliet&quot;, 7&gt;, #&gt; &lt;&quot;Kate&quot;, 5&gt;, #&gt; &lt;&quot;Nancy&quot;, 8&gt;, #&gt; &lt;&quot;Nathalie&quot;, 9&gt;, #&gt; &lt;&quot;Nicole&quot;, 0&gt;, #&gt; &lt;&quot;Patricia&quot;, 1&gt;, #&gt; &lt;&quot;Patrick&quot;, 6&gt;, #&gt; &lt;&quot;Roberta&quot;, 3&gt;, #&gt; &lt;&quot;Suzanne&quot;, 5&gt;, #&gt; &lt;&quot;Vickie&quot;, 7&gt;, #&gt; &lt;&quot;Wendie&quot;, 5&gt;, #&gt; &lt;&quot;Zoe&quot;, 8&gt; #&gt; }; #&gt; #&gt; shifts = { #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Monday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Monday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Tuesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Tuesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Wednesday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Wednesday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Thursday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Thursday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 2, 8&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Friday&quot;, 18, 2&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 8, 12&gt;, #&gt; &lt;&quot;Consultation&quot;, &quot;Friday&quot;, 12, 18&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Saturday&quot;, 20, 2&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 2, 12&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 12, 20&gt;, #&gt; &lt;&quot;Emergency&quot;, &quot;Sunday&quot;, 20, 2&gt; #&gt; }; Close Solution Write nurses and shifts to a single data file. References "],["sec-transform.html", "Module 15 Transforming data 15.1 Learning outcomes 15.2 Working with data in the tidyverse 15.3 Mutating and filtering joins 15.4 Different learning paths 15.5 Recap 15.6 Exercises", " Module 15 Transforming data In this module, we consider transformation of data. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. This is done using a tibble (data frame) where each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Given a raw dataset the first step is to clean it and and transform it to a tidy format. Given tidy data, you next often need to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. In this chapter, you will learn how to work with tibbles using the dplyr package which is a part of the tidyverse. 15.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what tidy and wangling is. Apply the most common string functions. Apply tidy operations to data. Transform data. Clean data. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 15.2 Working with data in the tidyverse An excellent introduction on how to transform data using the tidyverse is given in the interactive DataCamp course Data Manipulation with dplyr. Please complete the course before continuing. 15.3 Mutating and filtering joins Mutating joins allow you to combine variables from multiple tables. There are four types of mutating join, which differ in their behavior when a match is not found. We’ll illustrate each with a simple example: df1 &lt;- tibble(x = c(1, 2), y = 2:1) df2 &lt;- tibble(x = c(3, 1), a = 10, b = &quot;a&quot;) df1 #&gt; # A tibble: 2 × 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 2 #&gt; 2 2 1 df2 #&gt; # A tibble: 2 × 3 #&gt; x a b #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 10 a #&gt; 2 1 10 a Note that column x is present in both tables and used when joining them. inner_join(df1, df2) only includes observations that match in both df1 and df2. df1 %&gt;% inner_join(df2) #&gt; # A tibble: 1 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a left_join(df1, df2) includes all observations in df1, regardless of whether they match or not. This is the most commonly used join because it ensures that you don’t lose observations from your primary table. df1 %&gt;% left_join(df2) #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; right_join(df1, df2) includes all observations in df2. It’s equivalent to left_join(df2, df1), but the columns and rows will be ordered differently. df1 %&gt;% right_join(df2) #&gt; # A tibble: 2 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 3 NA 10 a df2 %&gt;% left_join(df1) #&gt; # A tibble: 2 × 4 #&gt; x a b y #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 3 10 a NA #&gt; 2 1 10 a 2 full_join() includes all observations from df1 and df2. df1 %&gt;% full_join(df2) #&gt; # A tibble: 3 × 4 #&gt; x y a b #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 10 a #&gt; 2 2 1 NA &lt;NA&gt; #&gt; 3 3 NA 10 a The left, right and full joins are collectively know as outer joins. When a row doesn’t match in an outer join, the new variables are filled in with missing values. While mutating joins are primarily used to add new variables, they can also generate new observations. If a match is not unique, a join will add all possible combinations (the Cartesian product) of the matching observations: df1 &lt;- tibble(x = c(1, 1, 2), y = 1:3) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) df1 %&gt;% left_join(df2) #&gt; # A tibble: 5 × 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 1 a #&gt; 2 1 1 b #&gt; 3 1 2 a #&gt; 4 1 2 b #&gt; 5 2 3 a Filtering joins match observations in the same way as mutating joins, but affect the observations, not the variables. There are two types: semi_join(df1, df2) keeps all observations in df1 that have a match in df2. anti_join(df1, df2) drops all observations in df1 that have a match in df2. These are most useful for diagnosing join mismatches. If you’re worried about what observations your joins will match, start with a semi_join() or anti_join(). semi_join() and anti_join() never duplicate; they only remove observations. df1 &lt;- tibble(x = c(1, 1, 3, 4), y = 1:4) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) # Four rows to start with: df1 %&gt;% nrow() #&gt; [1] 4 # And we get four rows after the join df1 %&gt;% inner_join(df2, by = &quot;x&quot;) %&gt;% nrow() #&gt; [1] 4 # But only two rows actually match df1 %&gt;% semi_join(df2, by = &quot;x&quot;) %&gt;% nrow() #&gt; [1] 2 15.4 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! Roger Peng provides a good video giving an Introduction to the dplyr R package. Chapter 12 in Peng (2018) provides a nice introduction to dplyr. An alternative interactive DataCamp course is Working with Data in the Tidyverse which may be good to take if you need more training. The ‘Data transformation with dplyr’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. 15.5 Recap We consider transformation of tidy data where data are stored using a tibble (data frame) where each column is a variable, and each row is an observation/case. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The package dplyr provides a consistent set of verbs that helps you solve the most common data manipulation challenges: The filter function chooses rows (cases/observations) that meet a specific criteria. The select function chooses columns (variables) based on their names. The arrange function reorders the rows. The transmute function adds/modifies columns (variables) and drops existing ones. The mutate function adds/modifies columns (variables). The group_by function groups variables for groupwise operations. The ungroup function removes the current grouping. The count function counts rows based on a grouping. The summarise function reduces multiple values down to a single summary. The distinct function selects unique/distinct rows. The pull function can be used to extract columns as vectors (it is similar to $). Some nice to know functions to use inside e.g. summarise or mutate are The n() function counts the number of rows in a group. The n_distinct counts the number of unique rows in a group. The first function considers the first row in a group (remember to order it as needed). The slice_min and slice_max functions select rows with highest or lowest values of a variable. The across function makes it easy to apply the same transformation to multiple columns. Use print(n = Inf) in a pipe to print all rows. Use the pipe operator %&gt;% to connect operations. Use functions glimpse, tail, head, View to have a look at the data. The skim function in the skimr package provides an approach to summary statistics. Use as.character, as.numeric, etc. to convert data to a different type. Use nrow and ncol functions to get the number of rows and columns of the data. 15.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 15.6.1 Exercise (gapminder) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The gapminder data set provides values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007 for 142 countries. The data can be loaded using the gapminder package: library(gapminder) gapminder #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows Let us try to examine the dataset (use pipes %&gt;% as much as possible). × Solution gapminder %&gt;% glimpse() #&gt; Rows: 1,704 #&gt; Columns: 6 #&gt; $ country &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afgh… #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Europe, … #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007, 1952, 19… #&gt; $ lifeExp &lt;dbl&gt; 28.8, 30.3, 32.0, 34.0, 36.1, 38.4, 39.9, 40.8, 41.7, 41.8, 42.1, 43.8, 55.2, 59… #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12881816, 13867957, 16… #&gt; $ gdpPercap &lt;dbl&gt; 779, 821, 853, 836, 740, 786, 978, 852, 649, 635, 727, 975, 1601, 1942, 2313, 27… gapminder %&gt;% summary() #&gt; country continent year lifeExp pop #&gt; Afghanistan: 12 Africa :624 Min. :1952 Min. :23.6 Min. :6.00e+04 #&gt; Albania : 12 Americas:300 1st Qu.:1966 1st Qu.:48.2 1st Qu.:2.79e+06 #&gt; Algeria : 12 Asia :396 Median :1980 Median :60.7 Median :7.02e+06 #&gt; Angola : 12 Europe :360 Mean :1980 Mean :59.5 Mean :2.96e+07 #&gt; Argentina : 12 Oceania : 24 3rd Qu.:1993 3rd Qu.:70.8 3rd Qu.:1.96e+07 #&gt; Australia : 12 Max. :2007 Max. :82.6 Max. :1.32e+09 #&gt; (Other) :1632 #&gt; gdpPercap #&gt; Min. : 241 #&gt; 1st Qu.: 1202 #&gt; Median : 3532 #&gt; Mean : 7215 #&gt; 3rd Qu.: 9325 #&gt; Max. :113523 #&gt; gapminder %&gt;% tail() #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zimbabwe Africa 1982 60.4 7636524 789. #&gt; 2 Zimbabwe Africa 1987 62.4 9216418 706. #&gt; 3 Zimbabwe Africa 1992 60.4 10704340 693. #&gt; 4 Zimbabwe Africa 1997 46.8 11404948 792. #&gt; 5 Zimbabwe Africa 2002 40.0 11926563 672. #&gt; 6 Zimbabwe Africa 2007 43.5 12311143 470. Close Solution Use glimpse, summary and tail to examine the data. Use count to count the number of × Solution gapminder %&gt;% count(country) %&gt;% nrow() #&gt; [1] 142 Close Solution         a) countries, × Solution gapminder %&gt;% count(continent) %&gt;% nrow() #&gt; [1] 5 Close Solution         b) continents, × Solution gapminder %&gt;% count(continent, country) %&gt;% count(continent) # or #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 52 #&gt; 2 Americas 25 #&gt; 3 Asia 33 #&gt; 4 Europe 30 #&gt; 5 Oceania 2 Close Solution         c) countries per continent. × Solution gapminder %&gt;% distinct(continent) %&gt;% pull(continent) %&gt;% as.character() #&gt; [1] &quot;Asia&quot; &quot;Europe&quot; &quot;Africa&quot; &quot;Americas&quot; &quot;Oceania&quot; Close Solution × Hint gapminder %&gt;% distinct(___) %&gt;% pull(___) %&gt;% as.character() Close Hint Retrieve a vector with all distinct continent values. Subset rows to find: × Solution gapminder %&gt;% filter(lifeExp &lt; 29) #&gt; # A tibble: 2 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Rwanda Africa 1992 23.6 7290203 737. Close Solution         a) all rows with life expectancy less that 29 years, × Solution gapminder %&gt;% filter(country == &quot;Rwanda&quot;, year &gt; 1979) #&gt; # A tibble: 6 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Rwanda Africa 1982 46.2 5507565 882. #&gt; 2 Rwanda Africa 1987 44.0 6349365 848. #&gt; 3 Rwanda Africa 1992 23.6 7290203 737. #&gt; 4 Rwanda Africa 1997 36.1 7212583 590. #&gt; 5 Rwanda Africa 2002 43.4 7852401 786. #&gt; 6 Rwanda Africa 2007 46.2 8860588 863. Close Solution         b) all rows for Rwanda after year 1979, × Solution gapminder %&gt;% filter(country %in% c(&quot;Rwanda&quot;, &quot;Afghanistan&quot;, &quot;France&quot;)) #&gt; # A tibble: 36 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 26 more rows Close Solution         c) all rows for Rwanda, Afghanistan or France. Select columns × Solution gapminder %&gt;% select(year, lifeExp) #&gt; # A tibble: 1,704 × 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 #&gt; 2 1957 30.3 #&gt; 3 1962 32.0 #&gt; 4 1967 34.0 #&gt; 5 1972 36.1 #&gt; 6 1977 38.4 #&gt; 7 1982 39.9 #&gt; 8 1987 40.8 #&gt; 9 1992 41.7 #&gt; 10 1997 41.8 #&gt; # … with 1,694 more rows Close Solution         a) year and life expectancy, × Solution gapminder %&gt;% select(country, gdpPercap) #&gt; # A tibble: 1,704 × 2 #&gt; country gdpPercap #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 779. #&gt; 2 Afghanistan 821. #&gt; 3 Afghanistan 853. #&gt; 4 Afghanistan 836. #&gt; 5 Afghanistan 740. #&gt; 6 Afghanistan 786. #&gt; 7 Afghanistan 978. #&gt; 8 Afghanistan 852. #&gt; 9 Afghanistan 649. #&gt; 10 Afghanistan 635. #&gt; # … with 1,694 more rows Close Solution         b) country and GDP per capita. × Solution gapminder %&gt;% filter((gdpPercap &gt; 40000 &amp; continent == &quot;Europe&quot;) | (gdpPercap &lt; 400 &amp; continent == &quot;Africa&quot;)) %&gt;% # print(n=Inf) %&gt;% # if want to see the intermediate results select(continent, country, gdpPercap) # %&gt;% print(n=Inf) #&gt; # A tibble: 21 × 3 #&gt; continent country gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Burundi 339. #&gt; 2 Africa Burundi 380. #&gt; 3 Africa Burundi 355. #&gt; 4 Africa Congo, Dem. Rep. 312. #&gt; 5 Africa Congo, Dem. Rep. 241. #&gt; 6 Africa Congo, Dem. Rep. 278. #&gt; 7 Africa Equatorial Guinea 376. #&gt; 8 Africa Eritrea 329. #&gt; 9 Africa Eritrea 344. #&gt; 10 Africa Eritrea 381. #&gt; # … with 11 more rows Close Solution × Hint gapminder %&gt;% filter((gdpPercap &gt; ___ &amp; continent == ___) | (___)) %&gt;% # print(n=Inf) %&gt;% # if want to see the intermediate results select(continent, ___, ___) # %&gt;% print(n=Inf) Close Hint Subset your data set to find all rows with GDP per capita greater than 40000 in Europe or with GDP per capita less than 500 in Africa. × Solution gapminder %&gt;% mutate(gdp = pop * gdpPercap) #&gt; # A tibble: 1,704 × 7 #&gt; country continent year lifeExp pop gdpPercap gdp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. #&gt; # … with 1,694 more rows Close Solution Use mutate to calculate each country’s GDP (population times GDP per capita). In general GDP numbers are large and abstract. Let us try to calculate relative numbers. × Solution mean_dk &lt;- gapminder %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% pull(gdpPercap) %&gt;% mean() dat &lt;- gapminder %&gt;% mutate(gdpPercapRel = gdpPercap/mean_dk) The relative GDP per capita numbers are, in general, well below 1. We see that most of the countries covered by this dataset have substantially lower GDP per capita, relative to Denmark, across the entire time period. Close Solution × Hint 2 dat &lt;- gapminder %&gt;% mutate(gdpPercapRel = ___) Close Hint 2 × Hint 1 mean_dk &lt;- gapminder %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% pull(___) %&gt;% mean() First you must calculate the mean of Danish gdpPercap and next use that to add a new column gdpPercapRel. Close Hint 1 Use mutate to calculate GDP per capita relative to mean GDP per capita in Denmark over the whole period (gdpPercap divided by the mean of Danish gdpPercap). Have a look at the calculated data. Does the numbers seem reasonable? I perceive Denmark to be a “high GDP” country, so I predict that the distribution of gdpPercapRel is located below 1, possibly even well below. Use arrange to order × Solution gapminder %&gt;% arrange(year, country) #&gt; # A tibble: 1,704 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Albania Europe 1952 55.2 1282697 1601. #&gt; 3 Algeria Africa 1952 43.1 9279525 2449. #&gt; 4 Angola Africa 1952 30.0 4232095 3521. #&gt; 5 Argentina Americas 1952 62.5 17876956 5911. #&gt; 6 Australia Oceania 1952 69.1 8691212 10040. #&gt; 7 Austria Europe 1952 66.8 6927772 6137. #&gt; 8 Bahrain Asia 1952 50.9 120447 9867. #&gt; 9 Bangladesh Asia 1952 37.5 46886859 684. #&gt; 10 Belgium Europe 1952 68 8730405 8343. #&gt; # … with 1,694 more rows Close Solution         a) data by year then country, as opposed to current by country then year, × Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(lifeExp) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Swaziland Africa 2007 39.6 1133066 4513. #&gt; 2 Mozambique Africa 2007 42.1 19951656 824. #&gt; 3 Zambia Africa 2007 42.4 11746035 1271. #&gt; 4 Sierra Leone Africa 2007 42.6 6144562 863. #&gt; 5 Lesotho Africa 2007 42.6 2012649 1569. #&gt; 6 Angola Africa 2007 42.7 12420476 4797. #&gt; 7 Zimbabwe Africa 2007 43.5 12311143 470. #&gt; 8 Afghanistan Asia 2007 43.8 31889923 975. #&gt; 9 Central African Republic Africa 2007 44.7 4369038 706. #&gt; 10 Liberia Africa 2007 45.7 3193942 415. #&gt; # … with 132 more rows Close Solution         b) data from 2007, sorted on life expectancy, × Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(desc(lifeExp)) #&gt; # A tibble: 142 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Japan Asia 2007 82.6 127467972 31656. #&gt; 2 Hong Kong, China Asia 2007 82.2 6980412 39725. #&gt; 3 Iceland Europe 2007 81.8 301931 36181. #&gt; 4 Switzerland Europe 2007 81.7 7554661 37506. #&gt; 5 Australia Oceania 2007 81.2 20434176 34435. #&gt; 6 Spain Europe 2007 80.9 40448191 28821. #&gt; 7 Sweden Europe 2007 80.9 9031088 33860. #&gt; 8 Israel Asia 2007 80.7 6426679 25523. #&gt; 9 France Europe 2007 80.7 61083916 30470. #&gt; 10 Canada Americas 2007 80.7 33390141 36319. #&gt; # … with 132 more rows Close Solution         c) data from 2007, sorted on life expectancy in descending order. Hint: use desc() inside arrange. Use select to × Solution gapminder %&gt;% select(yr = year, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; yr country continent lifeExp pop gdpPercap #&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan Asia 28.8 8425333 779. #&gt; 2 1957 Afghanistan Asia 30.3 9240934 821. #&gt; 3 1962 Afghanistan Asia 32.0 10267083 853. #&gt; 4 1967 Afghanistan Asia 34.0 11537966 836. #&gt; 5 1972 Afghanistan Asia 36.1 13079460 740. #&gt; 6 1977 Afghanistan Asia 38.4 14880372 786. #&gt; 7 1982 Afghanistan Asia 39.9 12881816 978. #&gt; 8 1987 Afghanistan Asia 40.8 13867957 852. #&gt; 9 1992 Afghanistan Asia 41.7 16317921 649. #&gt; 10 1997 Afghanistan Asia 41.8 22227415 635. #&gt; # … with 1,694 more rows Close Solution         a) rename year to yr and keep all other columns (the select helper everything may be used), × Solution gapminder %&gt;% select(-pop) #&gt; # A tibble: 1,704 × 5 #&gt; country continent year lifeExp gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 779. #&gt; 2 Afghanistan Asia 1957 30.3 821. #&gt; 3 Afghanistan Asia 1962 32.0 853. #&gt; 4 Afghanistan Asia 1967 34.0 836. #&gt; 5 Afghanistan Asia 1972 36.1 740. #&gt; 6 Afghanistan Asia 1977 38.4 786. #&gt; 7 Afghanistan Asia 1982 39.9 978. #&gt; 8 Afghanistan Asia 1987 40.8 852. #&gt; 9 Afghanistan Asia 1992 41.7 649. #&gt; 10 Afghanistan Asia 1997 41.8 635. #&gt; # … with 1,694 more rows Close Solution         b) remove pop, × Solution gapminder %&gt;% select(year, pop, everything()) #&gt; # A tibble: 1,704 × 6 #&gt; year pop country continent lifeExp gdpPercap #&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 8425333 Afghanistan Asia 28.8 779. #&gt; 2 1957 9240934 Afghanistan Asia 30.3 821. #&gt; 3 1962 10267083 Afghanistan Asia 32.0 853. #&gt; 4 1967 11537966 Afghanistan Asia 34.0 836. #&gt; 5 1972 13079460 Afghanistan Asia 36.1 740. #&gt; 6 1977 14880372 Afghanistan Asia 38.4 786. #&gt; 7 1982 12881816 Afghanistan Asia 39.9 978. #&gt; 8 1987 13867957 Afghanistan Asia 40.8 852. #&gt; 9 1992 16317921 Afghanistan Asia 41.7 649. #&gt; 10 1997 22227415 Afghanistan Asia 41.8 635. #&gt; # … with 1,694 more rows Close Solution         c) reorder columns in order year, pop, … (remaining). Use group_by and summarize to find the × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n()) #&gt; # A tibble: 5 × 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 Close Solution         a) number of observations per continent, × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n(), n_countries = n_distinct(country)) #&gt; # A tibble: 5 × 3 #&gt; continent n n_countries #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Africa 624 52 #&gt; 2 Americas 300 25 #&gt; 3 Asia 396 33 #&gt; 4 Europe 360 30 #&gt; 5 Oceania 24 2 Close Solution         b) number of countries per continent (use n_distinct inside summarize to count the number of distinct observations), × Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(avg_lifeExp = mean(lifeExp)) #&gt; # A tibble: 5 × 2 #&gt; continent avg_lifeExp #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa 48.9 #&gt; 2 Americas 64.7 #&gt; 3 Asia 60.1 #&gt; 4 Europe 71.9 #&gt; 5 Oceania 74.3 Close Solution         c) average life expectancy by continent, × Solution gapminder %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% group_by(year) %&gt;% summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp)) #&gt; # A tibble: 12 × 3 #&gt; year min_lifeExp max_lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 65.4 #&gt; 2 1957 30.3 67.8 #&gt; 3 1962 32.0 69.4 #&gt; 4 1967 34.0 71.4 #&gt; 5 1972 36.1 73.4 #&gt; 6 1977 31.2 75.4 #&gt; 7 1982 39.9 77.1 #&gt; 8 1987 40.8 78.7 #&gt; 9 1992 41.7 79.4 #&gt; 10 1997 41.8 80.7 #&gt; 11 2002 42.1 82 #&gt; 12 2007 43.8 82.6 Close Solution         d) minimum and maximum life expectancies seen by year in Asia. × Solution gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = lifeExp - first(lifeExp)) %&gt;% filter(year &lt; 1963) # just for nice printing #&gt; # A tibble: 426 × 4 #&gt; # Groups: country [142] #&gt; country year lifeExp lifeExp_gain #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1952 28.8 0 #&gt; 2 Afghanistan 1957 30.3 1.53 #&gt; 3 Afghanistan 1962 32.0 3.20 #&gt; 4 Albania 1952 55.2 0 #&gt; 5 Albania 1957 59.3 4.05 #&gt; 6 Albania 1962 64.8 9.59 #&gt; 7 Algeria 1952 43.1 0 #&gt; 8 Algeria 1957 45.7 2.61 #&gt; 9 Algeria 1962 48.3 5.23 #&gt; 10 Angola 1952 30.0 0 #&gt; # … with 416 more rows Close Solution × Hint gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = ___) %&gt;% # define new variable filter(year &lt; 1963) # just for nice printing The first function may be helpful to extract the first value from a vector in each group. Close Hint Sometimes you do not want to collapse the \\(n\\) rows for each group into one row. That is, you do not want to use summarize but mutate within your groups. Try to make a new variable that is the years of life expectancy gained (lost) relative to 1952, for each individual country. × Solution gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% group_by(continent, country) %&gt;% mutate(le_delta = lifeExp - lag(lifeExp)) %&gt;% summarize(worst_le_delta = min(le_delta, na.rm = TRUE)) %&gt;% slice_min(worst_le_delta) %&gt;% arrange(worst_le_delta) #&gt; # A tibble: 5 × 3 #&gt; # Groups: continent [5] #&gt; continent country worst_le_delta #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Rwanda -20.4 #&gt; 2 Asia Cambodia -9.10 #&gt; 3 Americas El Salvador -1.51 #&gt; 4 Europe Montenegro -1.46 #&gt; 5 Oceania Australia 0.170 Mostly you are seeing what genocide looks like in dry statistics on average life expectancy. Close Solution × Hint gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% # select relevant columns group_by(continent, country) %&gt;% # group mutate(le_delta = ___) %&gt;% # within country, take (lifeExp in year i) - (lifeExp in year i - 1) summarize(worst_le_delta = min(___, na.rm = TRUE)) %&gt;% # find lowest value slice_min(worst_le_delta) %&gt;% # find min in each continent arrange(worst_le_delta) # arrange The lag function is useful to select the value in the previous row. Positive values of le_delta means lifeExp went up, negative means it went down. Break the code into pieces, starting at the top, and inspect the intermediate results. These commands are built up gradually, with lots of errors and refinements along the way. Close Hint Which country experienced the sharpest 5-year drop in life expectancy in each continent? Recall that the Gapminder data only has data every five years, e.g. for 1952, 1957, etc. So this really means looking at life expectancy changes between adjacent timepoints. 15.6.2 Exercise (babynames) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The package babynames contains the dataset babynames provided by the U.S. Social Security Administration. For each year from 1880 to 2017, the number of children of each sex given each name. All names with more than 5 uses are given (source: http://www.ssa.gov/oact/babynames/limits.html). Install it using install.packages(&quot;babynames&quot;) We will use the skimr package to get an overview over babynames: library(babynames) library(skimr) skim(babynames) Table 15.1: Data summary Name babynames Number of rows 1924665 Number of columns 5 _______________________ Column type frequency: character 2 numeric 3 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace sex 0 1 1 1 0 2 0 name 0 1 2 15 0 97310 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist year 0 1 1975 34 1880 1951 1985 2003 2017.00 ▁▂▃▅▇ n 0 1 181 1533 5 7 12 32 99686.00 ▇▁▁▁▁ prop 0 1 0 0 0 0 0 0 0.08 ▇▁▁▁▁ × Solution The last line only selects the n column. Close Solution Which of these is NOT a way to select the name and n columns together? select(babynames, -c(year, sex, prop)) select(babynames, name:n) select(babynames, starts_with(&quot;n&quot;)) select(babynames, ends_with(&quot;n&quot;)) Use filter and the logical operators to find: × Solution babynames %&gt;% filter(prop &gt;= 0.08) #&gt; # A tibble: 3 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 M John 9655 0.0815 #&gt; 2 1880 M William 9532 0.0805 #&gt; 3 1881 M John 8769 0.0810 Close Solution         a) all of the names where prop is greater than or equal to 0.08, × Solution babynames %&gt;% filter(name == &quot;Sea&quot;) #&gt; # A tibble: 4 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1982 F Sea 5 0.00000276 #&gt; 2 1985 M Sea 6 0.00000312 #&gt; 3 1986 M Sea 5 0.0000026 #&gt; 4 1998 F Sea 5 0.00000258 Close Solution         b) all of the children named “Sea”. Use Boolean operators to return only the rows that contain: × Solution babynames %&gt;% filter(name == &quot;Sue&quot;, sex == &quot;M&quot;) #&gt; # A tibble: 52 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1917 M Sue 7 0.0000073 #&gt; 2 1927 M Sue 5 0.0000043 #&gt; 3 1928 M Sue 5 0.00000438 #&gt; 4 1930 M Sue 5 0.00000443 #&gt; 5 1931 M Sue 6 0.00000561 #&gt; 6 1932 M Sue 7 0.00000652 #&gt; 7 1933 M Sue 7 0.00000686 #&gt; 8 1934 M Sue 14 0.0000132 #&gt; 9 1935 M Sue 13 0.0000122 #&gt; 10 1936 M Sue 9 0.00000846 #&gt; # … with 42 more rows Close Solution         a) boys named Sue, × Solution babynames %&gt;% filter(year == 1880, n == 5 | n == 6) #&gt; # A tibble: 455 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1880 F Abby 6 0.0000615 #&gt; 2 1880 F Aileen 6 0.0000615 #&gt; 3 1880 F Alba 6 0.0000615 #&gt; 4 1880 F Alda 6 0.0000615 #&gt; 5 1880 F Alla 6 0.0000615 #&gt; 6 1880 F Alverta 6 0.0000615 #&gt; 7 1880 F Ara 6 0.0000615 #&gt; 8 1880 F Ardelia 6 0.0000615 #&gt; 9 1880 F Ardella 6 0.0000615 #&gt; 10 1880 F Arrie 6 0.0000615 #&gt; # … with 445 more rows Close Solution         b) names that were used by exactly 5 or 6 children in 1880, × Solution babynames %&gt;% filter(name %in% c(&quot;Acura&quot;, &quot;Lexus&quot;, &quot;Yugo&quot;)) #&gt; # A tibble: 57 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1990 F Lexus 36 0.0000175 #&gt; 2 1990 M Lexus 12 0.00000558 #&gt; 3 1991 F Lexus 102 0.0000502 #&gt; 4 1991 M Lexus 16 0.00000755 #&gt; 5 1992 F Lexus 193 0.0000963 #&gt; 6 1992 M Lexus 25 0.0000119 #&gt; 7 1993 F Lexus 285 0.000145 #&gt; 8 1993 M Lexus 30 0.0000145 #&gt; 9 1994 F Lexus 381 0.000195 #&gt; 10 1994 F Acura 6 0.00000308 #&gt; # … with 47 more rows Close Solution         c) names that are one of Acura, Lexus, or Yugo. × Solution min(babynames$n) #&gt; [1] 5 max(babynames$n) #&gt; [1] 99686 Close Solution What is the smallest value of n? What is the largest? × Solution babynames %&gt;% filter(sex == &quot;F&quot;, year == 2017) %&gt;% select(name, n) %&gt;% arrange(desc(n)) #&gt; # A tibble: 18,309 × 2 #&gt; name n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Emma 19738 #&gt; 2 Olivia 18632 #&gt; 3 Ava 15902 #&gt; 4 Isabella 15100 #&gt; 5 Sophia 14831 #&gt; 6 Mia 13437 #&gt; 7 Charlotte 12893 #&gt; 8 Amelia 11800 #&gt; 9 Evelyn 10675 #&gt; 10 Abigail 10551 #&gt; # … with 18,299 more rows Close Solution × Hint babynames %&gt;% filter(___) %&gt;% select(name, n) %&gt;% arrange(desc(___)) Close Hint Write a sequence of functions that filters babynames to just the girls that were born in 2017, then select the name and n columns, then arrange the results so that the most popular names are near the top. × Solution # for instance babynames %&gt;% filter(sex == &quot;M&quot;, name == &quot;Lars&quot;) #&gt; # A tibble: 112 × 5 #&gt; year sex name n prop #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1883 M Lars 7 0.0000622 #&gt; 2 1884 M Lars 5 0.0000407 #&gt; 3 1886 M Lars 5 0.000042 #&gt; 4 1887 M Lars 5 0.0000457 #&gt; 5 1897 M Lars 5 0.000041 #&gt; 6 1901 M Lars 8 0.0000692 #&gt; 7 1912 M Lars 6 0.0000133 #&gt; 8 1913 M Lars 6 0.0000112 #&gt; 9 1914 M Lars 16 0.0000234 #&gt; 10 1915 M Lars 17 0.0000193 #&gt; # … with 102 more rows Close Solution Trim babynames to just the rows that contain your name and your sex. × Solution babynames %&gt;% filter(name == &quot;Khaleesi&quot;) %&gt;% summarise(total = sum(n), first = min(year)) #&gt; # A tibble: 1 × 2 #&gt; total first #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1964 2011 Close Solution × Hint babynames ___ filter(____) ___ ____(total = ___, first = ___) Close Hint Extract the rows where name == \"Khaleesi\". Then use summarise() to find the total number of children named Khaleesi and the first year Khaleesi appeared in the data. × Solution babynames %&gt;% group_by(name, sex) %&gt;% summarize(total = sum(n)) %&gt;% arrange(desc(total)) #&gt; # A tibble: 107,973 × 3 #&gt; # Groups: name [97,310] #&gt; name sex total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 James M 5150472 #&gt; 2 John M 5115466 #&gt; 3 Robert M 4814815 #&gt; 4 Michael M 4350824 #&gt; 5 Mary F 4123200 #&gt; 6 William M 4102604 #&gt; 7 David M 3611329 #&gt; 8 Joseph M 2603445 #&gt; 9 Richard M 2563082 #&gt; 10 Charles M 2386048 #&gt; # … with 107,963 more rows Close Solution × Hint babynames %&gt;% _______(name, sex) %&gt;% _______(total = _____(n)) %&gt;% _______(desc(_____)) Close Hint Use group_by(), summarise(), and arrange() to display the ten most popular names. Compute popularity as the total number of children of a single gender given a name. × Solution babynames %&gt;% group_by(year) %&gt;% summarise(total = sum(n)) #&gt; # A tibble: 138 × 2 #&gt; year total #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 201484 #&gt; 2 1881 192696 #&gt; 3 1882 221533 #&gt; 4 1883 216946 #&gt; 5 1884 243462 #&gt; 6 1885 240854 #&gt; 7 1886 255317 #&gt; 8 1887 247394 #&gt; 9 1888 299473 #&gt; 10 1889 288946 #&gt; # … with 128 more rows Close Solution Use group_by() to calculate the total number of children born each year over time. × Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% arrange(year, sex, desc(prop)) #&gt; # A tibble: 1,924,665 × 6 #&gt; # Groups: year, sex [276] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1880 F Mary 7065 0.0724 1 #&gt; 2 1880 F Anna 2604 0.0267 2 #&gt; 3 1880 F Emma 2003 0.0205 3 #&gt; 4 1880 F Elizabeth 1939 0.0199 4 #&gt; 5 1880 F Minnie 1746 0.0179 5 #&gt; 6 1880 F Margaret 1578 0.0162 6 #&gt; 7 1880 F Ida 1472 0.0151 7 #&gt; 8 1880 F Alice 1414 0.0145 8 #&gt; 9 1880 F Bertha 1320 0.0135 9 #&gt; 10 1880 F Sarah 1288 0.0132 10 #&gt; # … with 1,924,655 more rows The same results if you use n since in the same order. Close Solution × Hint babynames %&gt;% group_by(___, ___) %&gt;% ___(rank = ___(desc(___))) %&gt;% arrange(year, sex, desc(prop)) Close Hint Column prop denotes the proportion given year and sex. Use mutate() and min_rank() to rank each row in babynames from largest prop to lowest prop given year and sex. What happens if you do the same using the n column? × Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% filter(rank == 1, year &gt; 2009) #&gt; # A tibble: 16 × 6 #&gt; # Groups: year, sex [16] #&gt; year sex name n prop rank #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 2010 F Isabella 22905 0.0117 1 #&gt; 2 2010 M Jacob 22117 0.0108 1 #&gt; 3 2011 F Sophia 21837 0.0113 1 #&gt; 4 2011 M Jacob 20365 0.0100 1 #&gt; 5 2012 F Sophia 22304 0.0115 1 #&gt; 6 2012 M Jacob 19069 0.00941 1 #&gt; 7 2013 F Sophia 21213 0.0110 1 #&gt; 8 2013 M Noah 18241 0.00904 1 #&gt; 9 2014 F Emma 20924 0.0107 1 #&gt; 10 2014 M Noah 19286 0.00943 1 #&gt; 11 2015 F Emma 20435 0.0105 1 #&gt; 12 2015 M Noah 19613 0.00962 1 #&gt; 13 2016 F Emma 19471 0.0101 1 #&gt; 14 2016 M Noah 19082 0.00946 1 #&gt; 15 2017 F Emma 19738 0.0105 1 #&gt; 16 2017 M Liam 18728 0.00954 1 Close Solution Filter the results to find all names with rank == 1 after 2009. 15.6.3 Exercise (profit) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit containing quarterly financial records for each costumer, product, etc.: library(skimr) path &lt;- system.file(&quot;extdata/profit_raw.csv&quot;, package = &quot;tfa&quot;) profit &lt;- read_csv(path) skim(profit) Table 15.2: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 9 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Quarter 0 1 1 2 0 12 0 Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Revenue 63 1 1 7 0 1210 0 Product Cost 61 1 3 6 0 1139 0 Customer Service Cost 10 1 1 6 0 464 0 Profit 0 1 3 7 0 966 0 Note that it seems that the dataset need to be cleaned. All columns are strings (some should be numbers) and there seems to be missing values. You may start by having a view of the dataset using: View(profit) First focus on column Quarter which currently has 12 distinct values: profit %&gt;% distinct(Quarter) #&gt; # A tibble: 12 × 1 #&gt; Quarter #&gt; &lt;chr&gt; #&gt; 1 Q3 #&gt; 2 1 #&gt; 3 Q4 #&gt; 4 Q1 #&gt; 5 Q2 #&gt; 6 2 #&gt; 7 4 #&gt; 8 q1 #&gt; 9 q4 #&gt; 10 q3 #&gt; 11 q2 #&gt; 12 3 You would like it to be a numeric with values 1-4. × Solution profit &lt;- profit %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) #&gt; # A tibble: 4 × 1 #&gt; Quarter #&gt; &lt;dbl&gt; #&gt; 1 3 #&gt; 2 1 #&gt; 3 4 #&gt; 4 2 Close Solution × Hint profit &lt;- profit %&gt;% mutate(Quarter = str_remove(___, &quot;q&quot;) %&gt;% str_remove(___) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) Close Hint Use mutate, str_remove and as.numeric to convert the column to a numeric by removing all ‘q’ and ‘Q’ values. Let us look at the next columns: profit %&gt;% distinct(Channel) %&gt;% pull() #&gt; [1] &quot;ATM&quot; &quot;BRH&quot; &quot;INT&quot; &quot;MAL&quot; &quot;EML&quot; &quot;CCT&quot; &quot;TEL&quot; &quot;MOP&quot; &quot;DSA&quot; &quot;EVE&quot; profit %&gt;% distinct(`Customer ID`) %&gt;% pull() #&gt; [1] &quot;FRT&quot; &quot;MRT&quot; &quot;PBI&quot; &quot;MAM&quot; &quot;EBP&quot; &quot;RPB&quot; &quot;WEB&quot; &quot;WEM&quot; &quot;HEC&quot; &quot;STF&quot; &quot;IAS&quot; &quot;CRE&quot; &quot;INB&quot; &quot;CAM&quot; &quot;AGR&quot; &quot;SBE&quot; #&gt; [17] &quot;AFF&quot; &quot;MFN&quot; profit %&gt;% distinct(Country) %&gt;% pull() #&gt; [1] &quot;USA&quot; &quot;Canada&quot; &quot;Great Britain&quot; &quot;Finland&quot; &quot;New Zealand&quot; #&gt; [6] &quot;Brazil&quot; &quot;Mexico&quot; &quot;Germany&quot; &quot;Puerto Rico&quot; &quot;Hong Kong&quot; #&gt; [11] &quot;Japan&quot; &quot;Columbia&quot; &quot;Switzerland&quot; &quot;Uruguay&quot; &quot;Netherlands&quot; #&gt; [16] &quot;Korea&quot; &quot;Venezuela&quot; &quot;Panama&quot; &quot;Sweden&quot; &quot;China&quot; #&gt; [21] &quot;Guatemala&quot; &quot;South Africa&quot; &quot;Malaysia&quot; &quot;Nigeria&quot; &quot;Denmark&quot; #&gt; [26] &quot;France&quot; &quot;India&quot; &quot;Taiwan&quot; &quot;Norway&quot; &quot;Chile&quot; #&gt; [31] &quot;Indonesia&quot; &quot;Ireland&quot; &quot;Thailand&quot; &quot;Peru&quot; &quot;Spain&quot; #&gt; [36] &quot;Belgium&quot; &quot;Poland&quot; &quot;Ecuador&quot; &quot;Costa Rica&quot; &quot;Australia&quot; #&gt; [41] &quot;Israel&quot; &quot;Guam&quot; &quot;Oman&quot; &quot;Singapore&quot; &quot;Argentina&quot; #&gt; [46] &quot;Czechoslovakia&quot; &quot;Philippines&quot; profit %&gt;% distinct(`Product Line`) %&gt;% pull() #&gt; [1] &quot;Credit Products&quot; &quot;Deposit Products&quot; &quot;Revolving Credit Products&quot; #&gt; [4] &quot;Other Products&quot; &quot;Third Party Products&quot; &quot;Fee Based Products&quot; These seem to be okay. The last columns should be numbers. Let us consider Revenue. profit %&gt;% distinct(Revenue) %&gt;% pull() %&gt;% head(n = 100) #&gt; [1] &quot;$ 6044&quot; &quot;$ 4686&quot; &quot;$ 6063&quot; &quot;$ 4682&quot; &quot;$ 6320&quot; &quot;$ 2993&quot; &quot;$ 3355&quot; &quot;$ 5716&quot; &quot;$ 3347&quot; #&gt; [10] &quot;$ 2624&quot; &quot;$ 3629&quot; &quot;$ 5612&quot; &quot;$ 4618&quot; &quot;$ 2080&quot; &quot;$ 2788&quot; &quot;$ 2829&quot; &quot;$ 2898&quot; &quot;$ 5232&quot; #&gt; [19] &quot;$ 2949&quot; &quot;$ 5565&quot; &quot;$ 2153&quot; &quot;$ 3097&quot; &quot;$ 1920&quot; &quot;$ 4041&quot; &quot;$ 5931&quot; &quot;$ 1605&quot; &quot;$ 2026&quot; #&gt; [28] &quot;$ 1687&quot; &quot;$ 5075&quot; &quot;$ 4223&quot; &quot;$ 2456&quot; &quot;$ 1924&quot; &quot;$ 1578&quot; &quot;$ 3235&quot; &quot;$ 5123&quot; &quot;$ 1560&quot; #&gt; [37] &quot;$ 1945&quot; &quot;$ 6060&quot; &quot;$ 1222&quot; &quot;$ 1660&quot; &quot;$ 3000&quot; &quot;$ 2970&quot; &quot;$ 1631&quot; &quot;$ 1215&quot; &quot;$ 1759&quot; #&gt; [46] &quot;$ 3285&quot; &quot;$ 2048&quot; &quot;$ 2173&quot; &quot;$ 3353&quot; &quot;$ 1162&quot; &quot;$ 1232&quot; &quot;$ 1561&quot; &quot;$ 1123&quot; &quot;$ 1794&quot; #&gt; [55] &quot;$ 1202&quot; &quot;$ 1510&quot; &quot;$ 4472&quot; &quot;$ 2370&quot; &quot;$ 2581&quot; &quot;$ 2761&quot; &quot;$ 6371&quot; &quot;$ 1972&quot; &quot;$ 1562&quot; #&gt; [64] &quot;$ 2742&quot; &quot;$ 4598&quot; &quot;$ 5322&quot; &quot;$ 3411&quot; NA &quot;$ 1569&quot; &quot;$ 2852&quot; &quot;$ 1622&quot; &quot;$ 2505&quot; #&gt; [73] &quot;$ 1596&quot; &quot;$ 1447&quot; &quot;$ 1690&quot; &quot;$ 2448&quot; &quot;$ 1593&quot; &quot;$ 1876&quot; &quot;$ 6591&quot; &quot;$ 1611&quot; &quot;$ 1254&quot; #&gt; [82] &quot;Unknown&quot; &quot;$ 842&quot; &quot;$ 1529&quot; &quot;$ 1439&quot; &quot;$ 762&quot; &quot;$ 1959&quot; &quot;$ 4382&quot; &quot;$ 1407&quot; &quot;$ 909&quot; #&gt; [91] &quot;$ 1549&quot; &quot;$ 2161&quot; &quot;$ 1331&quot; &quot;$ 727&quot; &quot;$ 1462&quot; &quot;$ 1067&quot; &quot;$ 833&quot; &quot;$ 1675&quot; &quot;$ 1524&quot; #&gt; [100] &quot;$ 1285&quot; Most values start with a dollar sign. Let us have a look at the other ones: profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 95 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 INT MAM USA Deposit Produ… Unknown $ 1008 $ 246 #&gt; 2 3 MAL RPB USA Credit Produc… ? $ 1420 $ 347 #&gt; 3 1 MAL WEM Great Britain Other Products ? $ 87 $ 19 #&gt; 4 3 ATM MFN Germany Fee Based Pro… unknown $ 47 $ 6 #&gt; 5 3 ATM PBI Costa Rica Third Party P… Unknown $ 51 $ 9 #&gt; 6 1 ATM PBI Chile Deposit Produ… Unknown $ 58 $ 7 #&gt; 7 4 CCT MRT Great Britain Revolving Cre… ? $ 27 $ 5 #&gt; 8 4 ATM MAM Taiwan Third Party P… unknown $ 55 $ 9 #&gt; 9 4 MAL WEB Japan Other Products unknown $ 40 $ 7 #&gt; 10 2 CCT MAM Netherlands Credit Produc… unknown $ 14 $ 3 #&gt; # … with 85 more rows, and 1 more variable: Profit &lt;chr&gt; na_values &lt;- profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) %&gt;% distinct(Revenue) %&gt;% pull(Revenue) na_values #&gt; [1] &quot;Unknown&quot; &quot;?&quot; &quot;unknown&quot; The expression is a bit complex. Let us break it up. Function fixed just returns the fixed string ‘$’. This is necessary since the dollar sign has a special meaning in regular expressions (beyond the scope here). Function str_starts checks if the string starts with a dollar sign. We use the logical negation (NOT) to find the complementary set. Note that different strings have been used to indicate NA values (Unknown, ?, unknown). Let us first use a single value to indicate NA (a question mark): profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) Next, we replace all ? with NA: profit &lt;- profit %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) profit %&gt;% # check filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 0 × 9 #&gt; # … with 9 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;chr&gt;, Product Cost &lt;chr&gt;, Customer Service Cost &lt;chr&gt;, #&gt; # Profit &lt;chr&gt; Finally, we remove all dollar signs: profit &lt;- profit %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 ATM FRT USA Credit Products 6044 $ 3998 $ 413 #&gt; 2 1 ATM MRT USA Credit Products 4686 $ 3229 $ 643 #&gt; 3 4 ATM PBI USA Deposit Products 6063 $ 7440 $ 1842 #&gt; 4 1 ATM PBI USA Deposit Products 4682 $ 6127 $ 1118 #&gt; 5 4 ATM MRT USA Deposit Products 6320 $ 7913 $ 1854 #&gt; 6 3 BRH MAM USA Deposit Products 2993 $ 1034 $ 242 #&gt; 7 4 BRH PBI USA Revolving Credit Products 3355 $ 4355 $ 1027 #&gt; 8 3 ATM FRT USA Revolving Credit Products 5716 $ 5617 $ 876 #&gt; 9 4 BRH PBI USA Deposit Products 3347 $ 4229 $ 425 #&gt; 10 1 BRH PBI USA Credit Products 2624 $ 1960 $ 264 #&gt; # … with 24,536 more rows, and 1 more variable: Profit &lt;chr&gt; As one pipe: profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) Convert the remaining columns to numeric like shown for Revenue above. × Solution profit &lt;- read_csv(path) profit &lt;- profit %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) profit #&gt; # A tibble: 24,546 × 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Q3 ATM FRT USA Credit Products 6044 3998 413 #&gt; 2 1 ATM MRT USA Credit Products 4686 3229 643 #&gt; 3 Q4 ATM PBI USA Deposit Products 6063 7440 1842 #&gt; 4 Q1 ATM PBI USA Deposit Products 4682 6127 1118 #&gt; 5 Q4 ATM MRT USA Deposit Products 6320 7913 1854 #&gt; 6 Q3 BRH MAM USA Deposit Products 2993 1034 242 #&gt; 7 Q4 BRH PBI USA Revolving Credit Products 3355 4355 1027 #&gt; 8 Q3 ATM FRT USA Revolving Credit Products 5716 5617 876 #&gt; 9 Q4 BRH PBI USA Deposit Products 3347 4229 425 #&gt; 10 Q1 BRH PBI USA Credit Products 2624 1960 264 #&gt; # … with 24,536 more rows, and 1 more variable: Profit &lt;dbl&gt; Close Solution × Hint profit &lt;- read_csv(path) %&gt;% mutate(across(___:___, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(___:___, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(___:___, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) profit Close Hint Use the across function to apply the operations in Question 2 for a set of columns. Hint: see the examples on the help page of across. × Solution profit &lt;- read_csv(path) %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) skim(profit) Table 15.3: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1.00 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 158 0.99 120.31 421.79 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 61 1.00 100.04 375.58 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 96 1.00 17.41 67.50 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1.00 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Close Solution Write one pipe that does all the cleaning. × Solution profit &lt;- profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, Profit_calc, Profit, missing = Profit) ) profit %&gt;% filter(Diff == 1, is.na(Profit_calc)) # check #&gt; # A tibble: 0 × 11 #&gt; # … with 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; Close Solution × Hint profit &lt;- profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(___)) %&gt;% mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, ___, Profit, Profit) ) profit %&gt;% filter(Diff == 1, is.na(Profit_calc)) # check Close Hint Validate that revenue - product costs - customer service cost equals profit. If you see small rounding errors (less than or equal one) then recalculate the profit. × Solution profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% mutate(Revenue = if_else(is.na(Revenue) &amp; c_na == 1, Profit + `Product Cost` + `Customer Service Cost`, Revenue, Revenue), `Product Cost` = if_else(is.na(`Product Cost`) &amp; c_na == 1, - Profit + Revenue - `Customer Service Cost`, `Product Cost`), `Customer Service Cost` = if_else(is.na(`Customer Service Cost`) &amp; c_na == 1, - Profit + Revenue - `Product Cost`, `Customer Service Cost`)) %&gt;% select(Quarter:Profit) # check - do numbers match profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% filter(Diff &gt; 0) #&gt; # A tibble: 0 × 11 #&gt; # Rowwise: #&gt; # … with 11 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, Customer ID &lt;chr&gt;, Country &lt;chr&gt;, #&gt; # Product Line &lt;chr&gt;, Revenue &lt;dbl&gt;, Product Cost &lt;dbl&gt;, Customer Service Cost &lt;dbl&gt;, #&gt; # Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt; # check - find NA values profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% filter(c_na &gt; 0) #&gt; # A tibble: 3 × 10 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 EML FRT France Revolving Credit Products 3 NA NA #&gt; 2 2 BRH EBP Guam Fee Based Products NA NA 0 #&gt; 3 1 MAL MFN Japan Fee Based Products NA NA 5 #&gt; # … with 2 more variables: Profit &lt;dbl&gt;, c_na &lt;int&gt; Close Solution × Hint 2 profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% mutate(Revenue = if_else(is.na(___) &amp; c_na == 1, ___, Revenue, Revenue), `Product Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Product Cost`), `Customer Service Cost` = if_else(is.na(___) &amp; c_na == 1, ___, `Customer Service Cost`)) %&gt;% select(Quarter:Profit) You can check you calculations using your code from Question 5. Close Hint 2 × Hint 1 # To find the number of missing values (`NA`) you can create a new column # counting the number of missing values: profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(ct_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% ungroup() profit %&gt;% filter(ct_na &gt;= 1) Recall that profit = revenue - product costs - customer service cost; that is, if a single value of these are missing then the value can be calculated using the other ones. Close Hint 1 Recalculate values in columns Revenue to Profit if possible. × Solution profit %&gt;% group_by(Quarter) %&gt;% slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 9 #&gt; # Groups: Quarter [4] #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 ATM PBI USA Credit Products 4821 1808 233 #&gt; 2 1 ATM PBI USA Revolving Credit Products 4268 1638 363 #&gt; 3 2 ATM FRT USA Credit Products 5931 3137 406 #&gt; 4 2 ATM RPB USA Deposit Products 4864 2156 533 #&gt; 5 3 ATM WEM USA Credit Products 5682 2112 454 #&gt; 6 3 ATM WEM USA Deposit Products 4850 2493 253 #&gt; 7 4 ATM MAM USA Revolving Credit Products 6699 2506 530 #&gt; 8 4 ATM WEM USA Revolving Credit Products 5836 2114 265 #&gt; # … with 1 more variable: Profit &lt;dbl&gt; Close Solution Find the two best rows with highest profit in each quarter. × Solution profit %&gt;% group_by(Quarter, `Customer ID`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit, n = 2) #&gt; # A tibble: 8 × 3 #&gt; # Groups: Quarter [4] #&gt; Quarter `Customer ID` Profit #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 MRT 3925 #&gt; 2 1 WEB 3776 #&gt; 3 2 FRT 7272 #&gt; 4 2 MAM 6992 #&gt; 5 3 WEM 6616 #&gt; 6 3 RPB 3245 #&gt; 7 4 EBP 10093 #&gt; 8 4 WEM 8262 The results are not the same since use another group by. Close Solution × Hint profit %&gt;% group_by(___, `Customer ID`) %&gt;% summarise(Profit = ___) %&gt;% slice_max(Profit, n = 2) Close Hint Find the two best customers with highest profit in each quarter. Is the result the same as in Question 7? × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 # ... repeat # Using a function summarise_profit &lt;- function(data, group_var, summarise_var) { data %&gt;% group_by(across({{ group_var }})) %&gt;% summarise(across({{ summarise_var }}, sum)) %&gt;% slice_max(Profit) } summarise_profit(profit, `Product Line`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31022 summarise_profit(profit, `Customer ID`, Profit) #&gt; # A tibble: 1 × 2 #&gt; `Customer ID` Profit #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 WEM 18942 # ... repeat # Using purrr package to get a single tibble (if interested in the purrr package) val &lt;- names(profit)[1:5] max_profit &lt;- map_df( val, ~{ tmp &lt;- profit %&gt;% group_by(.data[[.x]]) %&gt;% summarise(Profit = sum(Profit), .groups = &quot;drop&quot;) %&gt;% slice_max(Profit) tibble(by = .x, best = as.character(tmp[[1,1]]), profit = tmp[[1,2]] ) } ) max_profit #&gt; # A tibble: 5 × 3 #&gt; by best profit #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Quarter 4 35268 #&gt; 2 Channel ATM 30433 #&gt; 3 Customer ID WEM 18942 #&gt; 4 Country USA 39693 #&gt; 5 Product Line Credit Products 31022 Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = ___) %&gt;% slice_max(Profit) # ... repeat Close Hint Find the product line, customer, channel, country and quarter with the highest profit. × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% distinct(Country) %&gt;% count(`Customer ID`) #&gt; # A tibble: 18 × 2 #&gt; # Groups: Customer ID [18] #&gt; `Customer ID` n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 AFF 1 #&gt; 2 AGR 16 #&gt; 3 CAM 1 #&gt; 4 CRE 1 #&gt; 5 EBP 47 #&gt; 6 FRT 47 #&gt; 7 HEC 1 #&gt; 8 IAS 1 #&gt; 9 INB 1 #&gt; 10 MAM 47 #&gt; 11 MFN 30 #&gt; 12 MRT 47 #&gt; 13 PBI 47 #&gt; 14 RPB 47 #&gt; 15 SBE 1 #&gt; 16 STF 2 #&gt; 17 WEB 47 #&gt; 18 WEM 47 Close Solution Are there rows with the same customer in different countries? × Solution profit %&gt;% arrange(desc(Profit), desc(Revenue)) #&gt; # A tibble: 24,546 × 9 #&gt; # Rowwise: #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 ATM MAM USA Revolving Credit Products 6699 2506 530 #&gt; 2 4 ATM WEM USA Revolving Credit Products 5836 2114 265 #&gt; 3 4 ATM MAM USA Credit Products 7540 3374 728 #&gt; 4 4 ATM MRT USA Credit Products 6419 2669 618 #&gt; 5 3 ATM WEM USA Credit Products 5682 2112 454 #&gt; 6 4 ATM WEB USA Deposit Products 5145 1907 191 #&gt; 7 1 ATM PBI USA Credit Products 4821 1808 233 #&gt; 8 4 ATM RPB USA Credit Products 5828 2727 559 #&gt; 9 2 ATM FRT USA Credit Products 5931 3137 406 #&gt; 10 1 ATM PBI USA Revolving Credit Products 4268 1638 363 #&gt; # … with 24,536 more rows, and 1 more variable: Profit &lt;dbl&gt; Close Solution Sort the data decreasing with respect to profit and next revenue. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost` + `Customer Service Cost`)) %&gt;% # print() %&gt;% # if want a peek before slicing slice_max(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Credit Products 820665 profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost`)) %&gt;% slice_min(cost) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` cost #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 91796 Close Solution × Hint profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(___)) %&gt;% # print() %&gt;% # if want a peek before slicing slice_max(___) profit %&gt;% ___% slice_min(cost) Close Hint Which product line has the highest and lowest total cost? × Solution profit %&gt;% mutate(cust_cost_new = `Customer Service Cost` * 1.05, profit_new = Revenue - cust_cost_new - `Product Cost`) %&gt;% group_by(`Product Line`) %&gt;% summarise(cust_cost = sum(`Customer Service Cost`), profit = sum(Profit), cust_cost_new = sum(cust_cost_new), profit_new = sum(profit_new), profit_decrease = profit_new - profit) #&gt; # A tibble: 6 × 6 #&gt; `Product Line` cust_cost profit cust_cost_new profit_new profit_decrease #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Credit Products 119612 31022 125593. 25041. -5981. #&gt; 2 Deposit Products 114526 5408 120252. -318. -5726. #&gt; 3 Fee Based Products 22900 4953 24045 NA NA #&gt; 4 Other Products 33282 7438 34946. 5774. -1664. #&gt; 5 Revolving Credit Products NA 15905 NA NA NA #&gt; 6 Third Party Products 15970 2264 16768. 1465. -799. Close Solution × Hint profit %&gt;% mutate(cust_cost_new = ___ * 1.05, profit_new = ___) %&gt;% group_by(`Product Line`) %&gt;% summarise(cust_cost = sum(___), profit = sum(Profit), cust_cost_new = ___, profit_new = ___, profit_decrease = ___) Close Hint Assume that customer service cost increases with 5%. How will that affect the profit for each product line? rm(profit) 15.6.4 Exercise (fisheries) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The dataset called fisheries contains world fisheries harvest for 2005. The tonnage from capture and aquaculture is listed by country. You need the tidyverse package as usual: library(tidyverse) # install tfa package using remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;, upgrade = FALSE) We load the needed datasets: fisheries &lt;- read_csv(system.file(&quot;extdata/fisheries.csv&quot;, package = &quot;tfa&quot;)) fisheries #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # … with 206 more rows continents &lt;- read_csv(system.file(&quot;extdata/continents.csv&quot;, package = &quot;tfa&quot;)) continents #&gt; # A tibble: 247 × 2 #&gt; country continent #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan Asia #&gt; 2 Åland Islands Europe #&gt; 3 Albania Europe #&gt; 4 Algeria Africa #&gt; 5 American Samoa Oceania #&gt; 6 Andorra Europe #&gt; 7 Angola Africa #&gt; 8 Anguilla Americas #&gt; 9 Antigua &amp; Barbuda Americas #&gt; 10 Argentina Americas #&gt; # … with 237 more rows Some mean statistics: fisheries %&gt;% summarise(across(where(is.numeric), mean, na.rm = TRUE)) #&gt; # A tibble: 1 × 3 #&gt; capture aquaculture total #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 421916. 508368. 930284. × Solution fisheries %&gt;% anti_join(continents) # countries not belonging to a continent #&gt; # A tibble: 20 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 #&gt; 2 Bosnia and Herzegovina 305 4564 4869 #&gt; 3 Czech Republic 3507 20952 24459 #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 #&gt; 5 Eswatini 65 100 165 #&gt; 6 Federated States of Micronesia 88397 0 88397 #&gt; 7 Ivory Coast 67500 4701 72201 #&gt; 8 Jersey and Guernsey 2985 1499 4484 #&gt; 9 Macao 1500 0 1500 #&gt; 10 Myanmar 2072390 1017644 3090034 #&gt; 11 North Macedonia 306 986 1292 #&gt; 12 Palestine 3306 280 3586 #&gt; 13 Republic of the Congo 86748 177 86925 #&gt; 14 Saint Kitts and Nevis 65734 1 65735 #&gt; 15 Saint Lucia 2097 32 2129 #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 #&gt; 17 São Tomé and Príncipe 11750 0 11750 #&gt; 18 Trinidad and Tobago 13027 11 13038 #&gt; 19 Turks and Caicos Islands 2780 0 2780 #&gt; 20 US Virgin Islands 551 8 559 fisheries &lt;- fisheries %&gt;% print() %&gt;% left_join(continents) %&gt;% print() #&gt; # A tibble: 216 × 4 #&gt; country capture aquaculture total #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1000 1200 2200 #&gt; 2 Albania 7886 950 8836 #&gt; 3 Algeria 95000 1361 96361 #&gt; 4 American Samoa 3047 20 3067 #&gt; 5 Andorra 0 0 0 #&gt; 6 Angola 486490 655 487145 #&gt; 7 Antigua and Barbuda 3000 10 3010 #&gt; 8 Argentina 755226 3673 758899 #&gt; 9 Armenia 3758 16381 20139 #&gt; 10 Aruba 142 0 142 #&gt; # … with 206 more rows #&gt; # A tibble: 216 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1000 1200 2200 Asia #&gt; 2 Albania 7886 950 8836 Europe #&gt; 3 Algeria 95000 1361 96361 Africa #&gt; 4 American Samoa 3047 20 3067 Oceania #&gt; 5 Andorra 0 0 0 Europe #&gt; 6 Angola 486490 655 487145 Africa #&gt; 7 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 8 Argentina 755226 3673 758899 Americas #&gt; 9 Armenia 3758 16381 20139 Asia #&gt; 10 Aruba 142 0 142 Americas #&gt; # … with 206 more rows fisheries %&gt;% filter(is.na(continent)) # same result - countries not belonging to a continent #&gt; # A tibble: 20 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Antigua and Barbuda 3000 10 3010 &lt;NA&gt; #&gt; 2 Bosnia and Herzegovina 305 4564 4869 &lt;NA&gt; #&gt; 3 Czech Republic 3507 20952 24459 &lt;NA&gt; #&gt; 4 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 5 Eswatini 65 100 165 &lt;NA&gt; #&gt; 6 Federated States of Micronesia 88397 0 88397 &lt;NA&gt; #&gt; 7 Ivory Coast 67500 4701 72201 &lt;NA&gt; #&gt; 8 Jersey and Guernsey 2985 1499 4484 &lt;NA&gt; #&gt; 9 Macao 1500 0 1500 &lt;NA&gt; #&gt; 10 Myanmar 2072390 1017644 3090034 &lt;NA&gt; #&gt; 11 North Macedonia 306 986 1292 &lt;NA&gt; #&gt; 12 Palestine 3306 280 3586 &lt;NA&gt; #&gt; 13 Republic of the Congo 86748 177 86925 &lt;NA&gt; #&gt; 14 Saint Kitts and Nevis 65734 1 65735 &lt;NA&gt; #&gt; 15 Saint Lucia 2097 32 2129 &lt;NA&gt; #&gt; 16 Saint Vincent and the Grenadines 23077 0 23077 &lt;NA&gt; #&gt; 17 São Tomé and Príncipe 11750 0 11750 &lt;NA&gt; #&gt; 18 Trinidad and Tobago 13027 11 13038 &lt;NA&gt; #&gt; 19 Turks and Caicos Islands 2780 0 2780 &lt;NA&gt; #&gt; 20 US Virgin Islands 551 8 559 &lt;NA&gt; Close Solution × Hint 2 fisheries %&gt;% anti_join(___) # countries not belonging to a continent fisheries &lt;- fisheries %&gt;% print() %&gt;% left_join(___) %&gt;% print() fisheries %&gt;% filter(is.na(___)) # same result - countries not belonging to a continent Close Hint 2 × Hint 1 You could use anti_join to find missing values. Use left_join to join the datasets. Close Hint 1 Use a mutating join to add a continent column to the fisheries dataset. Are there some countries which do not belong to a continent? × Solution fisheries &lt;- fisheries %&gt;% filter(total &gt; 100000) Close Solution × Hint fisheries &lt;- ___ %&gt;% filter(___) Close Hint Filter out countries whose total harvest was less than 100,000 tons. × Solution fisheries %&gt;% filter(is.na(continent)) #&gt; # A tibble: 2 × 5 #&gt; country capture aquaculture total continent #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Democratic Republic of the Congo 237372 3161 240533 &lt;NA&gt; #&gt; 2 Myanmar 2072390 1017644 3090034 &lt;NA&gt; fisheries &lt;- fisheries %&gt;% mutate(continent = case_when( country == &quot;Democratic Republic of the Congo&quot; ~ &quot;Africa&quot;, country == &quot;Hong Kong&quot; ~ &quot;Asia&quot;, country == &quot;Myanmar&quot; ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries %&gt;% filter(is.na(continent)) #&gt; # A tibble: 0 × 5 #&gt; # … with 5 variables: country &lt;chr&gt;, capture &lt;dbl&gt;, aquaculture &lt;dbl&gt;, total &lt;dbl&gt;, continent &lt;chr&gt; Close Solution × Hint fisheries %&gt;% filter(is.na(continent)) fisheries &lt;- ___ %&gt;% mutate(continent = case_when( country == ___ ~ &quot;Africa&quot;, country == ___ ~ &quot;Asia&quot;, country == ___ ~ &quot;Asia&quot;, TRUE ~ continent ) ) fisheries %&gt;% filter(is.na(continent)) Close Hint If still any countries not belonging to a continent then add them to the closest continent. × Solution fisheries &lt;- fisheries %&gt;% mutate(aquaculture_perc = aquaculture / total) The percentage of fish harvest done using aquaculture. Close Solution × Hint fisheries &lt;- ___ %&gt;% mutate(___) Close Hint Add column aquaculture_perc = aquaculture / total and explain the variable. × Solution fisheries %&gt;% group_by(continent) %&gt;% summarize(mean_ap = mean(aquaculture_perc)) #&gt; # A tibble: 5 × 2 #&gt; continent mean_ap #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 #&gt; 2 Americas 0.192 #&gt; 3 Asia 0.367 #&gt; 4 Europe 0.165 #&gt; 5 Oceania 0.150 Close Solution × Hint fisheries %&gt;% # start with the fisheries data frame ___ %&gt;% # group by continent ___(mean_ap = ___) # calculate mean aquaculture Close Hint Calculate the mean aquaculture percentage (we’ll call it mean_ap for short) for continents in the fisheries data. × Solution fisheries_summary_continent &lt;- fisheries %&gt;% group_by(continent) %&gt;% summarize(mean_ap = mean(aquaculture_perc), min_ap = min(aquaculture_perc), max_ap = max(aquaculture_perc)) %&gt;% print() #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Africa 0.0943 0 0.803 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Asia 0.367 0 0.782 #&gt; 4 Europe 0.165 0.00682 0.618 #&gt; 5 Oceania 0.150 0.0197 0.357 Close Solution × Hint fisheries_summary_continent &lt;- fisheries %&gt;% # start with the fisheries data frame ___ %&gt;% # group by continent ___(mean_ap = ___, min_ap = ___, ___) # calculate mean aquaculture Close Hint Now expand your calculations to also calculate the minimum and maximum aquaculture percentage for continents in the fisheries data and store the summary table in a data frame called fisheries_summary_continent. × Solution fisheries_summary_continent %&gt;% arrange(desc(mean_ap)) #&gt; # A tibble: 5 × 4 #&gt; continent mean_ap min_ap max_ap #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Asia 0.367 0 0.782 #&gt; 2 Americas 0.192 0 0.529 #&gt; 3 Europe 0.165 0.00682 0.618 #&gt; 4 Oceania 0.150 0.0197 0.357 #&gt; 5 Africa 0.0943 0 0.803 Close Solution × Hint fisheries_summary_continent %&gt;% # start with the fisheries_summary_continent data frame ___ # order in descending order of mean_ap Close Hint Take the fisheries_summary_continent data frame and order the results in descending order of mean aquaculture percentage. × Solution ggplot(fisheries_summary_continent, aes(y = reorder(continent, mean_ap), x = mean_ap)) + geom_col() + labs( x = &quot;&quot;, y = &quot;&quot;, title = &quot;Average share of aquaculture by continent&quot;, subtitle = &quot;out of total fisheries harvest&quot;, caption = &quot;Source: bit.ly/2VrawTt&quot; ) An example plot Close Solution If you already have read the module about visualizations, then try to make some relevant plots. References "],["sec-plot.html", "Module 16 Data visualization using ggplot 16.1 Learning outcomes 16.2 Introduction to data visualization 16.3 Combining plots into one using patchwork 16.4 Saving graphics 16.5 Different learning paths 16.6 Recap 16.7 Exercises", " Module 16 Data visualization using ggplot This module considers visualization of your data using the ggplot2 package which is a part of tidyverse. R has several systems for making plots, but ggplot2 is one of the most elegant and most versatile. Using ggplot2 you can make plots faster by learning one system and applying it in many different plot types. 16.1 Learning outcomes By the end of this module, you are expected to: Know how to create basic plots using ggplot. Formulate the ideas behind the grammar of graphics. Explain the idea behind aesthetics such as color, fill, and line type. Add geometries to a plot such as a histogram, a boxplot, a barplot, a scatter plot, and a line. Understand how themes can be used to modify the overall look of a plot. Combine multiple plots into a single graphic. Save plots as variables and different image files. The learning outcomes relate to the overall learning goals number 7, 11-14 and 18 of the course. 16.2 Introduction to data visualization The package ggplot2 is a plotting package that makes it simple to create complex plots from data in a data frame. It provides an interface for specifying which variables to plot, how they are displayed, and general visual properties. Hence, only minimal changes are needed, if the underlying data change or if we decide to change from a bar plot to a scatterplot. The package implements the grammar of graphics, a coherent system for describing and building layered plots. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. An excellent introduction to data visualization using ggplot2 is given in the interactive DataCamp course Introduction to data visualization with ggplot2. Please complete the course before continuing. Note that there is a difference between using the pipe %&gt;% operator which passes the output of the previous line of code as the first input of the next line of code and the + operator used between ggplot2 functions for “layering”. That is, you create the plot in layers, separated by +. 16.3 Combining plots into one using patchwork You can combine separate ggplots into the same graphic using the patchwork package. You can install patchwork from CRAN using install.packages('patchwork'). The usage is simple. Plots in two rows: library(ggplot2) library(patchwork) p1 &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp)) p2 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) p1 + p2 The package provides rich support for arbitrarily complex layouts. Code for nesting three plots on top of a third: p3 &lt;- ggplot(mtcars) + geom_smooth(aes(disp, qsec)) p4 &lt;- ggplot(mtcars) + geom_bar(aes(carb)) (p1 | p2 | p3) / p4 For further examples see the documentation pages. 16.4 Saving graphics In general, when you do anlytics using R Markdown, there is no need to save your graphics. This is done automatically. However, in a few cases you may need to save you graphics in different formats. Let us consider a simple plot: library(tidyverse) p &lt;- ggplot(mpg, aes(displ, hwy, colour = class)) + geom_point() p # print it out To save the plot as a bitmap image (png, jpeg etc) have a look at the documentation (?png). Let us try to save the plot as a png file. png(&quot;test1.png&quot;) # open png device for writing p dev.off() # close device #&gt; quartz_off_screen #&gt; 2 png(&quot;test2.png&quot;, width = 1200, height = 600) # use other output width and height in px p dev.off() #&gt; quartz_off_screen #&gt; 2 png(&quot;test3.png&quot;, width = 1200, height = 900) # save a patchwork plot (p1 | p2 | p3) / p4 dev.off() #&gt; quartz_off_screen #&gt; 2 # browseURL(&quot;test1.png&quot;) # to have a look at the file # browseURL(&quot;test3.png&quot;) # to have a look at the file To save the plot as a pdf use pdf(&quot;test1.pdf&quot;) # open pdf device for writing p dev.off() # close device #&gt; quartz_off_screen #&gt; 2 # browseURL(&quot;test1.pdf&quot;) # to have a look at the file If you use LaTeX you may use the tikzDevice package to save plots as TikZ. 16.5 Different learning paths We are all different and you may like different learning styles compared to others. You may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Note these suggestions are not a part of syllabus! A detailed introduction to visualization using ggplot2 is given in Chapters 22-29 in Bryan (2017). A short introduction is given in Chapter 3 in H. Wickham (2017). The ‘Data visualization with ggplot2’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. A good place to see examples are on the main reference page. Follow the link to the function of interest and have a look at the examples. Further advanded possibilities for ggplot2 are given in the interactive DataCamp course Intermediate Data Visualization with ggplot2. 16.6 Recap The tidyverse package ggplot2 is an R package for producing data visualizations. It is based on the Grammar of Graphics by Wilkinson (2005). The grammar of graphics is a coherent system for describing and building layered plots. Graphics are made by grammatical elements such as data, aesthetics, geometries, scales, facets, and themes. Plots are made though aesthetic mappings. That is, variables are mapped to x or y position using aesthetics attributes such as color, shape, or size. A plot is built step by step by adding new layers. Adding layers in this fashion allows for extensive flexibility and customization of plots. Together, the data, aesthetic mappings, and geometric object form a layer. A plot may have multiple layers, for example, when we overlay a scatterplot with a smoothed line. Aesthetics are add in ggplot using the aes function or alternatively in geom_ functions. Geometries (e.g. a boxplot or line) are added to a plot using the geom_ functions. Themes can be applied to the plot using the theme_ functions and control all the non-data ink used to modify the overall look of a plot. Separate ggplots can be combined into the same graphic using the patchwork package. Save plots as variables and different image files using the device functions such as png and pdf. The pipe %&gt;% operator is used to “pipe” the output of the previous line of code as the first input of the next line of code. The + operator in ggplot2 functions is used for “layering”. This means you create the plot in layers, separated by +. 16.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware, you will not learn by giving up to early. Put some effort into finding a solution! 16.7.1 Exercise (gapminder) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). In this exercise, we will demonstrate how relatively simple ggplot2 code can create insightful and aesthetically pleasing plots. As motivation we will create plots that help us better understand trends in world health and economics. Hans Rosling was the co-founder of the Gapminder Foundation, an organization dedicated to educating the public by using data to dispel common myths about the so-called developing world. Hans Rosling conveyed actual data-based trends in a dramatic way of his own, using effective data visualization. Here we will try to answer two questions: Is it a fair characterization of today’s world to say it is divided into Western rich nations and the developing world in Africa, Asia, and Latin America? Has income inequality across countries worsened during the last 40 years? To answer these questions, we will be using the gapminder dataset provided in the dslabs package. This dataset was created using a number of spreadsheets available from the Gapminder Foundation. You can access the table like this: library(tidyverse) library(dslabs) data(gapminder) gapminder %&gt;% as_tibble() #&gt; # A tibble: 10,545 × 9 #&gt; country year infant_mortality life_expectancy fertility population gdp continent region #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; #&gt; 1 Albania 1960 115. 62.9 6.19 1636054 NA Europe Souther… #&gt; 2 Algeria 1960 148. 47.5 7.65 11124892 1.38e10 Africa Norther… #&gt; 3 Angola 1960 208 36.0 7.32 5270844 NA Africa Middle … #&gt; 4 Antigua … 1960 NA 63.0 4.43 54681 NA Americas Caribbe… #&gt; 5 Argentina 1960 59.9 65.4 3.11 20619075 1.08e11 Americas South A… #&gt; 6 Armenia 1960 NA 66.9 4.55 1867396 NA Asia Western… #&gt; 7 Aruba 1960 NA 65.7 4.82 54208 NA Americas Caribbe… #&gt; 8 Australia 1960 20.3 70.9 3.45 10292328 9.67e10 Oceania Austral… #&gt; 9 Austria 1960 37.3 68.8 2.7 7065525 5.24e10 Europe Western… #&gt; 10 Azerbaij… 1960 NA 61.3 5.57 3897889 NA Asia Western… #&gt; # … with 10,535 more rows We start by testing our knowledge regarding differences in child mortality across different countries. For each of the six pairs of countries below, which country do you think had the highest child mortality rates in 2015? Which pairs do you think are most similar? Sri Lanka or Turkey Poland or South Korea Malaysia or Russia Pakistan or Vietnam Thailand or South Africa When answering these questions without data, the non-European countries are typically picked as having higher child mortality rates: Sri Lanka over Turkey, South Korea over Poland, and Malaysia over Russia. It is also common to assume that countries considered to be part of the developing world: Pakistan, Vietnam, Thailand, and South Africa, have similarly high mortality rates. To answer these questions with data, we can use dplyr. For example, for the first comparison we see that: gapminder %&gt;% filter(year == 2015 &amp; country %in% c(&quot;Sri Lanka&quot;,&quot;Turkey&quot;)) %&gt;% select(country, infant_mortality) #&gt; country infant_mortality #&gt; 1 Sri Lanka 8.4 #&gt; 2 Turkey 11.6 Turkey has the higher infant mortality rate. We can use this code on all comparisons and find the following: country infant mortality country infant mortality Sri Lanka 8.4 Turkey 11.6 Poland 4.5 South Korea 2.9 Malaysia 6.0 Russia 8.2 Pakistan 65.8 Vietnam 17.3 Thailand 10.5 South Africa 33.6 We see that the European countries on this list have higher child mortality rates: Poland has a higher rate than South Korea, and Russia has a higher rate than Malaysia. We also see that Pakistan has a much higher rate than Vietnam, and South Africa has a much higher rate than Thailand. It turns out that when Hans Rosling gave this quiz to educated groups of people, the average score was less than 2.5 out of 5, worse than what they would have obtained had they guessed randomly. This implies that we are misinformed. We will try to use visualization to help us being more informed. The west vs. the developing world There is a preconceived notion that the world is divided into two groups: the Western world (Western Europe and North America), characterized by long life spans and small families, versus the developing world (Africa, Asia, and Latin America) characterized by short life spans and large families. But do the data support this dichotomous view? × Solution filter(gapminder, year == 1962) %&gt;% ggplot( aes(fertility, life_expectancy, color = continent)) + geom_point() Most points fall into two distinct categories: Life expectancy around 70 years and 3 or fewer children per family. Life expectancy lower than 65 years and more than 5 children per family. Countries are from the regions we expect. Close Solution × Hint filter(gapminder, year == ___) %&gt;% ggplot( aes(___, ___, color = ___)) + geom_point() Close Hint Make a scatterplot of life expectancy versus fertility rates (average number of children per woman) in 1962. Use continent as color aesthetic. × Solution filter(gapminder, year %in% c(1962, 2012)) %&gt;% ggplot(aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_grid(cols = vars(year)) This plot clearly shows that the majority of countries have moved from the developing world cluster to the western world one. In 2012, the western versus developing world view no longer makes sense. This is particularly clear when comparing Europe to Asia, the latter of which includes several countries that have made great improvements. Close Solution × Hint filter(gapminder, ___ %in% c(1962, 2012)) %&gt;% ggplot(aes(___, ___, col = ___)) + geom_point() + facet_grid(cols = vars(___)) Close Hint In 1962, “the West versus developing world” view was grounded in some reality. Is this still the case 50 years later? We could easily plot the 2012 data in the same way we did for 1962. To make comparisons, side by side plots are preferable. In ggplot2, we can achieve this by faceting variables and making a plot for each year. That is, you must filter by years 1962 and 2012 and add the layer facet_grid, which automatically separates the plots. × Solution years &lt;- c(1962, 1970, 1980, 1990, 2000, 2012) continents &lt;- c(&quot;Europe&quot;, &quot;Asia&quot;) gapminder %&gt;% filter(year %in% years &amp; continent %in% continents) %&gt;% ggplot( aes(fertility, life_expectancy, col = continent)) + geom_point() + facet_wrap(vars(year)) The plot clearly shows how most Asian countries have improved at a much faster rate than European ones. Close Solution × Hint gapminder %&gt;% filter(year %in% ___ &amp; continent %in% ___) %&gt;% ggplot(aes(___)) + geom_point() + facet_wrap(___) Close Hint To explore the transformation through the years, make a plot for the years 1962, 1970, 1980, 1990, 2000, and 2012 considering Europe and Asia. How has Asia transformed through the years compared to Europe? Since we consider many years, we will not want all the plots on the same row. Instead, we will want to use multiple rows and columns. The function facet_wrap permits us to do this by automatically wrapping the series of plots. Infobox - Scales The default choice of the range of the axes is important. When not using facet, this range is determined by the data shown in the plot. When using facet, this range is determined by the data shown in all plots and therefore kept fixed across plots. This makes comparisons across plots much easier. For example, in the above plot, we can see that life expectancy has increased and the fertility has decreased across most countries. We see this because the cloud of points moves. This is not the case if we adjust the scales: In the plot above, we have to pay special attention to the range to notice that the plot on the right has a larger life expectancy. × Solution gapminder %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot(aes(fertility, life_expectancy, col = year)) + geom_point() Close Solution × Hint gapminder %&gt;% filter(___) %&gt;% ggplot(aes(___)) + geom_point() Close Hint Illustrate the transformation for Asia using a single plot where year is used as color aesthetic. Time series plots The visualizations above effectively illustrate that data no longer supports the Western versus developing world view. Once we see these plots, new questions emerge. For example, which countries are improving more and which ones less? Was the improvement constant during the last 50 years or was it more accelerated during certain periods? For a closer look that may help answer these questions, we introduce time series plots. Time series plots have time in the x-axis and an outcome or measurement of interest on the y-axis. For example, here is a trend plot of United States fertility rates: gapminder %&gt;% filter(country == &quot;United States&quot;) %&gt;% ggplot(aes(year, fertility)) + geom_point() We see that the trend is not linear at all. Instead there is sharp drop during the 1960s and 1970s to below 2. Then the trend comes back to 2 and stabilizes during the 1990s. When the points are regularly and densely spaced, as they are here, we create curves by joining the points with lines, to convey that these data are from a single series, here a country. To do this, we use the geom_line function instead of geom_point. × Solution gapminder %&gt;% filter(country == &quot;United States&quot;) %&gt;% ggplot(aes(year, fertility)) + geom_line() Close Solution Make a lineplot showing the time series of fertility versus year for United States. × Solution countries &lt;- c(&quot;South Korea&quot;, &quot;Germany&quot;) gapminder %&gt;% filter(country %in% countries) %&gt;% ggplot(aes(year, fertility, col = country)) + geom_line() The plot clearly shows how South Korea's fertility rate dropped drastically during the 1960s and 1970s, and by 1990 had a similar rate to that of Germany. Close Solution × Hint gapminder %&gt;% filter(country %in% ___) %&gt;% ggplot(aes(year, fertility, col = ___)) + geom_line() Close Hint Lineplots is particularly helpful when we look at more countries. Make a lineplot showing the time series of fertility versus year for South Korea and Germany. Use country as color aesthetic. × Solution gapminder %&gt;% filter(country %in% countries) %&gt;% ggplot(aes(year, life_expectancy, col = country)) + geom_line() The plot clearly shows how an improvement in life expectancy followed the drops in fertility rates. In 1960, Germans lived 15 years longer than South Koreans, although by 2010 the gap is completely closed. It exemplifies the improvement that many non-western countries have achieved in the last 40 years. Close Solution Make a lineplot showing the time series of life expectancy versus year for South Korea and Germany. Use country as color aesthetic. Data transformations We now shift our attention to the second question related to the commonly held notion that wealth distribution across the world has become worse during the last decades. When general audiences are asked if poor countries have become poorer and rich countries become richer, the majority answers yes. By using stratification, histograms, smooth densities, and boxplots, we will be able to understand if this is in fact the case. First we learn how transformations can sometimes help provide more informative summaries and plots. The gapminder data table includes a column with the countries’ gross domestic product (GDP). GDP measures the market value of goods and services produced by a country in a year. The GDP per person is often used as a rough summary of a country’s wealth. Here we divide this quantity by 365 to obtain the more interpretable measure dollars per day. Using current U.S. dollars as a unit, a person surviving on an income of less than $2 a day, is defined to be living in absolute poverty. We add this variable to the data table: gapminder &lt;- gapminder %&gt;% mutate(dollars_per_day = gdp/population/365) The GDP values are adjusted for inflation and represent current U.S. dollar, so these values are meant to be comparable across the years. Of course, these are country averages and within each country there is much variability. All the graphs and insights described below relate to country averages and not to individuals. Here is a histogram of per day incomes from 1970: past_year &lt;- 1970 gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) We use the color = \"black\" argument to draw a boundary and clearly distinguish the bins. In this plot, we see that for the majority of countries, averages are below $10 a day. However, the majority of the x-axis is dedicated to the 35 countries with averages above $10. So the plot is not very informative about countries with values below $10 a day. It might be more informative to quickly be able to see how many countries have average daily incomes of about $1 (extremely poor), $2 (very poor), $4 (poor), $8 (middle), $16 (well off), $32 (rich), $64 (very rich) per day. These changes are multiplicative and log transformations convert multiplicative changes into additive ones: when using base 2, a doubling of a value turns into an increase by 1. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(log2(dollars_per_day))) + geom_histogram(binwidth = 1, color = &quot;black&quot;) This provides a close-up of the mid to lower income countries. Close Solution Make a histogram of log2(dollars_per_day) from 1970. Infobox - Which base? In the case above, we used base 2 in the log transformations. Other common choices are base \\(\\mathrm{e}\\) (the natural log) and base 10. In general, we do not recommend using the natural log for data exploration and visualization. This is because while \\(2^2, 2^3, 2^4, \\dots\\) or \\(10^2, 10^3, \\dots\\) are easy to compute in our heads, the same is not true for \\(\\mathrm{e}^2, \\mathrm{e}^3, \\dots\\), so the scale is not intuitive or easy to interpret. In the dollars per day example, we used base 2 instead of base 10 because the resulting range is easier to interpret. The range of the values being plotted is 0.327, 48.885. In base 10, this turns into a range that includes very few integers: just 0 and 1. With base two, our range includes -2, -1, 0, 1, 2, 3, 4, and 5. It is easier to compute \\(2^x\\) and \\(10^x\\) when \\(x\\) is an integer and between -10 and 10, so we prefer to have smaller integers in the scale. Another consequence of a limited range is that choosing the binwidth is more challenging. With log base 2, we know that a binwidth of 1 will translate to a bin with range \\(x\\) to \\(2x\\). For an example in which base 10 makes more sense, consider population sizes. A log base 10 is preferable since the range for these is: filter(gapminder, year == past_year) %&gt;% summarize(min = min(population), max = max(population)) #&gt; min max #&gt; 1 46075 8.09e+08 Here is the histogram of the transformed values: gapminder %&gt;% filter(year == past_year) %&gt;% ggplot(aes(log10(population))) + geom_histogram(binwidth = 0.5, color = &quot;black&quot;) In the above, we quickly see that country populations range between ten thousand and ten billion. There are two ways we can use log transformations in plots. We can log the values before plotting them or use log scales on the axes. Both approaches are useful and have different strengths. If we log the data, we can more easily interpret intermediate values in the scale. For example, if we see: ----1----x----2--------3---- for log transformed data, we know that the value of \\(x\\) is about 1.5. If the scales are logged: ----1----x----10------100--- then, to determine x, we need to compute \\(10^{1.5}\\), which is not easy to do in our heads. The advantage of using logged scales is that we see the original values on the axes. However, the advantage of showing logged scales is that the original values are displayed in the plot, which are easier to interpret. For example, we would see “32 dollars a day” instead of “5 log base 2 dollars a day”. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) The plot from Q8 is the same except the values on the x-axis. Close Solution Make a histogram of dollars_per_day from 1970 using a log2 scale on the x-axis. Compare it to the plot from Question 8. Hint: you can use the scale_x_continuous function with trans = \"log2\". The histograms in Questions 8 and 9 have two bumps: one at about 4 and another at about 32. In statistics these bumps are sometimes referred to as modes. The mode of a distribution is the value with the highest frequency. The mode of the normal distribution is the average. When a distribution, like the one above, does not monotonically decrease from the mode, we call the locations where it goes up and down again local modes and say that the distribution has multiple modes indicating different distributions for different groups. The histogram above suggests that the 1970 country income distribution has two modes: one at about 2 dollars per day (1 in the log 2 scale) and another at about 32 dollars per day (5 in the log 2 scale). However, the histogram does not show us if the two groups of countries are west versus the rest. Let us create the group column: gapminder &lt;- gapminder %&gt;% mutate(group = case_when( region %in% c(&quot;Western Europe&quot;, &quot;Northern Europe&quot;,&quot;Southern Europe&quot;, &quot;Northern America&quot;, &quot;Australia and New Zealand&quot;) ~ &quot;West&quot;, TRUE ~ &quot;Rest&quot;)) %&gt;% as_tibble() × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = vars(group)) + scale_x_continuous(trans = &quot;log2&quot;) The plot confirms the west vs the rest dichotomy. Close Solution × Hint gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + facet_grid(cols = ___) + scale_x_continuous(trans = &quot;log2&quot;) Close Hint Make a histogram of dollars_per_day from 1970 using a log2 scale and facet it by group. Is there a west versus the rest dichotomy? The exploratory data analysis above has revealed two characteristics about average income distribution in 1970. Using a histogram, we found a bimodal distribution with the modes relating to poor and rich countries. We will try to visualize these summaries in one plot. × Solution gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(group, dollars_per_day)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) + geom_point() Close Solution × Hint gapminder %&gt;% filter(year == past_year &amp; !is.na(gdp)) %&gt;% ggplot(aes(group, dollars_per_day)) + geom____() + scale_y_continuous(trans = &quot;log2&quot;) + geom____() Close Hint Make a boxplot (geom_boxplot) of dollars_per_day (y-axis) versus group (x-axis) from 1970 using a log2 scale. Also add a the data using geom_point(). Data exploration clearly shows that in 1970 there was a “west versus the rest” dichotomy. But does this dichotomy persist? We first have to be a little careful here since there are more countries represented in 2010 than in 1970: the total counts are larger. One reason for this is that several countries were founded after 1970. For example, the Soviet Union divided into several countries during the 1990s. Another reason is that data was available for more countries in 2010. Hence we only have to consider the countries with data available for both years: past_year &lt;- 1970 present_year &lt;- 2010 years &lt;- c(past_year, present_year) country_list_1 &lt;- gapminder %&gt;% filter(year == past_year &amp; !is.na(dollars_per_day)) %&gt;% pull(country) country_list_2 &lt;- gapminder %&gt;% filter(year == present_year &amp; !is.na(dollars_per_day)) %&gt;% pull(country) country_list &lt;- intersect(country_list_1, country_list_2) We can now filter the rows by years and country_list. × Solution gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(year ~ group) The income gap between rich and poor countries has narrowed considerably during the last 40 years Close Solution × Hint gapminder %&gt;% filter(year %in% ___ &amp; country %in% ___) %&gt;% ggplot(aes(dollars_per_day)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(___) Close Hint Make a histogram of dollars_per_day from 1970 and 2010 using a log2 scale and facet it by group and year. Does the dichotomy persist? × Solution gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% mutate(year = factor(year)) %&gt;% ggplot(aes(group, dollars_per_day, fill = year)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% mutate(year = factor(___)) %&gt;% ggplot(aes(group, dollars_per_day, fill = ___)) + geom_boxplot() + scale_y_continuous(trans = &quot;log2&quot;) Close Hint Make a boxplot of dollars_per_day versus group from 1970 and 2010 using a log2 scale. Use year as fill aesthetic. Hint: you must convert year to a factor using mutate(year = factor(year)). The previous data exploration suggested that the income gap between rich and poor countries has narrowed considerably during the last 40 years. We used a series of histograms and boxplots to see this. Let us now shift to density plots. Let us start by noting that density plots for income distribution in 1970 and 2010 deliver the message that the gap is closing: gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day)) + geom_density(fill = &quot;grey&quot;) + scale_x_continuous(trans = &quot;log2&quot;) + facet_grid(cols = vars(year)) In the 1970 plot, we see two clear modes: poor and rich countries. In 2010, it appears that some of the poor countries have shifted towards the right, closing the gap. The next message we need to convey is that the reason for this change in distribution is that several poor countries became richer, rather than some rich countries becoming poorer. To do this, we can assign a color to the groups we identified during data exploration. gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day, fill = group)) + scale_x_continuous(trans = &quot;log2&quot;) + geom_density(alpha = 0.2) + facet_grid(cols = vars(year)) Note the default is to have the area represented by each distribution add up to 1, regardless of the size of each group: the number of countries in the ‘west’ group is 21 and in the ‘rest’ group is 87. We may use count on the y-axis instead: p &lt;- gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% ggplot(aes(dollars_per_day, y = ..count.., fill = group)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + facet_grid(cols = vars(year)) p + geom_density(alpha = 0.2) × Solution p + geom_density(alpha = 0.2, bw = 0.75) This plot now shows that the developing world distribution is changing. Close Solution To get densities smoother, use bw = 0.75 argument so that the same bandwidth is used in each density. Comment on the plot. As a final point, we note that in these distributions the weight of every country is the same. So if most of the population is improving, but living in a very large country, such as China, we might not appreciate this. We can actually weight the smooth densities using the weight mapping argument. We modify the dataset: gapminder &lt;- gapminder %&gt;% filter(year %in% years &amp; country %in% country_list) %&gt;% group_by(year) %&gt;% mutate(weight = population/sum(population)*2) %&gt;% ungroup() × Solution gapminder %&gt;% ggplot(aes(dollars_per_day, fill = group, weight = weight)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of developing countries earning more than $16 a day increased substantially. Close Solution × Hint gapminder %&gt;% ggplot(aes(dollars_per_day, fill = group, weight = ___)) + scale_x_continuous(trans = &quot;log2&quot;, limit = c(0.125, 300)) + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(cols = vars(year)) Close Hint Modify the ggplot function with a weight argument and plot the density (with area equal 1). 16.7.2 Exercise (profit) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit (provided by the tfa package) containing quarterly financial records for each costumer, product, etc.: # remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;, upgrade = FALSE) # upgrade first library(tfa) library(skimr) glimpse(profit) #&gt; Rows: 24,546 #&gt; Columns: 9 #&gt; $ Quarter &lt;dbl&gt; 3, 1, 4, 1, 4, 3, 4, 3, 4, 1, 1, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 2, … #&gt; $ Channel &lt;chr&gt; &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BRH&quot;, &quot;ATM&quot;, &quot;BRH&quot;, &quot;BR… #&gt; $ `Customer ID` &lt;chr&gt; &quot;FRT&quot;, &quot;MRT&quot;, &quot;PBI&quot;, &quot;PBI&quot;, &quot;MRT&quot;, &quot;MAM&quot;, &quot;PBI&quot;, &quot;FRT&quot;, &quot;PBI&quot;, &quot;PB… #&gt; $ Country &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;US… #&gt; $ `Product Line` &lt;chr&gt; &quot;Credit Products&quot;, &quot;Credit Products&quot;, &quot;Deposit Products&quot;, &quot;Deposit… #&gt; $ Revenue &lt;dbl&gt; 6044, 4686, 6063, 4682, 6320, 2993, 3355, 5716, 3347, 2624, 3629, … #&gt; $ `Product Cost` &lt;dbl&gt; 3998, 3229, 7440, 6127, 7913, 1034, 4355, 5617, 4229, 1960, 4650, … #&gt; $ `Customer Service Cost` &lt;dbl&gt; 413, 643, 1842, 1118, 1854, 242, 1027, 876, 425, 264, 700, 1482, 4… #&gt; $ Profit &lt;dbl&gt; 1633, 815, -3219, -2563, -3447, 1718, -2027, -777, -1307, 401, -17… skim(profit) Table 16.1: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 4 numeric 5 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Quarter 0 1 2.50 1.12 1 2 2 3 4 ▇▇▁▇▇ Revenue 0 1 120.22 420.96 1 12 41 74 7540 ▇▁▁▁▁ Product Cost 0 1 100.07 375.51 0 9 29 68 9256 ▇▁▁▁▁ Customer Service Cost 0 1 17.42 67.43 0 1 5 12 1865 ▇▁▁▁▁ Profit 0 1 2.71 154.89 -4139 -7 0 9 3664 ▁▁▇▁▁ Make a barplot that shows the total profitability of the product lines. Use the following steps: × Solution profit &lt;- profit %&gt;% mutate(across(where(is.character), as.factor)) Close Solution × Hint profit &lt;- profit %&gt;% mutate(across(where(is.___), as.___)) Close Hint        a) Convert all character columns to factor columns. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = `Product Line`, y = Profit)) + geom_col() Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = sum(___)) %&gt;% ggplot(aes(x = ___, y = ___)) + geom_col() Close Hint        b) Group by product line, calculate the total profit and plot profit for each product line. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() # Alternatively you can reorder the data frame before calling ggplot profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% arrange(Profit) %&gt;% mutate(`Product Line` = factor(`Product Line`, levels = `Product Line`, ordered = TRUE)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint 2 profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(___), y = Profit)) + geom_col() Close Hint 2 × Hint 1 See the last section on this webpage. Close Hint 1        c) Plot profit for each product line where product line is reordered based on total profit. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) Close Solution × Hint Try to google 'ggplot add title'. Close Hint        d) Add a title to the plot using labs. × Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint Try to google 'ggplot2 rotate axis labels'. Close Hint        e) Rotate the x-axis labels 90 degrees. × Solution dat &lt;- profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) dat %&gt;% slice_min(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Third Party Products 2209 dat %&gt;% slice_max(Profit) #&gt; # A tibble: 1 × 2 #&gt; `Product Line` Profit #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Credit Products 31016 Close Solution × Hint dat &lt;- profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) dat %&gt;% slice_min(___) dat %&gt;% ___ Close Hint        f) Which product line is best and worst? × Solution profit %&gt;% group_by(`Product Line`, Quarter) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(Quarter)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Some product lines have quite different earnings in different quarters. Close Solution × Hint profit %&gt;% group_by(`Product Line`, ___) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Product Line`, Profit), y = Profit)) + geom_col() + facet_grid(cols = vars(___)) + labs(title = &quot;Total profit for each product line&quot;) + xlab(&quot;Product Line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the product lines in each quarter. Are there details we have missed in Question 1? × Solution profit %&gt;% ggplot(aes(y = Profit, x = `Product Line`)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) The profit varies more for three of the product lines. Close Solution × Hint profit %&gt;% ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each product line&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot of profitability of the product lines. Any insight? × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Lowest and highest total profit is for PBI and WEM, respectively. Close Solution × Hint profit %&gt;% group_by(___) %&gt;% summarise(Profit = sum(___)) %&gt;% ggplot(aes(x = reorder(___, ___), y = Profit)) + geom_col() + labs(title = &quot;Total profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the total profitability of the customers. Which customer is best and worst? × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = mean(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Since the number of transactions are not the same, the order of customers will not be the same. Close Solution × Hint profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(Profit = ___) %&gt;% ggplot(aes(x = reorder(`Customer ID`, Profit), y = Profit)) + geom_col() + labs(title = &quot;Mean profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a barplot that shows the mean profitability of the customers. Which customer is best and worst? Compare against Question 4 and discuss. × Solution profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(ctr = n(), `Total Profit` = sum(Profit)) %&gt;% ggplot(aes(x = reorder(`Customer ID`, `Total Profit`), y = ctr, fill = `Total Profit`)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit %&gt;% group_by(`Customer ID`) %&gt;% summarise(ctr = ___, `Total Profit` = sum(___)) %&gt;% ggplot(aes(x = reorder(___, `Total Profit`), y = ctr, fill = ___)) + geom_col() + labs(title = &quot;Number of transactions (rows) for each customer&quot;) + xlab(&quot;Customer&quot;) + ylab(&quot;Transactions&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a plot illustrating number of transactions for each customer. Use total profit as fill atheistic. × Solution profit %&gt;% ggplot(aes(y = Profit, x = `Customer ID`)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Solution × Hint profit %&gt;% ggplot(aes(y = ___, x = ___)) + geom_boxplot() + labs(title = &quot;Profit for each customer&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) Close Hint Make a boxplot illustrating the profit for each customer. 16.7.3 Exercise (COVID-19) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Countries around the world are responding to an outbreak of respiratory illness caused by a novel corona virus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries. The data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Corona virus repository. The corona virus package provides a tidy format dataset of the 2019 Novel Corona virus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily. First load the following packages: library(tidyverse) library(lubridate) # package for handling dates The data frame called coronavirus in the coronavirus package provides a daily summary of the Corona virus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. Since we just need the dataset we load it using read_csv: coronavirus &lt;- read_csv( &quot;https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv&quot;, col_types = cols( date = col_date(format = &quot;&quot;), province = col_character(), country = col_character(), lat = col_double(), long = col_double(), type = col_character(), cases = col_double() ) ) We calculate the total number of cases per day, cumulative numbers and days since first record: dat &lt;- coronavirus %&gt;% group_by(country, date, type) %&gt;% summarise(tot_cases = sum(cases)) %&gt;% group_by(country, type) %&gt;% arrange(date) %&gt;% mutate(cumulative_cases = cumsum(tot_cases)) %&gt;% ungroup() %&gt;% mutate( days_elapsed = as.numeric(date - min(date)), year = year(date) ) %&gt;% print() #&gt; # A tibble: 332,865 × 7 #&gt; country date type tot_cases cumulative_cases days_elapsed year #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 2020-01-22 confirmed 0 0 0 2020 #&gt; 2 Afghanistan 2020-01-22 death 0 0 0 2020 #&gt; 3 Afghanistan 2020-01-22 recovered 0 0 0 2020 #&gt; 4 Albania 2020-01-22 confirmed 0 0 0 2020 #&gt; 5 Albania 2020-01-22 death 0 0 0 2020 #&gt; 6 Albania 2020-01-22 recovered 0 0 0 2020 #&gt; 7 Algeria 2020-01-22 confirmed 0 0 0 2020 #&gt; 8 Algeria 2020-01-22 death 0 0 0 2020 #&gt; 9 Algeria 2020-01-22 recovered 0 0 0 2020 #&gt; 10 Andorra 2020-01-22 confirmed 0 0 0 2020 #&gt; # … with 332,855 more rows × Solution dat %&gt;% group_by(date, type) %&gt;% summarise(tot_cases = sum(tot_cases)) %&gt;% print() %&gt;% ggplot(aes(x = date, y = tot_cases)) + geom_col() + facet_grid(rows = vars(type), scales = &quot;free&quot;) + labs( title = &quot;Number of Covid 19 cases per day&quot;, y = &quot;cases&quot; ) #&gt; # A tibble: 1,707 × 3 #&gt; # Groups: date [569] #&gt; date type tot_cases #&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 2020-01-22 confirmed 557 #&gt; 2 2020-01-22 death 17 #&gt; 3 2020-01-22 recovered 30 #&gt; 4 2020-01-23 confirmed 98 #&gt; 5 2020-01-23 death 1 #&gt; 6 2020-01-23 recovered 2 #&gt; 7 2020-01-24 confirmed 286 #&gt; 8 2020-01-24 death 8 #&gt; 9 2020-01-24 recovered 7 #&gt; 10 2020-01-25 confirmed 492 #&gt; # … with 1,697 more rows Close Solution × Hint 2 dat %&gt;% group_by(date, type) %&gt;% summarise(tot_cases = sum(tot_cases)) %&gt;% print() %&gt;% ggplot(aes(x = ___, y = ___)) + geom_col() + facet_grid(rows = vars(___), scales = &quot;___&quot;) + labs( title = &quot;___&quot;, y = &quot;___&quot; ) Close Hint 2 × Hint 1 dat %&gt;% group_by(date, ___) %&gt;% summarise(tot_cases = sum(___)) Note you must aggegrate the numbers for the countries. Close Hint 1 Calculate and plot the number of confirmed, death and recovered cases per day given date using facet_grid and geom_col. Consider the following set of countries: countries &lt;- c( &quot;China&quot;, &quot;France&quot;, &quot;Denmark&quot;, &quot;US&quot;, &quot;Italy&quot; ) × Solution dat %&gt;% filter(type == &quot;death&quot;, country %in% countries) %&gt;% ggplot(aes(x = days_elapsed, y = cumulative_cases, color = country)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;Cumulative number of deaths&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Solution × Hint 2 dat %&gt;% filter(type == &quot;death&quot;, country %in% countries) %&gt;% ggplot(aes(x = ___, y = ___, color = ___)) + geom_line() + theme(legend.position = &quot;bottom&quot;) + labs( x = str_c(&quot;Days since &quot;, min(dat$date)), y = &quot;___&quot;, title = &quot;Cumulative deaths from COVID-19, selected countries&quot; ) Close Hint 2 × Hint 1 dat %&gt;% filter(type == &quot;___&quot;, country %in% ___) %&gt;% First you have to filter type and country Close Hint 1 Plot a lineplot of the cumulative number of deaths as a function of days elapsed for the selected countries. Use country as color aesthetic. Since the countries have different population sizes, we would like to calculate some numbers relative to the population size. First we need population sizes for each country. They are given in the dataset world_pop in the tfa package: world_pop &lt;- tfa::world_pop %&gt;% filter(country %in% countries) %&gt;% print() #&gt; # A tibble: 1,505 × 3 #&gt; country year pop #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 1800 321675013 #&gt; 2 China 1801 324408862 #&gt; 3 China 1802 327165946 #&gt; 4 China 1803 329946461 #&gt; 5 China 1804 332750607 #&gt; 6 China 1805 335578586 #&gt; 7 China 1806 338430598 #&gt; 8 China 1807 341306850 #&gt; 9 China 1808 344207546 #&gt; 10 China 1809 347132894 #&gt; # … with 1,495 more rows We can join the datasets using: dat &lt;- dat %&gt;% filter(country %in% countries) %&gt;% left_join(world_pop) %&gt;% print() #&gt; # A tibble: 8,535 × 8 #&gt; country date type tot_cases cumulative_cases days_elapsed year pop #&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 China 2020-01-22 confirmed 548 548 0 2020 1424548266 #&gt; 2 China 2020-01-22 death 17 17 0 2020 1424548266 #&gt; 3 China 2020-01-22 recovered 28 28 0 2020 1424548266 #&gt; 4 Denmark 2020-01-22 confirmed 0 0 0 2020 5796800 #&gt; 5 Denmark 2020-01-22 death 0 0 0 2020 5796800 #&gt; 6 Denmark 2020-01-22 recovered 0 0 0 2020 5796800 #&gt; 7 France 2020-01-22 confirmed 0 0 0 2020 65721165 #&gt; 8 France 2020-01-22 death 0 0 0 2020 65721165 #&gt; 9 France 2020-01-22 recovered 0 0 0 2020 65721165 #&gt; 10 Italy 2020-01-22 confirmed 0 0 0 2020 59132073 #&gt; # … with 8,525 more rows any(is.na(dat)) # check if any missing values #&gt; [1] FALSE × Solution dat &lt;- dat %&gt;% mutate(tot_cases_pop = 100000 * tot_cases/pop) Close Solution Calculate tot_cases_pop as number of cases per 100000 inhabitants. That is, total cases divided by population and multiplied by 100000. × Solution dat %&gt;% filter(date &gt;= today() - days(21), type == &quot;confirmed&quot;) %&gt;% ggplot(aes(x = date, y = tot_cases_pop, fill = country)) + geom_col(position = position_dodge2()) Close Solution × Hint 2 dat %&gt;% filter(date &gt;= today() - days(21), type == ___) %&gt;% ggplot(aes(x = date, y = ___, fill = ___)) + geom_col(position = position_dodge2()) Close Hint 2 × Hint 1 # Use this to find date 21 days ago today() - days(21) #&gt; [1] &quot;2021-07-23&quot; Close Hint 1 Plot the number of confirmed cases per 100000 inhabitants for the last 21 days. Use country as fill aesthetic. × Solution dat %&gt;% filter(date &gt;= today() - days(14), country == &quot;Denmark&quot;, type == &quot;confirmed&quot;) %&gt;% ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Solution × Hint dat %&gt;% filter(date &gt;= ___, country == ___, type == ___) %&gt;% ggplot(aes(x = date, y = tot_cases_pop)) + geom_col() Close Hint Plot the number of confirmed cases per 100000 inhabitants in Denmark for the last 14 days. 16.7.4 Exercise (Lego and sales) Use the exercise R Markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider (simulated) data of Lego sales in 2018 for a sample of customers who bought Legos in the U.S. The dataset is called lego_sales. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running ?lego_sales in your Console. You need the tidyverse package as usual and the dsbox package for the data. library(tidyverse) library(dsbox) # install using devtools::install_github(&quot;rstudio-education/dsbox&quot;) Answer the following questions using a table with numbers and try to visualize it. For each question, state your answer in a sentence, e.g. “The first three common names of purchasers are …”. What are the three most common first names of purchasers? What are the three most common themes of Lego sets purchased? Among the most common theme of Lego sets purchased, what is the most common subtheme? × Hint Use the case_when() function. Close Hint Create a new variable called age_group and group the ages into the following categories: “18 and under”, “19 - 25”, “26 - 35”, “36 - 50”, “51 and over”. × Hint You may need to consider quantity of purchases. Close Hint Which age group has purchased the highest number of Lego sets. × Hint Hint: You will need to consider quantity of purchases as well as price of Lego sets. Close Hint Which age group has spent the most money on Legos? Come up with a question you want to answer using these data, and write it down. Then, create a data visualization that answers the question, and explain how your visualization answers the question. References "],["sec-project.html", "Module 17 Mandatory R project 17.1 Learning outcomes 17.2 R project", " Module 17 Mandatory R project 17.1 Learning outcomes By the end of this module, you are expected to have: Know how the assignment is given. Know how your group report is handed in. Know how to peer grade other groups’ report. After handing in and grading the report you should have practiced: How to manage a code in a collaborative working environment. Handling data such as import, tidy, transform, visualize and export. Developing well-structured code. Performing testing and debugging. How to implement/code selected algorithms. Applying analytical techniques on data. Applying relevant methods, algorithms and techniques from this course in order to solve a specific problem. Independently handling data. Independently analyzing data given a relevant research question. Interpreting and discuss results based on a data analysis in relation to the relevant academic literature. Communicating results from applied research in a scientific way, e.g. using literate programming. The learning outcomes relate to the overall learning goals number 6-14, 17 and 18 of the course. 17.2 R project In week 48 you must write a mandatory R project in groups. Moreover, for being qualified for exam participation each student must do individual peer grading using the on-line platform Peergrade. The assignment will be available in the system at the opening time. It will be provided in R Markdown and include a description of the different questions which must be answered and links to the data sources needed. You must hand in the assignment in groups. That is, each group only hands in once, and simply select the group members from a list in the system. Make sure to do this very carefully! Each group must hand in the R Markdown source file and the rendered html file. When the peer-grading period starts, you must do peer evaluation based on a guiding solution of the project assignment. This step is done individually. The schedule for the project assignment is: Time Description 19/11 8:00: Assignment becomes available. During week 48: TAs inform you about time slots for online help. 26/11 24:00: Deadline for handing in your solution in Peergrade. 26/11 24:00: Peer grading starts. 30/11 24:00: Deadline for completing the peer grading in Peergrade. It is important that you use your university email as login, so we can identify you i Peergrade. Please find a guide on how to use the system here. "],["sec-maps.html", "Module 18 Spatial data and maps 18.1 Learning outcomes 18.2 Services for obtatining spatial data 18.3 Calculating distances 18.4 Geocoding and reverse geocoding 18.5 Adding markers and routes to a map", " Module 18 Spatial data and maps Spatial data, also known as geospatial data, is a term used to describe any data related to or containing information about a specific location on a surface (often a map). We will consider distance matrix calculations for finding the shortest distance/travel time between a set of origins and destinations, geocoding which is the process of converting an address to geographic coordinates (latitude, longitude) and reverse geocoding which is the opposite process of converting a location as described by geographic coordinates (latitude, longitude) to a human-readable address or place name. Finally, we consider how to display spatial data on a map. 18.1 Learning outcomes By the end of this module, you are expected to be able to: Calculate euclidean, manhattan, etc. distances. Calculate a distance matrix, i.e. shortest paths between places using the Google and Bing API. Geocode an address using the Google and Bing API. Add markers and routes (lines) on a map. 18.2 Services for obtatining spatial data Often you need to connect to a service using an API for obtaining spatial data. The most common is Google and Bing (Microsoft) and to use the services you need an API key. Another service is also Here. If you use Google Maps you can obtain an API key here. Modest to light use is free; however, you need a valid credit card. Note you must enable the APIs you intend to use. Google in fact has several services for geo-related solutions. For example, the Maps Static API provides map images, while the Geocoding API provides geocoding and reverse geocoding services. You need to enable the APIs before you use them. You will only need to do that once, and then they will be ready for you to use. Enabling the APIs just means clicking a few radio buttons on the Google Maps Platform web interface. We will be using the ggmap package for Google services. You can add the API key using: library(ggmap) register_google(key = &quot;[your key]&quot;, write = TRUE) Sys.getenv(&quot;GGMAP_GOOGLE_API_KEY&quot;) Note the key is stored in the environment object GGMAP_GOOGLE_API_KEY. Moreover, it is saved in the file .Renviron so that it is automatically reloaded when you restart R. If you use Bing Maps you can obtain an API key here. No credit card is needed. You can add the API key using: usethis::edit_r_environ() # opens the .Renviron file Sys.setenv(BING_MAPS_API_KEY=[your key]) # so you don&#39;t have to restart R Add the line BING_MAPS_API_KEY=[your key] and save the file. Note your API keys is private and unique to you, so be careful not to share it online! 18.3 Calculating distances If you need to calculate euclidean, manhattan, etc. distances, you can use the dist R function: coord &lt;- matrix(c(0,0, 0,1, 1,0, 1,1), ncol = 2, byrow = TRUE) coord #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; [3,] 1 0 #&gt; [4,] 1 1 dist(coord) #&gt; 1 2 3 #&gt; 2 1.00 #&gt; 3 1.00 1.41 #&gt; 4 1.41 1.00 1.00 as.matrix(dist(coord)) #&gt; 1 2 3 4 #&gt; 1 0.00 1.00 1.00 1.41 #&gt; 2 1.00 0.00 1.41 1.00 #&gt; 3 1.00 1.41 0.00 1.00 #&gt; 4 1.41 1.00 1.00 0.00 However, euclidean distances are often a poor approximation of shortest path lengths. 18.3.1 Using Google Maps Remember to have set your API key and activate the Distance Matrix API service on the Google Cloud Platform. We consider the following places: library(ggmap) library(tidyverse) dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat #&gt; # A tibble: 5 × 3 #&gt; Id Shop Address #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark To calculate a distance matrix we use the mapdist function: mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Golfvej 5, 7400 Herning, Denmark&quot;) #&gt; # A tibble: 1 × 9 #&gt; from to m km miles seconds minutes hours mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Golfvej 5, 740… 85637 85.6 53.2 4407 73.4 1.22 driv… Note Google returns results for the fastest path between the two points. Let us try to define a function which calculate all the distances: #&#39; Calculate the distance matrix in long format. #&#39; #&#39; @param address A vector of addresses. #&#39; @param mode Driving, bicycling, walking, or transit. #&#39; @param symmetric Use symmetric distances (half the number of queries). #&#39; @return A data frame with the results #&#39; @note The API returns results for the fastest route. goo_calc_distances &lt;- function(address, mode = &quot;driving&quot;, symmetric = TRUE) { datDist &lt;- expand_grid(id_from = 1:length(address), id_to = 1:length(address)) datDist &lt;- datDist %&gt;% filter(id_from != id_to) if (symmetric) datDist &lt;- datDist %&gt;% filter(id_from &lt; id_to) datDist &lt;- datDist %&gt;% mutate(from = address[id_from], to = address[id_to]) res &lt;- mapdist(from = datDist %&gt;% pull(from), to = datDist %&gt;% pull(to), mode = mode) return(left_join(datDist, res, by = c(&quot;from&quot;, &quot;to&quot;))) } datDistGoo &lt;- goo_calc_distances(dat$Address) datDistGoo #&gt; # A tibble: 10 × 11 #&gt; id_from id_to from to m km miles seconds minutes hours mode #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 2 Stormgade 157, 67… Golfvej 5, 7400 … 85637 85.6 53.2 4407 73.4 1.22 driv… #&gt; 2 1 3 Stormgade 157, 67… Slotsarkaderne 2… 321175 321. 200. 11677 195. 3.24 driv… #&gt; 3 1 4 Stormgade 157, 67… A.F Heidemannsve… 322236 322. 200. 10923 182. 3.03 driv… #&gt; 4 1 5 Stormgade 157, 67… Nyholmvej 20, 75… 103720 104. 64.5 5295 88.2 1.47 driv… #&gt; 5 2 3 Golfvej 5, 7400 H… Slotsarkaderne 2… 491579 492. 305. 17258 288. 4.79 driv… #&gt; 6 2 4 Golfvej 5, 7400 H… A.F Heidemannsve… 374866 375. 233. 13408 223. 3.72 driv… #&gt; 7 2 5 Golfvej 5, 7400 H… Nyholmvej 20, 75… 332587 333. 207. 12044 201. 3.35 driv… #&gt; 8 3 4 Slotsarkaderne 26… A.F Heidemannsve… 178212 178. 111. 7725 129. 2.15 driv… #&gt; 9 3 5 Slotsarkaderne 26… Nyholmvej 20, 75… 44036 44.0 27.4 1811 30.2 0.503 driv… #&gt; 10 4 5 A.F Heidemannsvej… Nyholmvej 20, 75… 181238 181. 113. 7698 128. 2.14 driv… Note that only the calculated distances are returned. If you want to have the whole distance matrix we define function: #&#39; Convert the data frame returned from calling a `___calc_distances` function to a distance matrix. #&#39; #&#39; @param dat The data frame returned from calling `___calc_distances`. #&#39; @param value_col The column containing the distances. #&#39; @return The distance matrix as_dist_matrix &lt;- function(dat, value_col) { lgt &lt;- max(dat$id_from, dat$id_to) distanceMat&lt;-matrix(NA, nrow=lgt, ncol = lgt) diag(distanceMat) &lt;- 0 map(1:nrow(dat), function(r) { distanceMat[dat$id_from[r], dat$id_to[r]] &lt;&lt;- dat[[value_col]][r] }) idx &lt;- which(is.na(distanceMat), arr.ind = TRUE) map(1:nrow(idx), function(r) { distanceMat[idx[r, &quot;row&quot;], idx[r, &quot;col&quot;]] &lt;&lt;- distanceMat[idx[r, &quot;col&quot;], idx[r, &quot;row&quot;]] }) return(distanceMat) } as_dist_matrix(datDistGoo, &quot;km&quot;) # distances in km #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.0 85.6 321 322 104 #&gt; [2,] 85.6 0.0 492 375 333 #&gt; [3,] 321.2 491.6 0 178 44 #&gt; [4,] 322.2 374.9 178 0 181 #&gt; [5,] 103.7 332.6 44 181 0 as_dist_matrix(datDistGoo, &quot;seconds&quot;) # travel time in seconds #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 4407 11677 10923 5295 #&gt; [2,] 4407 0 17258 13408 12044 #&gt; [3,] 11677 17258 0 7725 1811 #&gt; [4,] 10923 13408 7725 0 7698 #&gt; [5,] 5295 12044 1811 7698 0 18.3.2 Using Bing Maps Remember to have set your API key. We first define a bing_mapdist function: library(jsonlite) #&#39; Distance between two locations. #&#39; #&#39; @param from From address. #&#39; @param to To address. #&#39; @param mode Walking, driving or transit. #&#39; @param optimize Optimize either `distance` or `time`. #&#39; @return bing_mapdist &lt;- function(from, to, mode = &quot;driving&quot;, optimize = &quot;time&quot;) { if (is.data.frame(from)) { stopifnot(all(c(&quot;from&quot;, &quot;to&quot;) %in% names(from))) from_to_df &lt;- from %&gt;% select(&quot;from&quot;, &quot;to&quot;) %&gt;% as_tibble() } else { from_to_df &lt;- tibble(from = from, to = to) } dat &lt;- map_dfr(1:nrow(from_to_df), function(r) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/&quot;, mode, &quot;?wp.0=&quot;, from_to_df$from[r], &quot;&amp;wp.1=&quot;, from_to_df$to[r], &quot;&amp;optimize=&quot;, optimize, &quot;&amp;ra=excludeItinerary&amp;rpo=None&amp;ig=false&amp;du=km&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(tibble(km = NA, seconds = NA, mode = NA)) df &lt;- lst$resourceSets$resources[[1]] return(tibble(km = df$travelDistance, seconds = df$travelDuration, mode = df$travelMode)) }) return(bind_cols(from_to_df, dat)) } bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej 20, 9800 Hjørring, De… 322. 9960 Drivi… bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, optimize = &quot;distance&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej 20, 9800 Hjørring, De… 257. 14085 Drivi… Note we here can get both the shortest and fastest path between two points. Next, we use the bing_mapdist function for calculating distances: #&#39; Calculate the distance matrix in long format. #&#39; #&#39; @param address A vector of addresses. #&#39; @param symmetric Use symmetric distances (only half the number of queries). #&#39; @param ... Further parameters passed to `bing_mapdist`. #&#39; @return A data frame with the results #&#39; @note The API returns results for the fastest route. bing_calc_distances &lt;- function(address, symmetric = TRUE, ...) { datDist &lt;- expand_grid(id_from = 1:length(address), id_to = 1:length(address)) datDist &lt;- datDist %&gt;% filter(id_from != id_to) if (symmetric) datDist &lt;- datDist %&gt;% filter(id_from &lt; id_to) datDist &lt;- datDist %&gt;% mutate(from = address[id_from], to = address[id_to]) res &lt;- bing_mapdist(datDist %&gt;% select(from, to), ...) return(bind_cols(datDist %&gt;% select(id_from, id_to), res)) } datDistBing &lt;- bing_calc_distances(dat$Address) datDistBing #&gt; # A tibble: 10 × 7 #&gt; id_from id_to from to km seconds mode #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 2 Stormgade 157, 6715 Esbjerg, Denmark Golfvej 5, 7400 H… 87.7 4595 Driv… #&gt; 2 1 3 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkaderne 26… 322. 10422 Driv… #&gt; 3 1 4 Stormgade 157, 6715 Esbjerg, Denmark A.F Heidemannsvej… 322. 9960 Driv… #&gt; 4 1 5 Stormgade 157, 6715 Esbjerg, Denmark Nyholmvej 20, 750… 123. 5788 Driv… #&gt; 5 2 3 Golfvej 5, 7400 Herning, Denmark Slotsarkaderne 26… 334. 10640 Driv… #&gt; 6 2 4 Golfvej 5, 7400 Herning, Denmark A.F Heidemannsvej… 187. 7926 Driv… #&gt; 7 2 5 Golfvej 5, 7400 Herning, Denmark Nyholmvej 20, 750… 44.2 1744 Driv… #&gt; 8 3 4 Slotsarkaderne 26, 3400 Hillerød, Denmark A.F Heidemannsvej… 397. 17197 Driv… #&gt; 9 3 5 Slotsarkaderne 26, 3400 Hillerød, Denmark Nyholmvej 20, 750… 375. 12118 Driv… #&gt; 10 4 5 A.F Heidemannsvej 20, 9800 Hjørring, Denmark Nyholmvej 20, 750… 194. 8237 Driv… Note in general results from the API services are based on a set of assumptions and hence the results from different services may not be the same. You may use the different services to check if the distances are correct, by checking the results from different services: # Difference in minutes abs(as_dist_matrix(datDistGoo, &quot;seconds&quot;) - as_dist_matrix(datDistBing, &quot;seconds&quot;))/60 #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.00 3.13 20.9 16.05 8.22 #&gt; [2,] 3.13 0.00 110.3 91.37 171.67 #&gt; [3,] 20.92 110.30 0.0 157.87 171.78 #&gt; [4,] 16.05 91.37 157.9 0.00 8.98 #&gt; [5,] 8.22 171.67 171.8 8.98 0.00 # Km from 1 to 3 mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;) #&gt; # A tibble: 1 × 9 #&gt; from to m km miles seconds minutes hours mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkadern… 321175 321. 200. 11677 195. 3.24 driv… bing_mapdist(from = &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, to = &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;) #&gt; # A tibble: 1 × 5 #&gt; from to km seconds mode #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Stormgade 157, 6715 Esbjerg, Denmark Slotsarkaderne 26, 3400 Hillerød, Denmark 322. 10422 Driv… 18.4 Geocoding and reverse geocoding 18.4.1 Using Google maps Remember to enable the Geocoding API. To get the coordinates of an address we use the geocode function: geocode(&quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;) #&gt; # A tibble: 1 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 8.46 55.5 We may use mutate_geocode to add the coordinates to a dataset: dat &lt;- dat %&gt;% mutate_geocode(Address) dat #&gt; # A tibble: 5 × 5 #&gt; Id Shop Address lon lat #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.00 56.1 #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 To reverse geocode use the revgeocode function: revgeocode(c(dat$lon[1], dat$lat[1])) #&gt; [1] &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot; To apply it to the dataset use: dat &lt;- dat %&gt;% mutate(AddressGeoGoo = map_chr(1:n(), function(i) { revgeocode(c(lon = lon[i], lat = lat[i])) })) dat #&gt; # A tibble: 5 × 6 #&gt; Id Shop Address lon lat AddressGeoGoo #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark 8.46 55.5 Stormgade 157, 671… #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark 9.00 56.1 Golfvej 5, 7400 He… #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark 12.3 55.9 Slotsarkaderne 26,… #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark 10.0 57.4 A F Heidemanns Vej… #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark 8.62 56.4 Nyholmvej 20, 7500… 18.4.2 Use Bing Maps To get the coordinates of an address we define the bing_geocode function: #&#39; Geocode addresses #&#39; #&#39; @param address Address(es) to geocode. #&#39; @return The coordinates as a data frame. bing_geocode &lt;- function(address) { dat &lt;- map_dfr(address, function(s) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/v1/Locations?q=&quot;, s, &quot;&amp;key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(tibble(lon = NA, lat = NA)) v &lt;- lst$resourceSets$resources[[1]]$point$coordinates[[1]] if (is.null(v)) return(tibble(lon = NA, lat = NA)) return(tibble(lon = v[2], lat = v[1])) }) return(dat) } bing_geocode(&quot;A.F. Heidemannsvej 20, 9800 Hjørring, Denmark&quot;) #&gt; # A tibble: 1 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 10.0 57.4 bing_geocode(dat$Address) #&gt; # A tibble: 5 × 2 #&gt; lon lat #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 8.46 55.5 #&gt; 2 9.00 56.1 #&gt; 3 12.3 55.9 #&gt; 4 10.0 57.4 #&gt; 5 8.62 56.4 We may use bing_mutate_geocode to add the coordinates to a dataset: dat &lt;- dat %&gt;% select(-lat, -lon) mutate_bing_geocode &lt;- function (data, address, ...) { adr &lt;- data[[deparse(substitute(Address))]] gcdf &lt;- bing_geocode(adr) bind_cols(data, gcdf) } dat &lt;- dat %&gt;% mutate_bing_geocode(Address) dat #&gt; # A tibble: 5 × 6 #&gt; Id Shop Address AddressGeoGoo lon lat #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 6715 Esbjerg, Denmark Stormgade 157, 671… 8.46 55.5 #&gt; 2 2 Bilka Herning Golfvej 5, 7400 Herning, Denmark Golfvej 5, 7400 He… 9.00 56.1 #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26, 3400 Hillerød, Denmark Slotsarkaderne 26,… 12.3 55.9 #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej 20, 9800 Hjørring, Denmark A F Heidemanns Vej… 10.0 57.4 #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 7500 Holstebro, Denmark Nyholmvej 20, 7500… 8.62 56.4 To reverse geocode use the bing_revgeocode function: #&#39; Reverse geocode coordinates #&#39; #&#39; @param coordinates A vector with two elements (lon, lat). #&#39; @return The address as a data frame. bing_revgeocode &lt;- function(coordinates) { url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/v1/Locations/&quot;, coordinates[2], &quot;,&quot;, coordinates[1], &quot;?key=&quot;, Sys.getenv(&quot;BING_MAPS_API_KEY&quot;)) url &lt;- URLencode(url) lst &lt;- fromJSON(url) if (lst$statusCode != 200) return(NA) v &lt;- lst$resourceSets$resources[[1]]$address$formattedAddress if (is.null(v)) return(NA) return(v) } bing_revgeocode(c(dat$lon[1], dat$lat[1])) #&gt; [1] &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot; To apply it to the dataset use: dat &lt;- dat %&gt;% mutate(AddressGeoBing = map_chr(1:n(), function(i) { bing_revgeocode(c(lon = lon[i], lat = lat[i])) })) dat #&gt; # A tibble: 5 × 7 #&gt; Id Shop Address AddressGeoGoo lon lat AddressGeoBing #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 Bilka Esbjerg Stormgade 157, 67… Stormgade 157, 6715 E… 8.46 55.5 Stormgade 157, 6715 E… #&gt; 2 2 Bilka Herning Golfvej 5, 7400 H… Golfvej 5, 7400 Herni… 9.00 56.1 Golfvej 5, 7400 Herni… #&gt; 3 3 Bilka Hillerød Slotsarkaderne 26… Slotsarkaderne 26, 34… 12.3 55.9 SLOTSARKADERNE 26, 34… #&gt; 4 4 Bilka Hjørring A.F Heidemannsvej… A F Heidemanns Vej 20… 10.0 57.4 A.F. Heidemanns Vej 2… #&gt; 5 5 Bilka Holstebro Nyholmvej 20, 750… Nyholmvej 20, 7500 Ho… 8.62 56.4 Nyholmvej 20, 7500 Ho… 18.5 Adding markers and routes to a map Leaflet is an open-source JavaScript library for interactive maps. It’s used by websites ranging from The New York Times and The Washington Post to GitHub and Flickr, as well as GIS specialists like OpenStreetMap, Mapbox, and CartoDB. The leaflet package makes it easy to create Leaflet maps from R. Note Leaflet is open-source and free so you do not need an API key for making maps. If you would like to use Google maps instead then have a look at the googleway package instead. First let us create a map with two base layers library(leaflet) m &lt;- leaflet() %&gt;% # Base maps addTiles(group = &quot;Map&quot;) %&gt;% addProviderTiles(&#39;Esri.WorldImagery&#39;, group = &quot;Satelite&quot;) %&gt;% addProviderTiles(&quot;CartoDB.PositronOnlyLabels&quot;, group = &quot;Map&quot;) %&gt;% # Center and zoom setView(10.2, 56.2, zoom = 7) %&gt;% # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), options = layersControlOptions(collapsed = TRUE) ) m Next, let us add the places: dat &lt;- tibble::tribble( ~Id, ~Shop, ~Address, 1L, &quot;Bilka Esbjerg&quot;, &quot;Stormgade 157, 6715 Esbjerg, Denmark&quot;, 2L, &quot;Bilka Herning&quot;, &quot;Golfvej 5, 7400 Herning, Denmark&quot;, 3L, &quot;Bilka Hillerød&quot;, &quot;Slotsarkaderne 26, 3400 Hillerød, Denmark&quot;, 4L, &quot;Bilka Hjørring&quot;, &quot;A.F Heidemannsvej 20, 9800 Hjørring, Denmark&quot;, 5L, &quot;Bilka Holstebro&quot;, &quot;Nyholmvej 20, 7500 Holstebro, Denmark&quot;, ) dat &lt;- dat %&gt;% mutate_geocode(Address) m &lt;- m %&gt;% addMarkers(~lon, ~lat, popup = ~Address, label = ~str_c(Id, &quot; - &quot;, Shop), data = dat) m To add a line between a set of points use the addPolylines function: routeIds &lt;- c(2, 5, 1, 2) route &lt;- dat[routeIds,] m %&gt;% addPolylines(lng = ~lon, lat = ~lat, data = route, weight = 2, label = &quot;Route 1&quot;) A more advanced setup is to use the addFlows function from the leaflet.minicharts package. First let us define some lines: datLines &lt;- tibble(FromId = c(2, 5, 1, 2, 4, 3), ToId = c(5, 1, 2, 4, 3, 2)) datLines &lt;- left_join(datLines, dat %&gt;% select(-Shop, -Address), by = c(&quot;FromId&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) %&gt;% left_join(dat %&gt;% select(-Shop, -Address), by = c(&quot;ToId&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) datLines #&gt; # A tibble: 6 × 6 #&gt; FromId ToId FromLon FromLat ToLon ToLat #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 5 9.00 56.1 8.62 56.4 #&gt; 2 5 1 8.62 56.4 8.46 55.5 #&gt; 3 1 2 8.46 55.5 9.00 56.1 #&gt; 4 2 4 9.00 56.1 10.0 57.4 #&gt; 5 4 3 10.0 57.4 12.3 55.9 #&gt; 6 3 2 12.3 55.9 9.00 56.1 Note we have a from/to pair in each row. We add the lines to the map: library(leaflet.minicharts) m %&gt;% addFlows(datLines$FromLon, datLines$FromLat, datLines$ToLon, datLines$ToLat, flow = 1, maxFlow = 20, opacity = 0.5, popup = popupArgs(noPopup = TRUE)) Let us define a function for adding routes: add_route &lt;- function(dat = NULL, route, solution = 1) { route_id = if_else(is.null(dat), 1, max(dat$RouteId) + 1) tmp &lt;- tibble(From = route[1:(length(route)-1)], To = route[2:length(route)]) tmp &lt;- tmp %&gt;% mutate(Sol = solution, RouteId = route_id) dat &lt;- bind_rows(dat, tmp) } datLines &lt;- add_route(route = c(2, 5, 1, 2)) %&gt;% add_route(route = c(2, 4, 3, 2)) %&gt;% add_route(route = c(2, 3, 1, 2), solution = 2) %&gt;% add_route(route = c(2, 5, 4, 2), solution = 2) datLines &lt;- left_join(datLines, dat %&gt;% select(-Shop, -Address), by = c(&quot;From&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;FromLat&quot; = &quot;lat&quot;, &quot;FromLon&quot; = &quot;lon&quot;) %&gt;% left_join(dat %&gt;% select(-Shop, -Address), by = c(&quot;To&quot; = &quot;Id&quot;)) %&gt;% rename(&quot;ToLat&quot; = &quot;lat&quot;, &quot;ToLon&quot; = &quot;lon&quot;) %&gt;% mutate(group = str_c(&quot;Solution &quot;, Sol)) datLines #&gt; # A tibble: 12 × 9 #&gt; From To Sol RouteId FromLon FromLat ToLon ToLat group #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2 5 1 1 9.00 56.1 8.62 56.4 Solution 1 #&gt; 2 5 1 1 1 8.62 56.4 8.46 55.5 Solution 1 #&gt; 3 1 2 1 1 8.46 55.5 9.00 56.1 Solution 1 #&gt; 4 2 4 1 2 9.00 56.1 10.0 57.4 Solution 1 #&gt; 5 4 3 1 2 10.0 57.4 12.3 55.9 Solution 1 #&gt; 6 3 2 1 2 12.3 55.9 9.00 56.1 Solution 1 #&gt; 7 2 3 2 3 9.00 56.1 12.3 55.9 Solution 2 #&gt; 8 3 1 2 3 12.3 55.9 8.46 55.5 Solution 2 #&gt; 9 1 2 2 3 8.46 55.5 9.00 56.1 Solution 2 #&gt; 10 2 5 2 4 9.00 56.1 8.62 56.4 Solution 2 #&gt; 11 5 4 2 4 8.62 56.4 10.0 57.4 Solution 2 #&gt; 12 4 2 2 4 10.0 57.4 9.00 56.1 Solution 2 A map with Solution 1: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines %&gt;% filter(Sol == 1) m %&gt;% addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) A map with Solution 2: col_pal &lt;- rainbow(max(datLines$RouteId)) datP &lt;- datLines %&gt;% filter(Sol == 2) m %&gt;% addFlows(datP$FromLon, datP$FromLat, datP$ToLon, datP$ToLat, flow = datP$RouteId, maxThickness = 2, color = col_pal[datP$RouteId], opacity = 0.5, popup = popupArgs(labels = &quot;Route&quot;)) An interactive map with both solutions: mm &lt;- m res &lt;- map(1:nrow(datLines), function(i) { tmp &lt;- tibble(lat = c(datLines$FromLat[i], datLines$ToLat[i]), lon = c(datLines$FromLon[i], datLines$ToLon[i])) mm &lt;&lt;- mm %&gt;% addPolylines(lng = ~lon, lat = ~lat, color = col_pal[datLines$Sol[i]], group = datLines$group[i], data = tmp, weight = 2, label = datLines$group[i]) return(invisible(NULL)) }) mm &lt;- mm %&gt;% # Layer control addLayersControl( baseGroups = c(&quot;Map&quot;, &quot;Satelite&quot;), overlayGroups = unique(datLines$group), options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(unique(datLines$group)) %&gt;% showGroup(&quot;Solution 1&quot;) mm Note unfortunately arrows cannot be shown in this case. "],["sec-r-excel.html", "Module 19 Using R in Excel and Excel in R", " Module 19 Using R in Excel and Excel in R [Possible topic on the to do list] https://bert-toolkit.com/ "],["sec-opl.html", "Module 20 Run an OPL model from R", " Module 20 Run an OPL model from R [Possible topic on the to do list] "],["sec-simulation.html", "Module 21 Simulation in R", " Module 21 Simulation in R [Possible topic on the to do list] "],["groups.html", "A Working in groups R project structure Using Git together with GitHub", " A Working in groups During the course you have been allocated into groups. You are expected to solve the R exercises and write the R project report in these groups. Before you start, it is a good idea to agree on a set of group rules. First, agree on a coding convention. Most people in the R community use snake case but camel case is also okay. Next, setup rules on when to meet and how you will organize the work. For instance, it is a good idea that all try to solve some of the exercises before you meet and you then discuss the answers, problems etc. Finally, it is a good idea to have a common place for your code. You have different options: Use a cloud storage services such as Dropbox, OneDrive or Google Drive. Use a version control system such as Git together with GitHub. GitHub is a code sharing and publishing service and may be seen as a social networking site for programmers. The benefit of a cloud storage service is that it is well known to you and easy to setup. Cons are that you cannot work on the same file simultaneously. The benefit of Git and GitHub is that it manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Here you can work on files simultaneously. Moreover, it can be used from within RStudio. Cons are that it is harder to setup and learn. For a detailed description see Why Git? Why GitHub?. I recommend that you use Git and GitHub. However, if you find the learning curve to high just use a cloud storage service. The Using Git together with GitHub section gives a tutorial on how to setup Git and GitHub. Skip it if you use a cloud storage service. R project structure I suggest to have one common R project with subfolders joint, [student1 name], [student2 name], …, [student5 name]. Student folders contain files only a single student work on (good when you do some exercises before class). Folder joint contains joint work. That could for instance be a joint answer of an exercise (based on the work you did in the student folders) and a sub-folder with the project report. Using Git together with GitHub Git is a version control system. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. GitHub provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of it as DropBox but much, much better. It allows other people to see your stuff, sync up with you, and perhaps even make changes. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. To configure your computer go though the following steps: Register a free GitHub account Sign-up at GitHub. Some thoughts about your username: Incorporate your actual name! People like to know who they’re dealing with. Also makes your username easier for people to guess or remember. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Be as unique as possible in as few characters as possible. In some settings GitHub auto-completes or suggests usernames. Make it timeless. Don’t highlight your current university, employer, or place of residence, e.g. JennyFromTheBlock. Avoid the use of upper vs. lower case to separate words. We highly recommend all lowercase. GitHub treats usernames in a case insensitive way, but using all lowercase is kinder to people doing downstream regular expression work with usernames, in various languages. A better strategy for word separation is to use a hyphen - or underscore _. Install Git Find installation instructions below for your operating system. Windows Install Git from the web. Windows prefers for Git to be installed below C:/Program Files and this appears to be the default. This implies, for example, that the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention. If asked about “Adjusting your PATH environment”, make sure to select “Git from the command line and also from 3rd-party software”. macOS Option 1 (highly recommended): Install the Xcode command line tools (not all of Xcode), which includes Git. Go to the shell and enter one of these commands to elicit an offer to install developer command line tools: git --version git config Accept the offer! Click on “Install”. Here’s another way to request this installation, more directly: xcode-select --install We just happen to find this Git-based trigger apropos. Note also that, after upgrading macOS, you might need to re-do the above and/or re-agree to the Xcode license agreement. We have seen this cause the RStudio Git pane to disappear on a system where it was previously working. Use commands like those above to tickle Xcode into prompting you for what it needs, then restart RStudio. Option 2 (recommended): Install Git from here: http://git-scm.com/downloads. This arguably sets you up the best for the future. It will certainly get you the latest version of Git of all approaches described here. The GitHub home for the macOS installer is here: https://github.com/timcharper/git_osx_installer. At that link, you can find more info if something goes wrong or you are working on an old version of macOS. Option 3 (recommended): If you anticipate getting heavily into scientific computing, you’re going to be installing and updating lots of software. You should check out Homebrew, “the missing package manager for OS X”. Among many other things, it can install Git for you. Once you have Homebrew installed, do this in the shell: brew install git Linux Install Git via your distro’s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux Check your installation Quit and re-launch RStudio if there’s any doubt in your mind about whether you opened RStudio before or after installing Git. You can set your Git user name and email from within R using the usethis package: ## install if needed (do this exactly once): ## install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) What user name should you give to Git? This does not have to be your GitHub user name, although it can be. Another good option is your actual first name and last name. If you commit from different machines, sometimes people work that info into the user name. Your commits will be labelled with this user name, so make it informative to potential collaborators and future you. What email should you give to Git? This must be the email associated with your GitHub account. These commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list from a shell. An easy way to get into a shell from RStudio is **Tools &gt; Terminal* or *Tools &gt; Shell**. If you have any problems go though Chapters 4-14 on the Happy Git site. Setup projects using Git and GitHub You have different options depending on how you start you project. I will only highlight the prefererd one. New project, GitHub first Here we create a project with “GitHub first, then RStudio” sequence: Step 1: Go to GitHub and make sure you are logged in. Click green “New repository” button. Or, if you are on your own profile page, click on “Repositories”, then click the green “New” button. Repository name: test (or whatever you wish) Public YES Initialize this repository with a README Click the big green button “Create repository.” Copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. Step 2: In RStudio, start a new Project: File &gt; New Project &gt; Version Control &gt; Git. In the “repository URL” paste the URL of your new GitHub repository. It will be something like this https://github.com/[you-username]/test.git. Be intentional about where you create this Project. Suggest you “Open in new session”. Click “Create Project” to create a new directory, which will be all of these things: a directory or “folder” on your computer a Git repository, linked to a remote GitHub repository an RStudio Project In the absence of other constraints, I suggest that all of your R projects have exactly this set-up. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio’s file browser pane for the README.md file. There’s a big advantage to the “GitHub first, then RStudio” workflow: the remote GitHub repo is added as a remote for your local repo and your local master branch is now tracking master on GitHub. This is a technical but important point about Git. The practical implication is that you are now set up to push and pull. No need to fanny around setting up Git remotes and tracking branches on the command line. Step 3: Make local changes, save, commit. Do this every time you finish a valuable chunk of work, probably many times a day. From RStudio, modify the README.md file, e.g., by adding the line “This is a line from RStudio”. Save your changes. Commit these changes to your local repo. How? Click the “Git” tab in upper right pane Check “Staged” box for any files whose existence or modifications you want to commit. To see more detail on what’s changed in file since the last commit, click on “Diff” for a Git pop-up If you’re not already in the Git pop-up, click “Commit” Type a message in “Commit message”, such as “Commit from RStudio”. Click “Commit” Step 4: Push your local changes to GitHub Do this a few times a day, but possibly less often than you commit. You have new work in your local Git repository, but the changes are not online yet. This will seem counterintuitive, but first let’s stop and pull from GitHub. Why? Establish this habit for the future! If you make changes to the repo in the browser or from another machine or (one day) a collaborator has pushed, you will be happier if you pull those changes in before you attempt to push. Click the blue “Pull” button in the “Git” tab in RStudio. I doubt anything will happen, i.e. you’ll get the message “Already up-to-date.” This is just to establish a habit. Click the green “Push” button to send your local changes to GitHub. You should see some message along these lines. [master dc671f0] blah 3 files changed, 22 insertions(+) create mode 100644 .gitignore create mode 100644 myrepo.Rproj Step 5: Confirm the local change propagated to the GitHub remote Go back to the browser. I assume we’re still viewing your new GitHub repo. Refresh. You should see the new “This is a line from RStudio” in the README. If you click on “commits,” you should see one with the message “Commit from RStudio”. Step 6: Make a change on GitHub Click on README.md in the file listing on GitHub. In the upper right corner, click on the pencil for “Edit this file”. Add a line to this file, such as “Line added from GitHub.” Edit the commit message in “Commit changes” or accept the default. Click the big green button “Commit changes.” Step 7: Pull from GitHub Back in RStudio locally … Inspect your README.md. It should NOT have the line “Line added from GitHub”. It should be as you left it. Verify that. Click the blue Pull button. Look at README.md again. You should now see the new line there. The end Now just repeat these operations when you do group work. Do work somewhere. Commit it. Push it or pull it depending on where you did it, but get local and remote “synced up”. Repeat. Note that in general (and especially in future when collaborating with other developers) you will usually need to pull changes from the remote (GitHub) before pushing the local changes you have made. For this reason, it’s a good idea to try and get into the habit of pulling before you attempt to push. If you have to type in your password over and over again, this can be avoided. Have a look at Chapter 10 of Happy Git. Existing project, GitHub first See details in Chapter 16 of Happy Git. Existing project, GitHub last See details in Chapter 17 of Happy Git. "],["annotate.html", "B Annotate the course notes", " B Annotate the course notes I recommend using hypothes.is to annotate the online course notes. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help me indicate spell errors, unclear content etc. in the notes. "],["help.html", "C Getting help", " C Getting help We all get stuck sometimes and need some help. Below are some advises on how to help yourself and ask for help: First try to understand the error message and solve the problem. You may try to debug your code by inserting break points in VBA or use browser() in your R code. See Chapter 11 in Bryan and H (n.d.) for further details. Google is your friend. This is always the first step. Try searches like “vba range”, “r dplyr filter”, “r tidyverse”, “r subset vector”, etc. Do you need help for a specific function in R then try ?[function-name] such as ?geom_line, ?mutate, etc. Mostly, focus on the last section with examples. Moreover, some packages may have written vignettes try browseVignettes(package = \"package_name\") to check. Have a look at Help &gt; Cheatsheets in RStudio. If you can’t find an answer then it is time to ask on-line. I recommend asking a question at stackoverflow. To make your question effective, the idea is to make things as easy as possible for someone to answer. This stack overflow thread How to make a great R reproducible example? give you some good hints. The process of providing a good minimal reproducible example (reprex) often causes you to answer your own question! See also Stack Exchange’s ‘How to ask’ and How to make a reprex at tidyverse. If you have a more course related question then ask it at our course forum and we will try to answer your question asap. Students are also welcome in helping each other. You can also try to annotate the online course notes if something is unclear. I will try to answer asap. You can get help from our TAs at study cafés. Note help using mail correspondence is not supported! References "],["slides.html", "D Slides", " D Slides Slides and code from the lectures. Welcome to TFA. Getting started (Module 1-3) - R-scipt file. Programming (Module 4-5) - R-scipt file. IO, Tidy and transform (Module 6-8) - R Markdown file. Visualization using ggplot2 (Module 9) - R Markdown file. Mutating joins (Module 8.3) - R Markdown file. "],["lg-course.html", "E Learning goals", " E Learning goals The purpose of this course is to give students a knowledge about IT tools for Analytics which requires the analyst to be qualified in handling tools beyond e.g. basic Excel. After having participated in the course, the student must, in addition to achieving general academic skills, demonstrate: Knowledge of how a computer works at a basic level. basic programming such as variables, arrays, loops, functions and procedures. what an algorithm is. how to implement an algorithm based on a description. different programming languages. how to manage a code in a collaborative working environment. Skills to handle data such as import, tidy, transform, visualize and export. develop well-structured code. perform testing and debugging. implement/code selected algorithms. apply analytical techniques on data. apply relevant methods, algorithms and techniques from this course in order to solve a specific problem. Competences to independently handle data given a problem. independently analyze data given a relevant research question. compare different programming languages. compare different algorithms solving a problem and discuss their advantages and disadvantages. interpret and discuss results based on a data analysis in relation to the relevant academic literature. communicate results from applied research in a scientific way, e.g. using literate programming. "],["sec-ba.html", "F Business Analytics", " F Business Analytics Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using “big” data sources. Descriptive Analytics: A set of technologies and processes that use data to understand and analyze business performance. Descriptive analytics are the most commonly used and most well understood type of analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (KPIs, what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive Analytics: The use of data and statistical techniques to make predictions about future outputs/outcomes, identify patterns or opportunities for business performance. Examples of techniques are data mining (what data is correlated with other data?), pattern recognition and alerts (when should I take action to correct/adjust a spare part?), Monte-Carlo simulation (what could happen?), neural networks (which customer group are best?) and forecasting (what if these trends continue?). Prescriptive Analytics: The use of optimization and other decision modelling techniques using the results of descriptive and predictive analytics to suggest decision options with the goal of improving business performance. Prescriptive analytics attempt to quantify the effect of future decisions in order to advise on possible outcomes before the decisions are actually made. Prescriptive analytics predicts not only what will happen, but also why it will happen and provides recommendations regarding actions that will take advantage of the predictions. Prescriptive analytics are relatively complex to administer, and most companies are not yet using it in their daily course of business. However, when implemented correctly, it can have a huge impact on business performance and how businesses make decisions. Examples on prescriptive analytics are optimization in production planning and scheduling, inventory management, the supply chain and transportation planning. Companies who use BA focus on fact-based management to drive decision making and treats data and information as a strategic asset that is shared within the company. This enterprise approach generates a companywide respect for applying descriptive, predictive and prescriptive analytics in areas such as supply chain, marketing and human resources. Related areas: In the past Business Intelligence traditionally focuses on querying, reporting, online analytical processing, i.e. descriptive analytics. However, a more modern definition of Business Intelligence is the union of descriptive and predictive analytics. Operations Research or Management Science deals with the application of advanced analytical methods to help make better decisions and can hence be seen as prescriptive analytics. However, traditionally it has been taking a more theoretical approach and focusing on problem-driven research while BA takes a more data-driven approach. Logistics is a cross-functional area focusing on the effective and efficient flows of goods and services, and the related flows of information and cash. Supply Chain Management adds a process-oriented and cross-company perspective. Both can be seen as prescriptive analytics with a more problem-driven research focus. Advanced Analytics is often used as a classification of both predictive and prescriptive analytics. Data science is an interdisciplinary field about scientific methods, processes, and systems to extract knowledge or insights from data in various forms, either structured or unstructured and can be seen as Business analytics applied to a wider range of data. Resources http://analytics-magazine.org/the-analytics-journey/ https://en.wikipedia.org/wiki/Business_analytics http://connect.informs.org/analytics/home https://www.or-exchange.org/questions/5645/informs-analytics-definition https://en.wikipedia.org/wiki/Prescriptive_analytics https://en.wikipedia.org/wiki/Predictive_analytics "],["colophon.html", "G Colophon", " G Colophon This book was written in bookdown inside RStudio. This version of the book was built with: #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.1.1 (2021-08-10) #&gt; os macOS Catalina 10.15.7 #&gt; system x86_64, darwin17.0 #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; ctype en_US.UTF-8 #&gt; tz UTC #&gt; date 2021-08-13 Along with these packages: "]]
