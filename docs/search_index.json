[
["index.html", "Tools for Analytics (TFA) Course notes R part Module 1 Introduction 1.1 How this book is organised 1.2 Acknowledgements", " Tools for Analytics (TFA) Course notes R part Lars Relund Nielsen 2020-10-05 Module 1 Introduction This site/book contains course notes for the R part of the course “Tools for Analytics” held at Aarhus BSS. The notes show what we will be doing in each week. The course is an introductory course at the Operations and Supply Chain Analytics programme and intended to give knowledge about IT tools for Analytics. You can expect the book to be updated when the course runs. The date listed above is the last time this guide was updated. Since the amount of available data has increased extensively in many companies, there is a need for analysts with the ability to do tasks within Analytics. For instance, extract relevant data and perform valid quantitative analysis. Clearly, it is also important that the analyst can communicate the results of the analysis to their surroundings. This requires for the analyst to be particularly qualified in handling IT based tools beyond e.g. basic Excel. Business Analytics (BA) (or just Analytics) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem and the creation of business value by integration of concepts, methods and data. As a process, it can be characterized by descriptive, predictive, and prescriptive model building using data sources. For a full definition see the appendix. Within a Business Analytics (BA) framework the course focus on giving you an introduction to programming, handeling data and doing descriptive analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (key performance indicators (KPIs), what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive and prescriptive analytics are covered in other courses of the programme. Analytics may be seen as a data driven process: Figure 1.1: Analytics as a data driven process. For doing data driven analytics you first must import your data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form sutaiable for analysis. In brief, when your data is tidy, each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The next step is to do a simple exploration of you data such as calculating a set of summary statistics (like counts, means or KPIs). A good way to get an overview over your data is by visualisation. A good visualisation will show you things that you did not expect, raise new questions about the data or confirm your hypothesis. A good visualisation might also hint that you’re asking the wrong question, or you need to collect different data. Exploration and visusalization are descriptive analytics and used to answer questions such as: What happened? How many, how often, where? Where exactly is the problem? What actions are needed? Models are complementary tools to visualisation. Once you have made your questions sufficiently precise, you can use a model to answer them. A model is a description of a system using mathematical concepts and a simplification of the real system. That is, the results of a model are based on a set of assumptions. Models for statistical analysis, forecasting, system behaivior are predictive analytics and answer questions like: Why is this happening? What if these trends continue? What will happen next? Models for prescriptive analytics use optimization and other decision modelling techniques to suggest decision options with the goal of improving business performance and answer questions like: What is the best that can happen? Exploration, visualizaton and modeling may be seen as different steps which can be used for analyzing the data and answer the overall questions. This part of the course will focus on the different steps except modeling. Given an analysis, communication is an absolutely critical part. It doesn’t matter how well your models and visualization have led you to understand the data unless you can also communicate your results to decision makers. Note that analytics is not a one-way process, is is common that you several times have to tidy and transform your data, explore and visualize based on the results of a model, rerun the model given feedback on you communication to the decision makers etc. Common connections are visualized using directed arrows in Figure 1.1. Surrounding the process is programming. Programming is the Swiss army knife you use during parts of the process. An introduction to programming is given in the first part of the course using VBA in Excel. We will cover programming using R in this part of the course. 1.1 How this book is organised Module 1 (this module) gives a short introduction to the book. Next, the book consists of different parts each containing teaching modules about specific topics: Part I focus on helping you install the needed programs on your computer (Module 2) and give you a short introduction to R (Module 3). Part II gives you an overview over programming in R including loops and conditionals (Module 4) and functions (Module 5). Part III the focus is on import/export, tidy and transformation of data. Module 6 first gives you an introduction to the tidyverse packages and introduce you to literal programming using R Markdown. Next, Module 7 shows you how to export and import data. Finally, Module 8 focus on transformation of data. Part IV considers visualization of data in R (Module 9). Part V presents your mandatory R project. Part VI contains extra modules not part of the curriculum in this course. But it may be useful during your study. The appendix contains different modules that may be helpful for you including hints on how to work in groups, how to get help if you are stuck and how to annotate the course notes. 1.2 Acknowledgements Some of the materials in this book are taken from various places The bookdown skeleton and some notes are based on the Stat545 course. Some content in Module 1 is inspired by Chapter 1 in Wickham (2017). Module 2 is inspired by Chapter 1 in Bryan (2017). Module 3 is using some text and images from Chapter 1 in Ismay and Kim (2020) and Chapter 2 in Bryan (2017). A few exercises are inspired by Chapter 2 in Irizarry (2020). Notes about git and GitHub in the appendix are based on Bryan, STAT 545 TAs, and Hester (2020). Exercise 8.5.1 is a revision of Chapters 6-7 in Bryan (2017). Exercise 8.5.2 is a revision of Session 3 in the Welcome to the tidyverse course. Exercise ?? is a revision of Chapter 9 in Irizarry (2020). Also thanks to Solveig for proofreading the draft. I would like to thank all for their inspiration. This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC BY-NC-SA 4.0. References "],
["sec-install.html", "Module 2 Install R and RStudio 2.1 Learning outcomes 2.2 Install R and RStudio 2.3 Test your installation 2.4 Add-on packages 2.5 Different learning paths", " Module 2 Install R and RStudio 2.1 Learning outcomes By the end of this module, you are expected to have: Installed R. Installed RStudio. Tested R and RStudio. Installed some packages. 2.2 Install R and RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. For a further overview and description of the history of R see Chapter 2 in Peng (2018). To run R you need to install it on your computer. Moreover, you need the IDE (integrated development environment) RStudio to save your work. Install R from CRAN (Comprehensive R Archive Network). Install the latest precompiled binary distribution for your operating system (use the links up at the top of the CRAN page). Install the desktop version of RStudio, a powerful user interface for R. Under Windows it is a good idea to always open R with administrator rights: Add a shortcut for RStudio (e.g. to the taskbar or desktop). Ctrl+Shift+Right-Click the shortcut and choose Properties: Under Shortcut click Advanced and set Run as administrator You now always can open RStudio with this shortcut. If you have a pre-existing installation of R and/or RStudio, reinstall both to the latest versions. It can be considerably harder to run old software than new. To update your R version you may use the intallr package. 2.3 Test your installation Do whatever is appropriate for your OS to launch RStudio. You should get a window similar to the screenshot you see here, but yours will be more boring because you have not written any code or made any figures yet! Put your cursor in the pane labeled Console, which is where you interact with the live R process. Create a simple object using code like x &lt;- 2 * 4 (followed by enter or return). Then inspect the x object by typing x followed by enter or return. You should see the value 8 print to screen. If yes, you have succeeded in installing R and RStudio. Try to open a new file File &gt; New File &gt; New RMarkdown…. Use the defaults and press OK. Next save the file and compile it using Knit (Ctrl+Shift+K). You have now compiled a document with R code inside of it. 2.4 Add-on packages R is an extensible system and many people share useful codes they have developed as a package via CRAN and GitHub. To install a package from CRAN, for example the dplyr package for data manipulation, one way to do it is in the R console. install.packages(&quot;dplyr&quot;, dependencies = TRUE) By including dependencies = TRUE, we are being explicit and extra careful to install any additional packages, the target package, dplyr in the example above, needs to have around. Install the package tidyverse which is in fact a bundle of packages by running (note this operation may take a long time): install.packages(&quot;tidyverse&quot;, dependencies = TRUE) Check if you have successfully installed tidyverse by loading the package: library(tidyverse) If your install was unsuccessful try to install the packages who fails one by one. You may also see this short video explaining what packages are. 2.5 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Intro 2R has a set of introductory videos about R. Of special interest are A video about installing R and RStudio. A video giving an introduction to RStudio. A video about installing new packages. References "],
["sec-r-basics.html", "Module 3 R basics and workflows 3.1 Learning outcomes 3.2 Working with R at the command line in RStudio 3.3 Your first DataCamp course 3.4 Pipes 3.5 RStudio projects 3.6 Global options 3.7 Working directory 3.8 Different learning paths 3.9 Recap 3.10 Exercises", " Module 3 R basics and workflows 3.1 Learning outcomes By the end of this module, you are expected to have: Tried R and RStudio. Learned how the RStudio IDE works. Finished your first course on DataCamp. Solved your first exercises. 3.2 Working with R at the command line in RStudio R is a programming language and free software environment. The R language is widely used among statisticians and data miners for data analysis. To run R you need to install it on your computer. Throughout this book, we will assume that you are using R via RStudio. First time users often confuse the two. At its simplest, R is like a car’s engine while RStudio is like a car’s dashboard as illustrated in Figure 3.1. Figure 3.1: Analogy of difference between R and RStudio. More precisely, R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well. Compared to Excel. The benefit of using Excel is that the initial learning curve is quite minimal, and most analysis can be done via point-and-click on the top panel. Once a user imports their data into the program, it’s not exceedingly hard to make basic graphs and charts. R is a programming language, however, meaning the initial learning curve is steeper. It will take you some time to become familiar with the interface and master the various functions. Luckily, using R can quickly become second-nature with practice. For a detailed comparison you may see Excel vs R: A Brief Introduction to R by Jesse Sadler. Compared to VBA, R is an interpreted language; users typically access it through a command-line or script file. To run VBA you need to compile and execute it. Recall our car analogy from earlier. As we do not drive a car by interacting directly with the engine but rather by interacting with elements on the car’s dashboard, we will not be using R directly but rather we will use RStudio’s interface. After you install R and RStudio on your computer, you will have two new programs (also called applications) you can open. We will always work in RStudio (except when you do online courses) and not in the R application. Figure 3.2 shows what icon you should be clicking on your computer. Figure 3.2: Icons of R versus RStudio on your computer. Launch RStudio and notice the panes: Console (left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: Customizing RStudio. Now that you are set up with R and RStudio, you are probably asking yourself, “OK - now how do I use R?”. The first thing to note is that unlike other software programs like Excel or SPSS that provide point-and-click interfaces, R is an interpreted language. This means you have to type in commands written in R code. In other words, you have to code/program in R. Note that we’ll use the terms “coding” and “programming” interchangeably in this book. Go into the Console, where we interact with the live R process. Make an assignment and then inspect the object you just created: x &lt;- 3 * 4 x #&gt; [1] 12 All R statements where you create objects – “assignments” – have this form: object_name &lt;- value and in my head I hear, e.g., “x equals 12”. You will make lots of assignments and the operator &lt;- is a pain to type. Don’t be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudio’s keyboard shortcut: Alt+- (the minus sign). Note that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Give your eyes a break and use spaces. RStudio offers many handy keyboard shortcuts. Also, Alt+Shift+K brings up a keyboard shortcut reference card. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You are advised to adopt a naming convention. Some use snake case others use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. this_is_snake_case # note you don&#39;t use capital letters here thisIsCamelCase # you start each word with a capital letter Make another assignment: this_is_a_long_name &lt;- 2.5 To inspect this, try out RStudio’s completion facility: type the first few characters, press TAB, add characters until you agree, then press return. In VBA you have procedures and functions. In R we only use functions which always return an object. R has a mind-blowing collection of built-in functions that are accessed like so: function_name(arg1 = val1, arg2 = val2, ...) Let’s try function seq() which makes regular sequences of numbers and at the same time demo more helpful features of RStudio. Type se and hit TAB. A pop-up shows you possible completions. Specify seq() by typing more to disambiguate or using the up/down arrows to select. Note the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and note the automatic addition of the closing parenthesis and the placement of the cursor in the middle. Type the arguments 1, 10 and hit return. seq(1, 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. Type seq and press F1 or type: ?seq The Help tab of the lower right pane will show the help documentation of function seq with a description of usage, arguments, return value etc. Note all function arguments have names. You can always specify arguments using name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we didn’t specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. Note since the default value for from is 1, the same result is obtained by typing: seq(to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 Make this assignment and notice similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just make an assignment, you don’t see the value. You may see the value by: yo # same as print(yo) #&gt; [1] &quot;hello world&quot; print(yo) #&gt; [1] &quot;hello world&quot; Now look at your Environment tab in the upper right pane where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() #&gt; [1] &quot;addIcon&quot; &quot;addSolution&quot; &quot;ctrSol&quot; &quot;strExercises&quot; #&gt; [5] &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; ls() #&gt; [1] &quot;addIcon&quot; &quot;addSolution&quot; &quot;ctrSol&quot; &quot;strExercises&quot; #&gt; [5] &quot;strLPath&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; &quot;yo&quot; If you want to remove the object named yo, you can do this: rm(yo) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. 3.3 Your first DataCamp course Datacamp is an online platform for learning data science. We are going to use the platform for online lessons and exercises. You should already be signed up to the organization Tools for analytics at DataCamp, otherwise sign up using your university e-mail here. DataCamp runs all the courses in your browser. That is, R is run on a server and you don’t use RStudio here. The first course gives an Introduction to R. You are expected to have completed the course before continuing this module! 3.4 Pipes Most functions support the pipe operator which is a powerful tool for clearly expressing a sequence of multiple operations. The pipe operator %&gt;%, comes from the magrittr package and is loaded automatically when you load tidyverse. You may use the RStudio keyboard shortcut Ctrl+Shift+M. Consider the following code: # calculate x as a sequence of operations x &lt;- 16 x &lt;- sqrt(x) x &lt;- log2(x) x #&gt; [1] 2 # same as y &lt;- log2(sqrt(16)) y #&gt; [1] 2 Note we here calculate x using a sequence of operations: \\[ \\mbox{original data (x)} \\rightarrow \\mbox{ sqrt } \\rightarrow \\mbox{ log2 }. \\] That is, we take what is left of the arrow (the object x) and put it into the function on the right of the arrow. These operations can be done using the pipe operator: x &lt;- 16 x &lt;- x %&gt;% sqrt() %&gt;% log2() x #&gt; [1] 2 In general, the pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. That is, you may have other arguments in your functions: 16 %&gt;% sqrt() %&gt;% log2() #&gt; [1] 2 16 %&gt;% sqrt() %&gt;% log(base = 2) # equivalent #&gt; [1] 2 The above example is simple but illustrates that you can use pipes to skip intermediate assignment operations. Later you will do more complex pipes when we consider data wrangling. For instance, mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4, cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horse power and miles, and then rows with cars having four cylinders and gears. For a more detailed introduction to pipes see Chapter 18 in Wickham (2017). 3.5 RStudio projects Let us return to RStudio. One day you will need to quit R, do something else and return to your analysis later. One day you will have multiple analyses going that use R and you want to keep them separate. One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world. To handle these real life situations, you need to store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). RStudio has built-in support for this via its [projects][rstudio-using-projects]. You may think of a project as a folder where you store all you work. Let us create one to use for the rest of this module. Do this: File &gt; New Project… &gt; New Directory &gt; New Project &gt;. The directory name you choose here will be the project name. Call it whatever you want (or follow me for convenience). I used tfa_testing in my tmp directory (that is tfa_testing is now a subfolder of tmp. You now need a way to store R code in your project. We will use 2 ways of storing your code. An R script file or an R Markdown document. Normally you store lines of R code in a script file that you need to run. R Markdown provides an easy way to produce a rich, fully-documented reproducible analysis. Here you combine text, figures and metadata needed to reproduce the analysis from the beginning to the end in a single file. R Markdown compiles to nicely formatted HTML, PDF, or Word. We are going to use R Markdown for larger projects (e.g. the mandatory R report in Week 48). We will come back to R Markdown later. 3.5.1 Storing your code in a script file R code can be stored in a script file with file suffix .R. A script file contains a line for each R command to run (think of each line as a command added to the console). Create a new script file File &gt; New File &gt; R Script. Let us add some R code to the file: # this is a comment a &lt;- 2 b &lt;- -3 sig_sq &lt;- 0.5 x &lt;- runif(40) y &lt;- a + b * x + rnorm(40, sd = sqrt(sig_sq)) (avg_x &lt;- mean(x)) write(avg_x, &quot;avg_x.txt&quot;) plot(x, y) abline(a, b, col = &quot;purple&quot;) dev.print(pdf, &quot;toy_line_plot.pdf&quot;) Save the file as testing.R Now run each line by setting the cursor at the first line, hit Ctrl+Enter (runs the line in the Console and moves the cursor to the next line). Repeat Ctrl+Enter until you have run all the lines. Alternatively you may select all the code and hit Ctrl+Enter. Change some things in your code. For instance set a sample size n at the top, e.g. n &lt;- 40, and then replace all the hard-wired 40’s with n. Change some other minor, but detectable, stuff, e.g. alter the sample size n, the slope of the line b, the color of the line etc. Practice the different ways to rerun the code: Walk through line by line by keyboard shortcut (Ctrl+Enter) or mouse (click “Run” in the upper right corner of editor pane). Source the entire document by entering source('testing.R') in the Console or use keyboard shortcut (Shift+Ctrl+S) or mouse (click “Source” in the upper right corner of editor pane or select from the mini-menu accessible from the associated down triangle). Source with echo from the Source mini-menu. Try to get an overview of the different planes and tabs. For instance in the Files tab (lower right plane) you can get an overview of your project files. You may also see this video about projects. 3.6 Global options Quit RStudio. Inspect the folder associated with your project if you wish. Maybe view the PDF in an external viewer. Restart RStudio. Note that things, by default, restore to where we were earlier. Check the Environment tap (top-right plane). The environment should be empty. If it contains objects you defined before you closed R, it is because they have been restored. This is in general not advisable and should be changed by opening Tools &gt; Global Options …. Under General set the check marks as: Quit RStudio and reopen it. The Environment tab should now be empty. 3.7 Working directory Any process running on your computer has a notion of its “working directory”. In R, this is where R will look, by default, for files you ask it to load. It is also where, by default, any files you write to disk will go. Chances are your current working directory is the directory we inspected above, i.e. the one where RStudio wanted to save the workspace. You can explicitly check your working directory with: getwd() It is also displayed at the top of the RStudio console. In general it should be the directory of your R project. You can set R’s working directory at the command line like so: setwd(&quot;./subfolder&quot;) # sets the working dir to a subfolder of you project folder You can also use RStudio’s Files pane to navigate to a directory and then set it as working directory from the menu: Session &gt; Set Working Directory &gt; To Files Pane Location. 3.8 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Roger Peng has a lot of videos on YouTube about R. Of special interest are An introduction to the R language (Part 1, Part 2, Part 3) including data types and basic operations. An introduction to subsetting in R. A detailed description af data types. An introduction to R is given in Chapter 4 of Peng (2018). A detailed tutorial on subsetting is given in Chapter 9 of Peng (2018). A longer tutorial to factors is given in Chapter 15 of Wickham (2017). For a more detailed introduction to pipes see Chapter 18 in Wickham (2017). For a detailed introduction to strings (see exercise below) check out the DataCamp course String Manipulation with stringr in R. An introduction to good coding conventions in given in Chapter 16 of Stauffer, Simon, and Zeileis (2020). 3.9 Recap R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. Adopt a naming convention. Either use snake case or use camel case. Choose the naming convention you like best in your study group. But stick only to one of them. Store your work in a project that keeps all the files associated with a project organized together (such as input data, R scripts, analytical results and figures). You may think of a project as a folder where your store all you work. This workflow will serve you well in the future: Create an RStudio project for an analytical project Keep inputs there (we’ll soon talk about importing) Keep scripts there; edit them, run them in bits or as a whole from there Keep outputs there (like the PDF written above) Avoid using the mouse for pieces of your analytical workflow, such as loading a dataset or saving a figure. This is extremely important for the reproducibility and for making it possible to retrospectively determine how a numerical table or PDF was actually produced. Learn and use shortcuts as much as possible. For instance Alt+- for the assignment operator and Ctrl+Shift+M for the pipe operator. A reference card of shortcuts can be seen using Alt+Shift+K. Store your R commands in a script file and R scripts with a .R suffix. Comments start with one or more # symbols. Use them. RStudio helps you (de)comment selected lines with Ctrl+Shift+C (Windows and Linux) or Cmd+Shift+C (Mac). Values saved in R are stored in Objects. The interactive DataCamp course gave an introduction to some basic programming concepts and terminology: Data types: integers, doubles/numerics, logicals, and characters. Integers are values like -1, 0, 2, 4092. Doubles or numerics are a larger set of values containing both the integers but also fractions and decimal values like -24.932 and 0.8. Logicals are either TRUE or FALSE while characters are text such as “Hamilton”, “The Wire is the greatest TV show ever”, and “This ramen is delicious.” Note that characters are often denoted with the quotation marks around them. Vectors: a series of values. These are created using the c() function, where c() stands for “combine” or “concatenate.” For example, c(6, 11, 13, 31, 90, 92) creates a six element series of positive integer values . Factors: categorical data are commonly represented in R as factors. Categorical data can also be represented as strings. Data frames: rectangular spreadsheets. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. It is not even required that these objects are related to each other in any way. Comparison operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. A pipe (%&gt;%) sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Use pipes if you have many intermediate assignment operations. 3.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! Practice using shortcuts in RStudio (use Shift+Alt+K to get an overview). 3.10.1 Exercise (group work) You are not expected to start solving this exercise before you meet in your group. You have all been allocated into groups. During the course, you are expected to solve the R exercises in these groups. Before you start, it is a good idea to agree on a set of group rules: It is a good idea to have a shared place for your code. Have a look at the section Working in groups and decide on a place to share your code. Create a shared folder and project for your group. Agree on a coding convention. Agree about the rules of how to meet etc. 3.10.2 Exercise (install packages) This exercise is done from the Console in RStudio (under Windows, remember to have admin rights). &times; Solution install.packages(&quot;devtools&quot;) Close Solution Install the package devtools using function install.packages. Note you can always get help/see documentation of a function by typing ?install.packages or typing install.packages and press F1. You now have installed the package from the default repository (CRAN). You may also install packages from other repositories (e.g. GitHub): Have a look at the documentation for function install_github in the package devtools. This can be done in different ways: library(devtools) # we here load all the functions in devtools ?install_github ?devtools::install_github # we here use the namespace devtools to load only one function &times; Solution devtools::install_github(&quot;bss-osca/tfa/tfa-package&quot;) Close Solution Install the package tfa from github using path bss-osca/tfa/tfa-package. 3.10.3 Exercise (piping) Solve this exercise using a script file (e.g. exercises/pipe.R). Remember that you can run a line in the file using Ctrl+Enter. The pipe %&gt;% can be used to perform operations sequentially without having to define intermediate objects (Ctrl+Shift+M). Have a look at the dataset mtcars: head(mtcars) ?mtcars The pipe library(tidyverse) mtcars %&gt;% select(cyl, gear, hp, mpg) %&gt;% filter(gear == 4 &amp; cyl == 4) #&gt; cyl gear hp mpg #&gt; Datsun 710 4 4 93 22.8 #&gt; Merc 240D 4 4 62 24.4 #&gt; Merc 230 4 4 95 22.8 #&gt; Fiat 128 4 4 66 32.4 #&gt; Honda Civic 4 4 52 30.4 #&gt; Toyota Corolla 4 4 65 33.9 #&gt; Fiat X1-9 4 4 66 27.3 #&gt; Volvo 142E 4 4 109 21.4 selects the columns related to cylinders, gears, horsepower and miles, and then rows with cars having four cylinders and (operator &amp;) gears. &times; Solution mtcars %&gt;% select(mpg, hp, am, gear) Close Solution Create a pipe that selects columns related to miles, hoursepower, transmission and gears. &times; Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20, gear == 4) Close Solution Given the answer in 1), filter so cars have miles less than 20 and 4 gears. The “or” operator in R is |. &times; Solution mtcars %&gt;% select(mpg, hp, am, gear) %&gt;% filter(mpg &lt; 20 | gear == 4) Close Solution Given the answer in 1), filter so cars have miles less than 20 or 4 gears. &times; Solution mtcars %&gt;% filter(mpg &lt; 20, gear == 4) %&gt;% select(wt, vs) Close Solution Create a pipe that filters the cars having miles less than 20 and 4 gears and selects columns related to weight and engine. &times; Solution dat &lt;- mtcars dat &lt;- filter(dat, mpg &lt; 20, gear == 4) dat &lt;- select(dat, wt, vs) dat Close Solution Solve Question 4 without the pipe operator. 3.10.4 Exercise (working dir) Do this exercise from the Console in RStudio. When reading and writing to local files, your working directory becomes important. You can get and set the working directory using functions getwd and setwd. Set the working directory to the project directory using the menu: Session &gt; Set Working Directory &gt; To Project Directory. Now let us create some files: dir.create(&quot;subfolder&quot;) write_file(&quot;Some text in a file&quot;, path = &quot;test1.txt&quot;) write_file(&quot;Some other text in a file&quot;, path = &quot;subfolder/test2.txt&quot;) Which folders and files have been created? You may have a look in the Files plane in RStudio. We can read the file again using: read_file(&quot;test1.txt&quot;) #&gt; [1] &quot;Some text in a file&quot; &times; Solution read_file(&quot;subfolder/test2.txt&quot;) Close Solution Read the file test2.txt. Set the working directory to subfolder using function setwd. Note that setwd supports relative paths. Check that you are in the right working directory using getwd. You may also have a look at the files in the directory using function list.files. &times; Solution setwd(&quot;subfolder&quot;) # Q3 read_file(&quot;../test1.txt&quot;) read_file(&quot;test2.txt&quot;) Close Solution Read files test1.txt and test2.txt. Note that in relative paths ../ means going to the parent folder. What is different compared to Question 2? 3.10.5 Exercise (vectors) Solve this exercise using a script file. &times; Solution n &lt;- 100 n*(n+1)/2 Close Solution What is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum? &times; Solution n &lt;- 1000 n*(n+1)/2 Close Solution Now use the same formula to compute the sum of the integers from 1 through 1000. Look at the result of typing the following code into R: n &lt;- 1000 x &lt;- seq(1, n) sum(x) Based on the result, what do you think the functions seq and sum do? You can use help. sum creates a list of numbers and seq adds them up. seq creates a list of numbers and sum adds them up. seq creates a random list and sum computes the sum of 1 through 1,000. sum always returns the same number. Run code set.seed(123) v &lt;- sample.int(100,30) v #&gt; [1] 31 79 51 14 67 42 50 43 97 25 90 69 57 9 72 26 7 95 87 36 78 93 76 15 32 84 82 41 23 27 &times; Solution sum(v) mean(v) sd(v) Close Solution What is the sum, mean, and standard deviation of v? Select elements 1, 6, 4 and 15 of v. Select elements with value above 50. Select elements with value above 75 or below 25. Select elements with value 43. Select elements with value NA. Which elements have value above 75 or below 25? Hint: see the documentation of function which. 3.10.6 Exercise (matrices) Solve this exercise using a script file. Consider matrices m1 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3) m2 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), nrow = 3, byrow = TRUE) m3 &lt;- matrix(c(37, 8, 51, NA, 50, 97, 86, NA, 84, 46, 17, 62L), ncol = 3) What is the difference between the three matrices (think/discuss before running the code). &times; Solution rowSums(m1, na.rm = T) colSums(m2, na.rm = T) Close Solution Calculate the row sums of m1 and column sums of m2 ignoring NA values. Hint: have a look at the documentation of rowSums. &times; Solution rbind(m1, c(1, 2, 3, 4)) Close Solution Add row c(1, 2, 3, 4) as last row to m1. &times; Solution rbind(c(1, 2, 3, 4), m1) Close Solution Add row c(1, 2, 3, 4) as first row to m1. &times; Solution cbind(m3, c(1, 2, 3, 4)) Close Solution Add column c(1, 2, 3, 4) as last column to m3. &times; Solution m1[2,4] Close Solution Select the element in row 2 and column 4 of m1. &times; Solution m1[2:3,1:2] Close Solution Select elements in rows 2-3 and columns 1-2 of m1. &times; Solution m1[3, c(1,3,4)] Close Solution Select elements in row 3 and columns 1, 3 and 4 of m1. &times; Solution m1[3,] Close Solution Select elements in row 3 of m1. &times; Solution m2[is.na(m2)] Close Solution Select all NA elements in m2. &times; Solution m2[m2 &gt; 50] Close Solution Select all elements greater that 50 in m2. 3.10.7 Exercise (data frames) Solve this exercise using a script file. Data frames may be seen as cell blocks in Excel. They are representations of datasets in R where the rows correspond to observations and the columns correspond to variables that describe the observations. We consider the data frame mtcars: str(mtcars) glimpse(mtcars) ?mtcars Use the head and tail functions to have a look at the data. &times; Solution mtcars[,4] mtcars[,&quot;hp&quot;] mtcars$hp Close Solution Select column hp using index (column 4), its name, and the $ operator. &times; Solution mtcars &lt;- rbind(mtcars, c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3)) rownames(mtcars)[33] &lt;- &quot;Phantom XE&quot; Close Solution Update mtcars by adding row c(34, 3, 87, 112, 4.5, 1.515, 167, 1, 1, 5, 3). Name the row ‘Phantom XE’. &times; Solution col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) mtcars &lt;- cbind(mtcars, col) class(mtcars$col) Close Solution Update mtcars by adding column: col &lt;- c(NA, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, NA, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, NA, &quot;green&quot;, NA, &quot;blue&quot;, &quot;green&quot;, &quot;green&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, NA) What class is column col? &times; Solution mtcars[mtcars$vs == 0,] Close Solution Select cars with a V-shaped engine. 3.10.8 Exercise (lists) Solve this exercise using a script file. Lists are general containers that can be used to store a set of different objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. Let us define a list: lst &lt;- list(45, &quot;Lars&quot;, TRUE, 80.5) lst #&gt; [[1]] #&gt; [1] 45 #&gt; #&gt; [[2]] #&gt; [1] &quot;Lars&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE #&gt; #&gt; [[4]] #&gt; [1] 80.5 Elements can be accessed using brackets: x &lt;- lst[2] x #&gt; [[1]] #&gt; [1] &quot;Lars&quot; y &lt;- lst[[2]] y #&gt; [1] &quot;Lars&quot; &times; Solution class(x) class(y) Close Solution What is the class of the two objects x and y? What is the difference between using one or two brackets? &times; Solution names(lst) &lt;- c(&quot;age&quot;, &quot;name&quot;, &quot;male&quot;, &quot;weight&quot;) lst Close Solution Add names age, name, male and weight to the 4 components of the list. &times; Solution lst$name Close Solution Extract the name component using the $ operator. You can add/change/remove components using: lst$height &lt;- 173 # add component lst$name &lt;- list(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) # change the name component lst$male &lt;- NULL # remove male component lst #&gt; $age #&gt; [1] 45 #&gt; #&gt; $name #&gt; $name$first #&gt; [1] &quot;Lars&quot; #&gt; #&gt; $name$last #&gt; [1] &quot;Nielsen&quot; #&gt; #&gt; #&gt; $weight #&gt; [1] 80.5 #&gt; #&gt; $height #&gt; [1] 173 &times; Solution lst$name$last Close Solution Extract the last name component using the $ operator. 3.10.9 Exercise (string management) Strings in R can be defined using single or double quotes: str1 &lt;- &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business.&quot; str2 &lt;- &#39;BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&#39; str3 &lt;- c(str1, str2) # vector of strings The stringr package in tidyverse provides many useful functions for string manipulation. We will consider a few. str4 &lt;- str_c(str1, str2, &quot;As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot;, sep = &quot; &quot;) # join strings str4 #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using data sources.&quot; str_c(str3, collapse = &quot; &quot;) # collapse vector to a string #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) # replace first occurrence #&gt; [1] &quot;Business Analytics can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value.&quot; str_replace_all(str2, &quot;the&quot;, &quot;a&quot;) # replace all occurrences #&gt; [1] &quot;BA can both be seen as a complete decision making process for solving a business problem or as a set of methodologies that enable a creation of business value.&quot; str_remove(str1, &quot; for making better decisions in business&quot;) #&gt; [1] &quot;Business Analytics (BA) refers to the scientific process of transforming data into insight.&quot; str_detect(str2, &quot;BA&quot;) # detect a pattern #&gt; [1] TRUE &times; Solution str_detect(str1, &quot;Business&quot;) str_detect(str2, &quot;Business&quot;) Close Solution Is Business (case sensitive) contained in str1 and str2? &times; Solution str5 &lt;- str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) Close Solution Define a new string that replace BA with Business Analytics in str2 &times; Solution str5 &lt;- str_remove(str5, &quot; or as a set of methodologies that enable the creation of business value&quot;) Close Solution In the string from Question 2, remove or as a set of methodologies that enable the creation of business value. &times; Solution str5 &lt;- str_c(str5, &quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) Close Solution In the string from Question 3, add This course will focus on programming and descriptive analytics.. &times; Solution str5 &lt;- str_replace(str5, &quot;analytics&quot;, &quot;business analytics&quot;) Close Solution In the string from Question 4, replace analytics with business analytics. &times; Solution str_replace(str2, &quot;BA&quot;, &quot;Business Analytics&quot;) %&gt;% str_remove(&quot; or as a set of methodologies that enable the creation of business value&quot;) %&gt;% str_c(&quot;This course will focus on programming and descriptive analytics.&quot;, sep= &quot; &quot;) %&gt;% str_replace(&quot;analytics&quot;, &quot;business analytics&quot;) Close Solution Do all calculations in Question 2-5 using pipes. References "],
["sec-loops.html", "Module 4 Loops and conditionals 4.1 Learning outcomes 4.2 Conditionals and control flow 4.3 Loops 4.4 Different learning paths 4.5 Recap 4.6 Exercises", " Module 4 Loops and conditionals This module consider programming with loops and conditional statements. 4.1 Learning outcomes By the end of this module, you are expected to be able to: Formulate conditional statements. Use functions any, and all. Formulate loops in R using for and while statements. Use function if_else. 4.2 Conditionals and control flow An excellent introduction to conditionals and if statements is given in Chapter 1 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. Some functions are also useful for comparing logical data types. Consider example: x &lt;- c(1, 3, 5, 10, 2, 17, 11, NA, 4) x &gt; 10 # are the elements greater that 10 #&gt; [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE NA FALSE any(x &gt; 10) # are any of the elements greater that 10 #&gt; [1] TRUE all(x &gt; 10) # are all of the elements greater that 10 #&gt; [1] FALSE all(x &lt; 20) # are all of the elements greater that 20 #&gt; [1] NA all(x &lt; 20, na.rm = TRUE) # are all of the elements greater that 20 #&gt; [1] TRUE That is, functions any and all can be used to join logical values in vectors. Some if statements can be written alternatively using function if_else: if_else(condition, true, false, missing = NULL) For example: x &lt;- c(-5:5, NA) x #&gt; [1] -5 -4 -3 -2 -1 0 1 2 3 4 5 NA ## using if and for res &lt;- rep(&quot;&quot;, length(x)) for (i in seq_along(x)) { if (is.na(x[i])) res[i] &lt;- &quot;missing&quot; else if (x[i] &lt; 0) res[i] &lt;- &quot;negative&quot; else res[i] &lt;- &quot;positive&quot; } res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## implicit if statement res &lt;- rep(&quot;&quot;, length(x)) res #&gt; [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; res[x &lt; 0] &lt;- &quot;negative&quot; res[x &gt;= 0] &lt;- &quot;positive&quot; res[is.na(x)] &lt;- &quot;missing&quot; res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; ## using if_else res &lt;- if_else(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;, &quot;missing&quot;) res #&gt; [1] &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;negative&quot; &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; #&gt; [9] &quot;positive&quot; &quot;positive&quot; &quot;positive&quot; &quot;missing&quot; 4.3 Loops An excellent introduction to conditionals and if statements is given in Chapter 2 of the interactive DataCamp course Intermediate R. Please complete the chapter before continuing. For loops in R may be slow. However, not if you follow some golden rules: Don’t use a loop when a vectorized alternative exists Don’t grow objects (via c, cbind, etc) during the loop - R has to create a new object and copy across the information just to add a new element or row/column. Instead, allocate an object to hold the results and fill it in during the loop. As an example, consider the for loop with 4 iterations: i_val &lt;- c(1,2,6,9) res &lt;- rep(NA,4) res #&gt; [1] NA NA NA NA for (idx in 1:length(i_val)) { res[idx] &lt;- 6 * i_val[idx] + 9 } res #&gt; [1] 15 21 45 63 Note we allocate memory for the result vector before the loop so we don’t have to grow the result object. Next, we calculate results \\(6i+9\\) using a loop. Be careful here! This is not the same: res &lt;- rep(NA,4) for (i in i_val) { res[i] &lt;- 6 * i + 9 } res #&gt; [1] 15 21 NA NA NA 45 NA NA 63 In this example we however can use a vetorized alternative: res &lt;- 6 * i_val + 9 res #&gt; [1] 15 21 45 63 where the operation is applied to each element in the vector. Nested for loops are also possible. A simple example of a nested loop: for (i in 1:3) { for (j in 1:2) { cat(str_c(&quot;i =&quot;, i, &quot; j = &quot;,j, &quot;\\n&quot;)) } } #&gt; i =1 j = 1 #&gt; i =1 j = 2 #&gt; i =2 j = 1 #&gt; i =2 j = 2 #&gt; i =3 j = 1 #&gt; i =3 j = 2 We here uses the function cat to print out a string (\\n indicate new line). Note how the nested loops are executed: Set i = 1 (outer loop) Set j = 1 (inner loop), i stays 1 Set j = 2 (inner loop), i stays 1 Inner loop finishes, proceed with outer loop. Increase i = 2 (outer loop) Set j = 1 (inner loop), i stays 2 Set j = 2 (inner loop), i stays 2 Inner loop finishes, proceed with outer loop. Increase i = 3 (outer loop) Set j = 1 (inner loop), i stays 3 Set j = 2 (inner loop), i stays 3 Inner loop finishes, proceed with outer loop. Outer loop finishes as well (we looped over i in 1:3). Job done. Nested loops can be used to iterate over matrices or data frames: mat &lt;- matrix(NA, nrow = 2, ncol = 3) mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] NA NA NA for (i in 1:nrow(mat)) { for (j in 1:ncol(mat)) { mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Often you can replace nested loops with a single loop by using expand_grid: mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 1:2, j=1:3) ite #&gt; # A tibble: 6 x 2 #&gt; i j #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 1 #&gt; 2 1 2 #&gt; 3 1 3 #&gt; 4 2 1 #&gt; 5 2 2 #&gt; 6 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (1, 1) = 1 #&gt; Entry (1, 2) = 2 #&gt; Entry (1, 3) = 3 #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 2) = 5 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 Note expand_grid creates a data frame with all combinations. This way of looping is a more flexible approach since you can nest more loops by adding more columns to ite, add different values in each column. For instance, if you only want to calculate values for row 2 and columns 1 and 3 the code becomes: mat &lt;- matrix(NA, nrow = 2, ncol = 3) ite &lt;- expand_grid(i = 2, j = c(1,3)) ite #&gt; # A tibble: 2 x 2 #&gt; i j #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 #&gt; 2 2 3 for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] mat[i,j] &lt;- (i-1)*ncol(mat) + j cat(str_c(&quot;Entry (&quot;, i, &quot;, &quot;, j, &quot;) = &quot;, mat[i,j], &quot;\\n&quot;)) } #&gt; Entry (2, 1) = 4 #&gt; Entry (2, 3) = 6 mat #&gt; [,1] [,2] [,3] #&gt; [1,] NA NA NA #&gt; [2,] 4 NA 6 4.4 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Roger Peng has a video An introduction to control structures including if, for and while. Hefin Rhys has a video Conditional statements and loops in R doing examples in RStudio. For a more detailed introduction to loops see Chapter 21 in Wickham (2017). Loops can also be created using the apply family of functions. An introduction is given in Chapter 4 of the interactive DataCamp course Intermediate R. 4.5 Recap Comparison/relational operators known to R are: &lt; for less than, &gt; for greater than, &lt;= for less than or equal to, &gt;= for greater than or equal to, == for equal to each other (and not = which is typically used for assignment!), != not equal to each other. Logical operators known to R are: &amp; and, | or, ! not. If you use &amp;&amp; and || only the first element in vectors are compared. In general this is used rarely. Useful functions that return a logical are any and all which can be used to join logical values in vectors. Conditional Statements can be constructed using for instance if and while statements. Moreover, function if_else is a vetorized alternative. Loops can be created using for and while statements. You can break out of a look using break and jump to the next iteration (skipping the remainder of the code in the loop) using next. Don’t use a loop when a vectorized alternative exists. Don’t grow objects during the loop. Instead, allocate an object to hold the results and fill it in during the loop. Nested loops are possible in R. However, often they can be converted into a single loop by defining a data frame having the values of the nested loops in each row. Here function expand_grid may be useful to create the data frame. 4.6 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! 4.6.1 Exercise (conditional expressions) Solve this exercise using a script file Consider object x: x &lt;- c(1,2,-3,4) What will this conditional expression return? if(all(x&gt;0)){ print(&quot;All Postives&quot;) } else { print(&quot;Not all positives&quot;) } What will the following expressions return? x &lt;- c(TRUE, FALSE, TRUE, TRUE) all(x) any(x) any(!x) all(!x) Which of the expressions above is always FALSE when at least one entry of a logical vector x is TRUE? Consider vector: x &lt;- 1:15 x #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 &times; Solution if_else(x &lt; 7, as.integer(0), x) Close Solution Use the if_else function set elements with value below 7 to 0. &times; Solution if_else(x &lt; 7 | x &gt; 10, NA_integer_, x) Close Solution Use the if_else function set elements with value below 7 or above 10 to NA_integer_. Consider code x &lt;- sample(c(1:10,NA,5.5), 1) x #&gt; [1] 5.5 which generate a natural number from the vector c(1:10,NA,5.5). &times; Solution x &lt;- sample(c(1:10,NA,5.5), 1) if (is.na(x)) { y &lt;- &quot;missing&quot; } else if (x %% 2 == 0) { y &lt;- &quot;even&quot; } else if (x %% 2 == 1) { y &lt;- &quot;odd&quot; } else if (x %% 1 &gt; 0) { y &lt;- &quot;decimal&quot; } x y Close Solution Write code which set object y equal to “even” if x is even, “odd” if x is odd, “decimal” if x has a decimal not zero and “missing” if x is NA. Hint: have a look at ?'%%' (the modulo operator). 4.6.2 Exercise (loops) &times; Solution x &lt;- rep(NA,4) for (i in 1:4) { x[i] &lt;- 2 * i + 4 } x Close Solution 1) Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=1\\ldots 4\\). &times; Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) for (idx in 1:length(i_val)) { x[idx] &lt;- 2 * i_val[idx] + 4 } Close Solution 2) Using a for loop, create a vector having values \\(2i + 4\\) given \\(i=2,5,6,12\\). &times; Solution i_val &lt;- c(2, 5, 6, 12) x &lt;- rep(NA, length(i_val)) idx &lt;- 1 while (idx &lt; 5) { x[idx] &lt;- 2 * i_val[idx] + 4 idx &lt;- idx + 1 } Close Solution 3) Solve Question 2 using a while loop. &times; Solution 2 * 1:4 + 4 # Q1 2* c(2, 5, 6, 12) + 4 # Q2 Close Solution 4) Solve Question 1 and 2 using a vectorized alternative. &times; Solution 2 * 1:4 + 4 # Q1 2* c(2, 5, 6, 12) + 4 # Q2 Close Solution 5) Solve Question 1 and 2 using a vectorized alternative. 4.6.3 Exercise (calculating distances) Consider zip codes in Jutland: library(tfa) zips #&gt; # A tibble: 376 x 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; #&gt; 6 8592 &quot;Anholt&quot; #&gt; 7 8643 &quot;Ans By&quot; #&gt; 8 6823 &quot;Ansager&quot; #&gt; 9 9510 &quot;Arden&quot; #&gt; 10 5466 &quot;Asperup&quot; #&gt; # … with 366 more rows We want to calculate distances between between a subset of zip areas: idx &lt;- 1:5 dat &lt;- zips[idx,] dat #&gt; # A tibble: 5 x 2 #&gt; Zip Area #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5320 &quot;Agedrup&quot; #&gt; 2 6753 &quot;Agerb\\xe6k&quot; #&gt; 3 6534 &quot;Agerskov&quot; #&gt; 4 8961 &quot;Alling\\xe5bro&quot; #&gt; 5 6051 &quot;Almind&quot; distanceMat &lt;- matrix(NA, nrow = length(idx), ncol = length(idx)) colnames(distanceMat) &lt;- str_c(dat$Zip[idx], dat$Area[idx], sep = &quot; &quot;) rownames(distanceMat) &lt;- colnames(distanceMat) distanceMat #&gt; 5320 Agedrup 6753 Agerb\\xe6k 6534 Agerskov 8961 Alling\\xe5bro 6051 Almind #&gt; 5320 Agedrup NA NA NA NA NA #&gt; 6753 Agerb\\xe6k NA NA NA NA NA #&gt; 6534 Agerskov NA NA NA NA NA #&gt; 8961 Alling\\xe5bro NA NA NA NA NA #&gt; 6051 Almind NA NA NA NA NA We can find average distances between two zip codes (here rows 1 and 2 in dat) using Bing maps: key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[1], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[2], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) library(jsonlite) lst &lt;- jsonlite::fromJSON(url) dist &lt;- lst$resourceSets$resources[[1]]$travelDistance dist #&gt; [1] 139 lst$statusCode #&gt; [1] 200 lst$statusDescription #&gt; [1] &quot;OK&quot; Note we call the Bing maps API with the two zip codes. A json file is returned and stored in a list. To get the average travel distance we access travelDistance. The status code should be 200 if the calculation returned is okay. &times; Solution key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for(i in 1:nrow(distanceMat)) { for(j in 1:ncol(distanceMat)) { if (i&gt;j) {distanceMat[i,j] &lt;- distanceMat[j,i]; next} # assume symetric distances if (!is.na(distanceMat[i,j])) next # value already calculated if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance } } } distanceMat Close Solution Use nested for loops to fill distanceMat with distances. Assume that the distance from a to b is the same as from b to a. That is, you only have to call the API once for two zip codes. Use an if statement to check if the status code is okay. 4.6.4 Exercise (expand_grid) &times; Solution ite &lt;- expand_grid(i = c(1,5), j = 2:3) ite key &lt;- &quot;AlUJdApmvPe8y2_IMrC4j4x8fzytbD2M0SvlmpemL09ae_CWS6-IuNSgrAtXoyeP&quot; for (r in 1:nrow(ite)) { # iterate over rows i &lt;- ite$i[r] j &lt;- ite$j[r] if (i==j) {distanceMat[i,j] &lt;- 0; next} url &lt;- str_c(&quot;http://dev.virtualearth.net/REST/V1/Routes/Driving?wp.0=&quot;, dat$Zip[i], &quot;,Denmark&quot;, &quot;&amp;wp.1=&quot;, dat$Zip[j], &quot;,Denmark&quot;, &quot;&amp;avoid=minimizeTolls&amp;key=&quot;, key) lst &lt;- jsonlite::fromJSON(url) if (lst$statusCode == 200) { distanceMat[i,j] &lt;- lst$resourceSets$resources[[1]]$travelDistance distanceMat[j,i] &lt;- distanceMat[i,j] } } distanceMat Close Solution Consider the solution of Exercise 4.6.3 and assume that you only want to calculate the distance from rows 1 and 5 to rows 2 and 3 in dat. Modify the solution using expand_grid so only one loop is used. References "],
["sec-functions.html", "Module 5 Functions 5.1 Learning outcomes 5.2 DataCamp course 5.3 Functions returning multiple objects 5.4 The ... argument 5.5 Documenting your functions 5.6 Different learning paths 5.7 Recap 5.8 Exercises", " Module 5 Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. John Chambers Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that need to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style how code is written. Rather than repeating code, functions and control structures allow one to build code in blocks. As a result your code becomes more structured, more readable and much easier to maintain and debug (find errors). 5.1 Learning outcomes By the end of this module, you are expected to be able to: Call a function. Formulate a function with different input arguments. Describe why functions are important in R. Set defaults for input arguments. Return values from functions. Explain how variable scope and precedence works. Document functions. 5.2 DataCamp course An excellent introduction to functions is given in Chapter 3 in the DataCamp course [Intermediate R][datacamp-intermediate-r]. Please complete the chapter before continuing. 5.3 Functions returning multiple objects Functions in R only return a single object. However, note that the object may be a list. That is, if you want to return multiple arguments store them in a list. A simple example: test &lt;- function() { # the function do some stuff and calculate some results res1 &lt;- 45 res2 &lt;- &quot;Success&quot; res3 &lt;- c(4, 7, 9) res4 &lt;- list(cost = 23, profit = 200) lst &lt;- list(days = res1, run = res2, id = res3, money = res4) return(lst) } test() #&gt; $days #&gt; [1] 45 #&gt; #&gt; $run #&gt; [1] &quot;Success&quot; #&gt; #&gt; $id #&gt; [1] 4 7 9 #&gt; #&gt; $money #&gt; $money$cost #&gt; [1] 23 #&gt; #&gt; $money$profit #&gt; [1] 200 5.4 The ... argument The special argument ... which indicate a variable number of arguments and is usually used to pass arguments to nested functions used inside the function. Consider example: my_name &lt;- function(first = &quot;Lars&quot;, last = &quot;Nielsen&quot;) { str_c(first, last, sep = &quot; &quot;) } my_name() #&gt; [1] &quot;Lars Nielsen&quot; cite_text &lt;- function(text, ...) { str_c(text, &#39;, -&#39;, my_name(...)) } cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Nielsen&quot; cite_text(&quot;Learning by doing is the best way to learn how to program!&quot;, last = &quot;Relund&quot;) #&gt; [1] &quot;Learning by doing is the best way to learn how to program!, -Lars Relund&quot; cite_text(&quot;To be or not to be&quot;, first = &quot;Shakespeare&quot;, last = &quot;&quot;) #&gt; [1] &quot;To be or not to be, -Shakespeare &quot; Note in the first function run we use the defaults in my_name. In the second run, we change the default last name and in the last run, we change both arguments. If you need to retrieve/capture the content of the ... argument, put it in a list: test &lt;- function(...) { return(list(...)) } test(x = 4, y = &quot;hey&quot;, z = 1:5) #&gt; $x #&gt; [1] 4 #&gt; #&gt; $y #&gt; [1] &quot;hey&quot; #&gt; #&gt; $z #&gt; [1] 1 2 3 4 5 5.5 Documenting your functions It is always a good idea to document your functions. This is in fact always done in functions of a package. For instance try ?mutate and see the documentation in the Help tab. Assume that you have written a function subtract &lt;- function(x, y) { return(x-y) } In RStudio you can insert a Roxygen documentation skeleton by having the cursor at the first line of the function and go to Code &gt; Insert Roxygen Skeleton (Ctrl+Alt+Shift+R): #&#39; Title #&#39; #&#39; @param x #&#39; @param y #&#39; #&#39; @return #&#39; @export #&#39; #&#39; @examples subtract &lt;- function(x, y) { return(x-y) } You now can modify your documentation to #&#39; Subtract two vectors #&#39; #&#39; @param x First vector. #&#39; @param y Vector to be subtracted. #&#39; #&#39; @return The difference. #&#39; @export #&#39; #&#39; @examples #&#39; subtract(x = c(5,5), y = c(2,3)) subtract &lt;- function(x, y) { return(x-y) } Note Parameters/function arguments are documented using the @param tag. Return value is documented using the @return tag. Under the @examples tag you can insert some examples. Ignore the @export tag. This is used if you include your function in your own package. Package development is beyond the scope of this course. If you are interested, have a look at the book Wickham (2015). A list of further tags can be seen in the vignette Rd (documentation) tags. 5.6 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. For a more detailed interactive tutorial about functions see the DataCamp course Introduction to Writing Functions in R. Hefin Rhys has a video about Writing functions in R giving examples in RStudio. An introduction to functions is also given in Chapter 14 of Peng (2018). A detailed tutorial on functions is given in Chapters 18, 19 and 20 of Bryan (2017). 5.7 Recap Writing functions is a core activity of an R programmer. It represents the key step of the transition from a user to a programmer. Functions have inputs and outputs. Functions (and control structures) are what makes your code more dynamic. Functions are often used to encapsulate a sequence of expressions that need to be executed numerous times, perhaps under slightly different conditions. In programming, functional programming is a programming paradigm, a style how code is written. Rather than repeating code, functions and control structures allow one to build code in blocks. As a result your code becomes more structured, more readable and much easier to maintain and debug (find errors). Functions can be defined using the function() directive. The named arguments (input values) can have default values. Moreover, R passes arguments by value. That is, an R function cannot change the variable that you input to that function. A function can be called using its name and its arguments can be specified by name or by position in the argument list. Functions always return the last expression evaluated in the function body or when you use the return flow control statement (good coding practice). Scoping refers to the rules R uses to lookup the value of variables. A function will first look inside the body of the function to identify all the variables. If all variables exist no further search are required. Otherwise, R will look one level up to see if the variable exists. Functions can be assigned to R objects just like any other R object. Document your functions using the Roxygen skeleton! 5.8 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! 5.8.1 Exercise (defining functions) Solve this exercise using a script file. &times; Solution #&#39; Computes the sum of the integers from 1 to n (inclusive). #&#39; #&#39; @param n Max value in the sum. #&#39; #&#39; @return Sum of the integers from 1 to n. #&#39; #&#39; @examples #&#39; sum_n(30) sum_n &lt;- function(n) { return(sum(1:n)) } sum_n(5000) Close Solution Create a function sum_n that for any given value, say \\(n\\), computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5000. Remember to document your function. &times; Solution #&#39; Computes the sum S_n = 1^2 + 2^2 + 3^2 + ... + n^2 #&#39; #&#39; @param n Max input in sum. #&#39; #&#39; @return S_n compute_s_n &lt;- function(n) { return(sum((1:n)^2)) } compute_s_n(10) Close Solution Write a function compute_s_n that for any given \\(n\\) computes the sum \\(S_n = 1^2 + 2^2 + 3^2 + \\dots + n^2\\). Report the value of the sum when \\(n=10\\). &times; Solution s_n &lt;- vector(&#39;numeric&#39;, 25) for (n in 1:25) { s_n[n] &lt;- compute_s_n(n) } s_n Close Solution Define an empty numerical vector s_n of size 25 using s_n &lt;- vector(\"numeric\", 25) and store in the results of \\(S_1, S_2, \\dots S_{25}\\) using a for-loop. &times; Solution compute_s_n_alt &lt;- function(n) { return(n*(n+1)*(2*n+1)/6) } for (n in 1:25) { if (s_n[n] != compute_s_n_alt(n)) { cat(&#39;Error!&#39;) break } } Close Solution Confirm that the formula for the sum is \\(S_n= n(n+1)(2n+1)/6\\) for \\(n = 1, \\ldots, 25\\). &times; Solution biggest &lt;- function(a, b) { if (a &gt; b) return(1) return(0) } biggest(3,4) biggest(3,3) biggest(8,2) Close Solution Write a function biggest which takes two integers as arguments. Let the function return 1 if the first argument is larger than the second and return 0 otherwise. &times; Solution shipping_cost &lt;- function(total) { return(0.1 * total) } shipping_cost(450) Close Solution Write a function that returns the shipping cost as 10% of the total cost of an order (input argument). &times; Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } shipping_cost(450) shipping_cost(450, pct = 0.2) Close Solution Given Question 5, rewrite the function so the percentage is an input argument with a default of 10%. &times; Solution shipping_cost &lt;- function(total) { return(0.1 * total) } gasoline_cost &lt;- function(total) { return(shipping_cost(total) * 0.5) } gasoline_cost(450) Close Solution Given Question 5 the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost a input argument and calculate the gasoline cost and uses the function defined in Question 5 inside it. &times; Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } gasoline_cost(450) gasoline_cost(450, pct = 0.2) Close Solution Given Question 6 the shipping cost can be split into parts. One part is gasoline which is 50% of the shipping cost. Write a function that has total cost a input argument and calculate the gasoline cost and uses the function defined in Question 6 inside it. Hint: Use the ... argument to pass arguments to shipping_cost. &times; Solution shipping_cost &lt;- function(total, pct = 0.1) { return(pct * total) } gasoline_cost &lt;- function(total, ...) { return(shipping_cost(total, ...) * 0.5) } costs &lt;- function(total, ...) { lst &lt;- list(total = total, shipping = shipping_cost(total, ...), gasoline = gasoline_cost(total, ...)) return(lst) } costs(450) costs(450, pct = 0.15) Close Solution Given Question 8, write a function costs that given total cost returns the total cost, shipping cost and gasoline cost. 5.8.2 Exercise (scope) &times; Solution That value is still 3 since x defined inside the function is a local variable. Close Solution After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 5 return(y + 5) } my_func(7) &times; Solution The code runs. But it is not good coding practice to call global variables inside a function (x). Instead x should have been an argument to the function. Close Solution Any problems with the following code? x &lt;- 3 my_func &lt;- function(y){ return(y + x) } my_func(7) &times; Solution That value is still 3 since my_func has not been called yet. Close Solution Have a look at the documentation for operator &lt;&lt;- (run ?'&lt;--'). After running the code below, what is the value of variable x? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + 5) } &times; Solution That value of x is 5 since &lt;&lt;- is used to look at the parent environment. The function call returns 11 since the x used is the local variable. In general avoid using &lt;&lt;- and give local variables different names compared to global ones. Close Solution After running the code below, what is the value of variable x and output of the function call? x &lt;- 3 my_func &lt;- function(y){ x &lt;- 4 x &lt;&lt;- 5 return(y + x) } my_func(7) 5.8.3 Exercise (job sequencing) Solve this exercise using a script file. This exercise is based on on Exercise 6.12 in Wøhlk (2010). Consider a problem of determining the best sequencing of jobs on a machine. A set of startup costs are given for 5 machines: startup_costs &lt;- c(27, 28, 32, 35, 26) startup_costs #&gt; [1] 27 28 32 35 26 Moreover, when changing from one job to another job the setup costs are given as: setup_costs &lt;- matrix(c( NA, 35, 22, 44, 12, 49, NA, 46, 38, 17, 46, 12, NA, 29, 41, 23, 37, 31, NA, 26, 17, 23, 28, 34, NA), byrow = T, nrow = 5) setup_costs #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] NA 35 22 44 12 #&gt; [2,] 49 NA 46 38 17 #&gt; [3,] 46 12 NA 29 41 #&gt; [4,] 23 37 31 NA 26 #&gt; [5,] 17 23 28 34 NA The goal of the problem is to determine a sequence of jobs which minimizes the total setup cost including the startup cost. One possible way to find a sequence is the use a greedy strategy: Greedy Algorithm Step 0: Start with the job which has minimal startup cost. Step 1: Select the next job as the job not already done with minimal setup cost given current job. Step 2: Set next job in Step 1 to current job and go to Step 1 if not all jobs are done. In R the greedy algorithm can be implemented as: greedy &lt;- function(startup, setup) { jobs &lt;- nrow(setup) cur_job &lt;- which.min(startup) cost &lt;- startup[cur_job] cat(&quot;Start job:&quot;, cur_job, &quot;\\n&quot;) job_seq &lt;- cur_job setup[, cur_job] &lt;- NA # browser() for (i in 1:(jobs-1)) { next_job &lt;- which.min(setup[cur_job, ]) cat(&quot;Next job:&quot;, next_job, &quot;\\n&quot;) cost &lt;- cost + setup[cur_job, next_job] job_seq &lt;- c(job_seq, next_job) cur_job &lt;- next_job setup[, cur_job] &lt;- NA } # print(setup) return(list(seq = job_seq, cost = cost)) } greedy(startup_costs, setup_costs) #&gt; Start job: 5 #&gt; Next job: 1 #&gt; Next job: 3 #&gt; Next job: 2 #&gt; Next job: 4 #&gt; $seq #&gt; [1] 5 1 3 2 4 #&gt; #&gt; $cost #&gt; [1] 115 First, the job with minimum startup cost is found using function which.min and we define cost a the startup cost. We use cat to make some debugging statements and initialize job_seq with the first job. Next we have to have a way ignoring jobs already done. We do that here by setting the columns of setup cost equal to NA for jobs already done. Hence they will not be selected by which.min. The for loop runs 4 times and selects jobs and accumulate the total cost. A well-known better strategy is to: Better Algorithm Step 0: Subtract minimum of startup and setup cost for each job from setup and startup costs (that is columnwise) Step 1: Call the greedy algorithm with the modified costs. Note that the total cost returned has to be modified a bit. #&gt; Start job: 4 #&gt; Next job: 1 #&gt; Next job: 3 #&gt; Next job: 2 #&gt; Next job: 5 &times; Solution better &lt;- function(startup, setup) { jobs &lt;- nrow(setup) min_col_val &lt;- apply(rbind(startup, setup), 2, min, na.rm = T) startup &lt;- startup - min_col_val min_mat &lt;- matrix(rep(min_col_val, jobs), ncol = jobs, byrow = T) setup &lt;- setup - min_mat lst &lt;- greedy(startup, setup) lst$cost &lt;- lst$cost + sum(min_col_val) return(lst) } better(startup_costs, setup_costs) Close Solution Implement a better function calculating a better strategy. Hint: to find the minimum column costs you may use apply(rbind(startup, setup), 2, min, na.rm = T). References "],
["sec-tidy-intro.html", "Module 6 Introduction to tidyverse and R Markdown 6.1 Learning outcomes 6.2 The tidyverse package 6.3 Writing reproducible reports 6.4 Tibbles 6.5 Different learning paths 6.6 Recap 6.7 Exercises", " Module 6 Introduction to tidyverse and R Markdown 6.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what the tidyverse package is. Explain the ideas behind reproducible reports and literal programming. Create your first R Markdown document and add some code and text. 6.2 The tidyverse package The tidyverse is an collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The core tidyverse includes the packages that you’re likely to use in everyday data analyses. In tidyverse 1.3.0, the following packages are included in the core tidyverse: dplyr provides a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges. We are going to use dplyr in Module 8. ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. We are going to use ggplot in Module 9. tidyr provides a set of functions that help you get to tidy data. Tidy data is data with a consistent form: in brief, every variable goes in a column, and every column is a variable. readr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes. We are going to use dplyr in Module 7. purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. Once you master the basic concepts, purrr allows you to replace many for loops with code that is easier to write and more expressive. This package is not covered by this course. tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what it has not. Tibbles are data.frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code. We are going to use tibbles in Module 8. stringr provides a cohesive set of functions designed to make working with strings as easy as possible. You have already worked a bit with stringr in Exercise 3.10.9 forcats provides a suite of useful tools that solve common problems with factors. R uses factors to handle categorical variables, variables that have a fixed and known set of possible values. This package is not covered by this course. Small introductions (with examples) to the packages are given on their documentation pages (follow the links above). The tidyverse also includes many other packages with more specialized usage. They are not loaded automatically with library(tidyverse), so you’ll need to load each one with its own call to library(). 6.3 Writing reproducible reports The concept of literate programming was originally introduced by Donald Knuth in 1984. In a nutshell, Knuth envisioned a new programming paradigm where computer scientists focus on weaving code together with text as documentation. That is, when we do an Analytics project, are we interested in writing reports containing both R code for importing data, wangling and analysis. Moreover, at the same time the document should contain our comments about the code, plots, analysis, results etc. The document is then rendered to an output format such as html, pdf or Word which is presented to the decision maker. Note the document can be seen as the “the source code” for the report communicated to the decision maker. Some developers have created tools to enable others to write better literate programs. They use a markup language made for authoring. We are going to focus on R Markdown. In R Markdown documents you can weave R code together with text (written in Markdown) to produce elegantly formatted output. In fact this book is written in R Markdown by using a set of R Markdown documents bound together as a collection using the bookdown package, rendered to a web-page using RStudio, shared on GitHub, built by GitHub Actions, and published on GitHub Pages. This may seem complicated at first. However, after setup it has made life much easier since we can update the book easier, share and collaborate on the book easier, update the web-page automatically, keep history of the book source. and keep the book source at a single location. R Markdown documents are reproducible. Anybody who works with data has at some point heard a colleague say ‘Well, it works on my computer’, expressing dismay at the fact that you cannot reproduce their results. Ultimately, reproducible means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. For instance, people may be using a different operating system, other versions of the software etc. That is, there are different levels of reproducibility. In this course we will focus on R Markdown only. See Section 6.5 for more info about levels of reproducibility. An introduction to R Markdown is given in the Chapters 3 and 4 of the Datacamp course Communicating with Data in the Tidyverse. Note that you may skip Chapters 1 and 2 and still understand mostly of the questions in Chapters 3 and 4 (otherwise just see the solution). You are expected to have completed the chapters before continuing this module! 6.4 Tibbles Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. This forces you to confront problems earlier, typically leading to cleaner, more expressive code. Moreover, tibbles have an enhanced print method and can have columns that are lists. Let us see a few examples: tbl1 &lt;- tibble(name = c(&quot;Lars&quot;, &quot;Susan&quot;, &quot;Hans&quot;), age = c(23, 56, 45)) tbl1 #&gt; # A tibble: 3 x 2 #&gt; name age #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Lars 23 #&gt; 2 Susan 56 #&gt; 3 Hans 45 tbl2 &lt;- tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) tbl2 #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;int&gt; &lt;list&gt; #&gt; 1 1 &lt;int [5]&gt; #&gt; 2 2 &lt;int [10]&gt; #&gt; 3 3 &lt;int [20]&gt; tbl3 &lt;- as_tibble(mtcars) tbl3 #&gt; # A tibble: 33 x 12 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 green #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 red #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 blue #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 green #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 blue #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 red #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 red #&gt; # … with 23 more rows tbl4 &lt;- tribble( ~x, ~y, ~z, #--|--|---- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) tbl4 #&gt; # A tibble: 2 x 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 2 3.6 #&gt; 2 b 1 8.5 Note that we can always coerce a data frame to a tibble (tbl3) or create it directly using tibble. Another way to create a tibble is with tribble. Here column headings are defined by formulas (i.e. they start with ~), and entries are separated by commas. This makes it possible to lay out small amounts of data in easy to read form. Tibbles have a refined print method that shows only the first 10 rows along with the number of columns that will fit on your screen. This makes it much easier to work with large data. In addition to its name, each column reports its type. Hence your console is not overwhelmed with data. To see a full view of the data you may use RStudio’s built-in data viewer: View(tbl3) 6.5 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Chapter 4 in Ismay and Kennedy (2019) gives an overview over R Markdown with videos included. You may also do the interactive DataCamp Reporting with R Markdown which is a bit longer than the suggested course. If Help &gt; Markdown Quick Reference not is enough then try out this interactive markdown tutorial. The R Markdown cheatsheet may be useful. Find the newest version in RStudio Help &gt; Cheatsheets. Glenn Moncrieff gives a nice detained overview on how to create reproducible projects. If you are interested in trying Git and GitHub out see Bryan, STAT 545 TAs, and Hester (2020) for detailed help. All chunk options for R code can be seen here. An introduction to tibbles and differences to data frames is given in the video Working with tibbles in R by Hefin Rhys. Chapter 10 in Wickham (2017) gives an introduction to tibbles. 6.6 Recap The tidyverse is an collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. R Markdown is an example of literate programming. The core tidyverse includes the packages that you’re likely to use in everyday data analyses. The concept of literate programming is a programming paradigm which focus on weaving code together with text as documentation. That is, we are interested in writing reports containing both text and R code for importing data, wangling and analysis. Reproducibility means that the results can be reproduced given access to the original data, software, and code. In practice it may be hard to make your project totally reproducible. That is, there are different levels of reproducibility. R Markdown documents are a attempt to make reproducible documents and combine R code and markdown text. Tibbles are a modern data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are more strict compared to data frames e.g. they do not change variable names or types, do not do partial matching and complain more e.g. when a variable does not exist. Tibbles have an enhanced print method and can have columns that are lists. 6.7 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! 6.7.1 Exercise (your first R Markdown exercise) Load the tfa package: # remotes::install_github(&quot;bss-osca/tfa/tfa-package&quot;) # if not installed library(tfa) The package contains templates for exercises etc. Go to File &gt; New File &gt; R Markdown…. In the pop-up box select From template in the left column and then TFA Exercise. Press Ok and a new R Markdown document will be opened. Change the meta text (e.g. the title and add your name) in the yaml. Render/compile the document by pressing the Knit button (or Ctrl+Shift+K). &times; Solution All the code is now hidden. But not the output. Close Solution Change echo = TRUE to echo = FALSE in the first chunk setup and render the document. What have happened? You can easily go to a chunk using the navigation in the bottom left of the source window. Try to change fig.asp = 0.25 to e.g. 0.5 in Chunk 10. What happens? Create a new section `## Question 4 and add text in italic: What is the sum of all setup costs? &times; Solution total &lt;- sum(setup_costs) Close Solution Add a code chunk solving Question 5 above. &times; Solution The sum of all setup costs are `r total`. Close Solution Add a line of text with the result. 6.7.2 Exercise (tibbles) Solve this exercise using a R script file. Convert the dataset airquality to a tibble. Print the tibble and the original data frame and compare the difference. Create a tibble with 3 columns of data type string/character, double and list. Task/checklist box: * dasf * fsa * 324 Exercise box: **Exercise 1** asdf asdlfkj sdfklj fsdjka æ 1. sdf 2. edasf **Exercise 2** asdfav sdaf sdhj sdjkahdf jkhasdkjæsdfh asjf 1. sdf 2. sdf Numbered exercises with hints: ## Exercises Exercises are numbered using [module number].[section number].[exercise number]. ### Exercise (install packages) This exercise is done from the Console in RStudio. 1) Install the package `devtools` using function `install.packages`. Note you can always get help/see documentation by typing `?install.packages` or typing `install.packages` and press F1. You now have install the package from the default repository ([CRAN][cran]). You may also install packages from other repositories (e.g. GitHub) 1) Have a look at the documentation for function `install_github` in the package `devtools`. This can be done in different ways: ```r library(devtools) # we here load all the functions in devtools ?install_github ?devtools::install_github # we here use the namespace devtools to load only one function ``` 1) Install the package `tfa` from github using path `` ```r # filter the flights table to include only United and # American flights ``` References "],
["sec-io.html", "Module 7 Importing and exporting data 7.1 Learning outcomes 7.2 CSV files 7.3 Excel 7.4 Google Sheets 7.5 Text files 7.6 R’s native binary format 7.7 Json 7.8 Different learning paths 7.9 Recap 7.10 Exercises", " Module 7 Importing and exporting data For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. Moreover, after processing data you often want to export or store some of the results. This module introduces you to different ways of importing and exporting data. 7.1 Learning outcomes By the end of this module, you are expected to be able to: Import and export csv files in different formats. Import and export data from Excel. Import and export data from Google Sheets Write to a text file. Save data using R’s native format. Read and write to a json file. 7.2 CSV files CSV files contains comma separated values (csv) in plain text and are often named using the file suffix .csv. Each line of the file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The CSV file format is not fully standardized. Different delimiters may be used, fields may be surrounded by quotation marks, text may contain escape characters and the encoding of the file may not be known. Despite these problems CSV files are commonly used since they are easy to exchange and read. We will use the [readr][readr-web] package for reading and writing. An overview over the functions can be seen in the cheatsheet. 7.2.1 Reading a CSV file In general use the following functions read_csv: Read a file with delimiter ,. read_csv2: Read a file with delimiter ;. read_delim: Read a file with a delimiter set by you. 7.2.1.1 Reading an unknown CSV file For importing a CSV file properly you need to know the delimiter, if the files has headers and the encoding. If you are not sure, you may have a look on the file by opening it in a text editor or try to read some lines: csv_file &lt;- system.file(&quot;extdata/mtcars.csv&quot;, package = &quot;readr&quot;) # csv file lines &lt;- read_lines(csv_file, n_max = 3) lines #&gt; [1] &quot;\\&quot;mpg\\&quot;,\\&quot;cyl\\&quot;,\\&quot;disp\\&quot;,\\&quot;hp\\&quot;,\\&quot;drat\\&quot;,\\&quot;wt\\&quot;,\\&quot;qsec\\&quot;,\\&quot;vs\\&quot;,\\&quot;am\\&quot;,\\&quot;gear\\&quot;,\\&quot;carb\\&quot;&quot; #&gt; [2] &quot;21,6,160,110,3.9,2.62,16.46,0,1,4,4&quot; #&gt; [3] &quot;21,6,160,110,3.9,2.875,17.02,0,1,4,4&quot; cat(lines, sep = &quot;\\n&quot;) #&gt; &quot;mpg&quot;,&quot;cyl&quot;,&quot;disp&quot;,&quot;hp&quot;,&quot;drat&quot;,&quot;wt&quot;,&quot;qsec&quot;,&quot;vs&quot;,&quot;am&quot;,&quot;gear&quot;,&quot;carb&quot; #&gt; 21,6,160,110,3.9,2.62,16.46,0,1,4,4 #&gt; 21,6,160,110,3.9,2.875,17.02,0,1,4,4 It seems that the delimiter is a , and we may try to read the file using read_csv: dat &lt;- read_csv(csv_file) head(dat) #&gt; # A tibble: 6 x 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Consider another example: csv_file &lt;- system.file(&quot;extdata/massey-rating.txt&quot;, package = &quot;readr&quot;) lines &lt;- read_lines(csv_file, n_max = 3) cat(lines, sep = &quot;\\n&quot;) #&gt; UCC PAY LAZ KPK RT COF BIH DII ENG ACU Rank Team Conf #&gt; 1 1 1 1 1 1 1 1 1 1 1 Ohio St B10 #&gt; 2 2 2 2 2 2 2 2 4 2 2 Oregon P12 Here it is harder to guess the delimiter. It could be a space or a tabulator. Let us try to read it assuming a space or tabulator read_tsv(csv_file) # assume tabulator (\\t) #&gt; # A tibble: 10 x 1 #&gt; `UCC PAY LAZ KPK RT COF BIH DII ENG ACU Rank Team Conf` #&gt; &lt;chr&gt; #&gt; 1 1 1 1 1 1 1 1 1 1 1 1 Ohio St B10 #&gt; 2 2 2 2 2 2 2 2 2 4 2 2 Oregon P12 #&gt; 3 3 4 3 4 3 4 3 4 2 3 3 Alabama SEC #&gt; 4 4 3 4 3 4 3 5 3 3 4 4 TCU B12 #&gt; 5 6 6 6 5 5 7 6 5 6 11 5 Michigan St B10 #&gt; 6 7 7 7 6 7 6 11 8 7 8 6 Georgia SEC #&gt; 7 5 5 5 7 6 8 4 6 5 5 7 Florida St ACC #&gt; 8 8 8 9 9 10 5 7 7 10 7 8 Baylor B12 #&gt; 9 9 11 8 13 11 11 12 9 14 9 9 Georgia Tech ACC #&gt; 10 13 10 13 11 8 9 10 11 9 10 10 Mississippi SEC read_delim(csv_file, delim = &quot; &quot;, trim_ws = T) # assume space #&gt; Warning: 10 parsing failures. #&gt; row col expected actual file #&gt; 1 -- 13 columns 15 columns &#39;/Users/runner/work/_temp/Library/readr/extdata/massey-rating.txt&#39; #&gt; 2 -- 13 columns 14 columns &#39;/Users/runner/work/_temp/Library/readr/extdata/massey-rating.txt&#39; #&gt; 3 -- 13 columns 14 columns &#39;/Users/runner/work/_temp/Library/readr/extdata/massey-rating.txt&#39; #&gt; 4 -- 13 columns 14 columns &#39;/Users/runner/work/_temp/Library/readr/extdata/massey-rating.txt&#39; #&gt; 5 -- 13 columns 15 columns &#39;/Users/runner/work/_temp/Library/readr/extdata/massey-rating.txt&#39; #&gt; ... ... .......... .......... .................................................................. #&gt; See problems(...) for more details. #&gt; # A tibble: 10 x 13 #&gt; UCC PAY LAZ KPK RT COF BIH DII ENG ACU Rank Team Conf #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 1 1 1 1 1 1 1 1 1 1 Ohio St #&gt; 2 2 2 2 2 2 2 2 2 4 2 2 Oregon P12 #&gt; 3 3 4 3 4 3 4 3 4 2 3 3 Alabama SEC #&gt; 4 4 3 4 3 4 3 5 3 3 4 4 TCU B12 #&gt; 5 6 6 6 5 5 7 6 5 6 11 5 Michigan St #&gt; 6 7 7 7 6 7 6 11 8 7 8 6 Georgia SEC #&gt; 7 5 5 5 7 6 8 4 6 5 5 7 Florida St #&gt; 8 8 8 9 9 10 5 7 7 10 7 8 Baylor B12 #&gt; 9 9 11 8 13 11 11 12 9 14 9 9 Georgia Tech #&gt; 10 13 10 13 11 8 9 10 11 9 10 10 Mississippi SEC The first function puts all data in one column. The second function worked even though we have some warnings. CSV files should always be saved using encoding UTF-8. However, sometimes you may have encoding problems when you read a file: csv_file &lt;- system.file(&quot;extdata/persons.csv&quot;, package = &quot;tfa&quot;) read_csv(csv_file) #&gt; # A tibble: 3 x 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &quot;Hans&quot; &quot;S\\xf8gaard&quot; #&gt; 2 &quot;\\xc5ge&quot; &quot;\\xd8kse&quot; #&gt; 3 &quot;Yvette&quot; &quot;L\\xe6ske&quot; Note that some of the characters are not converted correctly. This is usually because the file encoding is not UTF-8. In this case try to guess the encoding using guess_encoding(csv_file) #&gt; # A tibble: 1 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ISO-8859-1 0.27 dat &lt;- read_csv(csv_file, locale = locale(encoding = &quot;ISO-8859-1&quot;)) dat #&gt; # A tibble: 3 x 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske 7.2.2 Writing to CSV files Given a tibble/data frame export it using write_csv: csv_file &lt;- &quot;testing.csv&quot; write_csv(dat, path = csv_file) You can now always import the data again using read_csv: read_csv(csv_file) #&gt; # A tibble: 3 x 2 #&gt; first last #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Hans Søgaard #&gt; 2 Åge Økse #&gt; 3 Yvette Læske guess_encoding(csv_file) #&gt; # A tibble: 3 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 UTF-8 1 #&gt; 2 windows-1252 0.31 #&gt; 3 windows-1250 0.25 Note that write_csv always save the file using encoding UTF-8. In a few cases you may need to save a CSV file that can be read by Excel. For this purpose use: write_excel_csv2(dat, csv_file) The CSV file can now be opened correctly in Excel. 7.3 Excel There are different packages in R for reading and writing to Excel. We will use the readxl package for reading Excel files which is a part of tidyverse. The package supports both the legacy .xls format and the modern xml-based .xlsx format. Let us use one of the example files provided by the package: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;) It is always a good idea to have a look at the file before you import from it. You can open it from R by using browseURL(xlsx_file) Data can be read using library(readxl) xlsx &lt;- read_excel(xlsx_file) # reads the first sheet xlsx #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # … with 140 more rows xlsx &lt;- read_excel(xlsx_file, sheet = 2) # reads the second sheet xlsx #&gt; # A tibble: 32 x 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 #&gt; # … with 22 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;quakes&quot;) # reads a named sheet xlsx #&gt; # A tibble: 1,000 x 5 #&gt; lat long depth mag stations #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -20.4 182. 562 4.8 41 #&gt; 2 -20.6 181. 650 4.2 15 #&gt; 3 -26 184. 42 5.4 43 #&gt; 4 -18.0 182. 626 4.1 19 #&gt; 5 -20.4 182. 649 4 11 #&gt; 6 -19.7 184. 195 4 12 #&gt; 7 -11.7 166. 82 4.8 43 #&gt; 8 -28.1 182. 194 4.4 15 #&gt; 9 -28.7 182. 211 4.7 35 #&gt; 10 -17.5 180. 622 4.3 19 #&gt; # … with 990 more rows xlsx &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A5:G11&quot;, col_names = F) # reads a range colnames(xlsx) &lt;- read_excel(xlsx_file, sheet = &quot;mtcars&quot;, range = &quot;A1:G1&quot;, col_names = F) # reads the column names xlsx #&gt; # A tibble: 7 x 7 #&gt; mpg cyl disp hp drat wt qsec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21.4 6 258 110 3.08 3.22 19.4 #&gt; 2 18.7 8 360 175 3.15 3.44 17.0 #&gt; 3 18.1 6 225 105 2.76 3.46 20.2 #&gt; 4 14.3 8 360 245 3.21 3.57 15.8 #&gt; 5 24.4 4 147. 62 3.69 3.19 20 #&gt; 6 22.8 4 141. 95 3.92 3.15 22.9 #&gt; 7 19.2 6 168. 123 3.92 3.44 18.3 Writing to an Excel file can be done using the openxlsx package. To write to a new file use: library(openxlsx) dat &lt;- trees # test dataset head(dat) #&gt; Girth Height Volume #&gt; 1 8.3 70 10.3 #&gt; 2 8.6 65 10.3 #&gt; 3 8.8 63 10.2 #&gt; 4 10.5 72 16.4 #&gt; 5 10.7 81 18.8 #&gt; 6 10.8 83 19.7 write.xlsx(dat, &quot;test1.xlsx&quot;, sheetName = &quot;trees&quot;) # start at cell A1 write.xlsx(dat, &quot;test2.xlsx&quot;, sheetName = &quot;trees&quot;, startCol = &quot;C&quot;, startRow = 3) If you want to append a sheet to a file use: xlsx_file &lt;- system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;tfa&quot;) file.copy(xlsx_file, &quot;test.xlsx&quot;) # copy the file so can make some tests #&gt; [1] TRUE wb &lt;- loadWorkbook(file = &quot;test.xlsx&quot;) # read the workbook addWorksheet(wb = wb, sheetName = &quot;trees&quot;) writeData(wb, sheet = &quot;trees&quot;, x = dat) saveWorkbook(wb, file = &quot;test.xlsx&quot;, overwrite = TRUE) 7.4 Google Sheets You can import and export to Google sheets using the googlesheets4 package in tidyverse. To read and write data you in general need to be logged in as a Google user. The package will ask you when needed. However if you only want to read data from a public sheet you can use gs4_deauth to skip this: library(googlesheets4) gs4_deauth() To read data use: url &lt;- &quot;https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077&quot; read_sheet(url) #&gt; # A tibble: 624 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Algeria Africa 1952 43.1 9279525 2449. #&gt; 2 Algeria Africa 1957 45.7 10270856 3014. #&gt; 3 Algeria Africa 1962 48.3 11000948 2551. #&gt; 4 Algeria Africa 1967 51.4 12760499 3247. #&gt; 5 Algeria Africa 1972 54.5 14760787 4183. #&gt; 6 Algeria Africa 1977 58.0 17152804 4910. #&gt; 7 Algeria Africa 1982 61.4 20033753 5745. #&gt; 8 Algeria Africa 1987 65.8 23254956 5681. #&gt; 9 Algeria Africa 1992 67.7 26298373 5023. #&gt; 10 Algeria Africa 1997 69.2 29072015 4797. #&gt; # … with 614 more rows read_sheet(url, sheet = 3) #&gt; # A tibble: 396 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 386 more rows range_read(url, sheet = 2, n_max = 3) #&gt; # A tibble: 3 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Argentina Americas 1952 62.5 17876956 5911. #&gt; 2 Argentina Americas 1957 64.4 19610538 6857. #&gt; 3 Argentina Americas 1962 65.1 21283783 7133. range_read(url, range = &quot;Africa!A5:C15&quot;) #&gt; # A tibble: 10 x 3 #&gt; Algeria Africa `1967` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Algeria Africa 1972 #&gt; 2 Algeria Africa 1977 #&gt; 3 Algeria Africa 1982 #&gt; 4 Algeria Africa 1987 #&gt; 5 Algeria Africa 1992 #&gt; 6 Algeria Africa 1997 #&gt; 7 Algeria Africa 2002 #&gt; 8 Algeria Africa 2007 #&gt; 9 Angola Africa 1952 #&gt; 10 Angola Africa 1957 To write data to a new file use: gs4_auth() gs &lt;- gs4_create(&quot;test&quot;, sheets = c(&quot;Sheet 1&quot;, &quot;Sheet 2&quot;)) write_sheet(dat, ss = gs) range_write(gs, dat, sheet = &quot;Sheet 1&quot;, range = &quot;C4&quot;) gs4_browse(gs) # have a look at the file in a browser To see the results have a look at your Google sheet test in your browser. 7.5 Text files You can read and write to plain text files using the [readr][readr-web] package. However, mostly you want to write to a text file because you want to save some kind of log file when you run your script. Here sink is a excellent function to use. Since it redirects your R output. To see the output without messages, errors and warnings use: sink(file = &quot;ex1.log&quot;, split = TRUE) # open the file for output cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file again # file.show(&quot;ex1.log&quot;) # to view in external viewer Let us have a look at the content of the file (run cat(read_file(\"ex1.log\"))): This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 [1] 1 1 1 1 Last line Note that messages, errors and warnings are not included in the output. If you want to include it use: zz &lt;- file(&quot;ex2.log&quot;, open = &quot;wt&quot;) sink(zz, type = &quot;output&quot;) # open the file for output sink(zz, type = &quot;message&quot;) # open the same file for messages, errors and warnings cat(&quot;This is a string\\n... and on a new line\\n\\n&quot;) print(&quot;This is another string&quot;) head(mtcars) rep(1, 4) message(&quot;A message.&quot;) warning(&quot;A warning.&quot;) rep(3, f) # a error cat(&quot;\\nLast line\\n&quot;) sink() # close the file for output sink() # close the file for messages, errors and warnings That is, we call sink two times. Let us have a look at the content of the file: This is a string ... and on a new line [1] &quot;This is another string&quot; mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 [1] 1 1 1 1 A message. Advarselsbesked: A warning. Fejl: objekt &#39;f&#39; blev ikke fundet Last line 7.6 R’s native binary format In general, we can differ between two main types of data/files. Information is either binary encoded (basically just 0’s and 1’s) or stored as text files. What we have considered so far is storing data in text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allows space-efficient data compression. Furthermore, binary formats may be difficult to read and write using other programs. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimised for speed and compression ratios. To save and read an R object use: dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = mtcars) saveRDS(dat, file = &quot;test.rds&quot;) readRDS(&quot;test.rds&quot;) #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 red #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 blue #&gt; Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 green #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 blue #&gt; Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 red #&gt; Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 red #&gt; Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 blue #&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 green #&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 blue #&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 blue #&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 green #&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 red #&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 red #&gt; Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 &lt;NA&gt; #&gt; Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 &lt;NA&gt; #&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 red #&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 green #&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 red #&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 red #&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 &lt;NA&gt; #&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 green #&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 &lt;NA&gt; #&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 blue #&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 green #&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 green #&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 red #&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 green #&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 blue #&gt; Phantom XE 34.0 3 87.0 112 4.50 1.51 167.0 1 1 5 3 &lt;NA&gt; Note we here have saved a non tabular R object (a list). 7.7 Json JavaScript Object Notation (json) is an open standard text file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It can be used to store non tabular data in text format. It is often used for data-exchange in web-apis. Let us try to read and write to a json file using the jsonlite package. library(jsonlite) dat &lt;- list(x = c(2, 5, 6), y = &quot;A string&quot;, z = head(mtcars)) write_json(dat, &quot;test.json&quot;, pretty = T) lst &lt;- read_json(&quot;test.json&quot;, simplifyDataFrame = T, simplifyVector = T) lst #&gt; $x #&gt; [1] 2 5 6 #&gt; #&gt; $y #&gt; [1] &quot;A string&quot; #&gt; #&gt; $z #&gt; mpg cyl disp hp drat wt qsec vs am gear carb col #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 &lt;NA&gt; #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 green #&gt; Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 blue #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 red #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 &lt;NA&gt; #&gt; Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 blue The content of the json file look likes: { &quot;x&quot;: [2, 5, 6], &quot;y&quot;: [&quot;A string&quot;], &quot;z&quot;: [ { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.62, &quot;qsec&quot;: 16.46, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;_row&quot;: &quot;Mazda RX4&quot; }, { &quot;mpg&quot;: 21, &quot;cyl&quot;: 6, &quot;disp&quot;: 160, &quot;hp&quot;: 110, &quot;drat&quot;: 3.9, &quot;wt&quot;: 2.875, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 4, &quot;col&quot;: &quot;green&quot;, &quot;_row&quot;: &quot;Mazda RX4 Wag&quot; }, { &quot;mpg&quot;: 22.8, &quot;cyl&quot;: 4, &quot;disp&quot;: 108, &quot;hp&quot;: 93, &quot;drat&quot;: 3.85, &quot;wt&quot;: 2.32, &quot;qsec&quot;: 18.61, &quot;vs&quot;: 1, &quot;am&quot;: 1, &quot;gear&quot;: 4, &quot;carb&quot;: 1, &quot;col&quot;: &quot;blue&quot;, &quot;_row&quot;: &quot;Datsun 710&quot; }, { &quot;mpg&quot;: 21.4, &quot;cyl&quot;: 6, &quot;disp&quot;: 258, &quot;hp&quot;: 110, &quot;drat&quot;: 3.08, &quot;wt&quot;: 3.215, &quot;qsec&quot;: 19.44, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;col&quot;: &quot;red&quot;, &quot;_row&quot;: &quot;Hornet 4 Drive&quot; }, { &quot;mpg&quot;: 18.7, &quot;cyl&quot;: 8, &quot;disp&quot;: 360, &quot;hp&quot;: 175, &quot;drat&quot;: 3.15, &quot;wt&quot;: 3.44, &quot;qsec&quot;: 17.02, &quot;vs&quot;: 0, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 2, &quot;_row&quot;: &quot;Hornet Sportabout&quot; }, { &quot;mpg&quot;: 18.1, &quot;cyl&quot;: 6, &quot;disp&quot;: 225, &quot;hp&quot;: 105, &quot;drat&quot;: 2.76, &quot;wt&quot;: 3.46, &quot;qsec&quot;: 20.22, &quot;vs&quot;: 1, &quot;am&quot;: 0, &quot;gear&quot;: 3, &quot;carb&quot;: 1, &quot;col&quot;: &quot;blue&quot;, &quot;_row&quot;: &quot;Valiant&quot; } ] } 7.8 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Chapter 5 in Irizarry (2020) gives an alternative introduction to importing data. 7.9 Recap For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. CSV files contain delimiter separated values in plain text and are often named using the file suffix .csv. Each line of a csv file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. ,, ; or _). The readxl package can be used to read Excel files. Writing to an Excel file can be done using the openxlsx package. You can import and export to Google sheets using the googlesheets4 package in tidyverse. Use sink to save output of you R script. There are two main types of data files. Information is either binary encoded or stored as text files. Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allows space-efficient data compression. Moreover they can be used to save non tabular data. As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimized for speed and compression ratios. Json is an open standard text file format, and data interchange format. It can be used to store non tabular data in text format. It is often used for data-exchange in web-api’s. 7.10 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! 7.10.1 Exercise (Statistikbanken) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). You can use the API from Statistikbanken to download a lot of data sets. Let us consider airports in Denmark (data set with table id FLYV41): url &lt;- &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&quot; Use cat(read_lines(url, n_max = 3), sep = \"\\n\") to have a look at the delimiter used. &times; Solution url &lt;- &#39;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&amp;Transport=*&#39; dat &lt;- read_csv2(url) dat Close Solution Import the csv file. Try to retrieve information and get an overview over the data by running: library(jsonlite) url &lt;- &quot;https://api.statbank.dk/v1/tableinfo/FLYV41?lang=en&quot; lst &lt;- read_json(url, simplifyVector = T) View(lst) Note the data returned is in json format, so we use read_json to read the data into a list. &times; Solution info &lt;- function(tab_id) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) return(list(description = lst$description, unit = lst$unit, variables = lst$variables)) } info(&quot;FLYV41&quot;) Close Solution Create a function info(tab_id) that returns a list with components description, unit and variables from the information for a data set with table id tab_id. Hint you can modify the code in Question 3 to return only parts of the list. Information about all the data sets can be retrieved using: url &lt;- &quot;https://api.statbank.dk/v1/tables?lang=en&quot; lst &lt;- jsonlite::read_json(url, simplifyVector = T) View(lst) Have a look at the row for FlYV41. &times; Solution get_data &lt;- function(tab_id, col_id = NULL) { url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) cols &lt;- lst$variables$id if (!is.null(col_id)) cols &lt;- cols[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, lst$id[i], &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() dat &lt;- read_csv2(url) return(dat) } get_data(&quot;FLYV41&quot;, 3) get_data(&quot;FLYV41&quot;, 1:2) get_data(&quot;FLYV41&quot;) Close Solution Given the information about variables in a data set we can construct the url to retrieve the data in csv format: tab_id &lt;- &quot;FLYV41&quot; url &lt;- str_c(&quot;https://api.statbank.dk/v1/tableinfo/&quot;, tab_id, &quot;?lang=en&quot;) lst &lt;- read_json(url, simplifyVector = T) col_id &lt;- c(1,3) # column ids in lst$variables$id cols &lt;- lst$variables$id[col_id] url &lt;- str_c(&quot;https://api.statbank.dk/v1/data/&quot;, tab_id, &quot;/CSV?lang=en&amp;&quot;, str_c(cols, collapse = &quot;=*&amp;&quot;), &quot;=*&quot;) %&gt;% URLencode() url #&gt; [1] &quot;https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&amp;LUFTHAVN=*&amp;Tid=*&quot; Create a function get_data(tab_id, col_id) that retrieve a data set. &times; Solution dat &lt;- get_data(&quot;FOLK1A&quot;, c(2, 3, 5)) dat write_csv(dat, &quot;test.csv&quot;) Close Solution Use the function get_data to retrieve data for tab_id = \"FOLK1A\" and col_id = c(2, 3, 5) and save it as a csv file with a comma as delimiter. &times; Solution library(openxlsx) write.xlsx(dat, &quot;test.xlsx&quot;, sheetName = &quot;FOLK1A&quot;) library(googlesheets4) gs &lt;- gs4_create(&quot;test&quot;) write_sheet(dat, ss = gs, sheet = &quot;FOLK1A&quot;) gs4_browse(gs) Close Solution Save the data in an Excel file and a Google sheet. References "],
["sec-transform.html", "Module 8 Transforming data 8.1 Learning outcomes 8.2 Working with data in the tidyverse 8.3 Different learning paths 8.4 Recap 8.5 Exercises", " Module 8 Transforming data In this module we consider transformation of data. In general raw data may be messy and need to be structured in a tidy way. Tidying your data means storing it in a structured form suitable for analysis. This is done using a tibble (data frame) where each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Given a raw data set the first step is to clean it and and transform it to a tidy format. Given tidy data, you next often need to transform it. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Together, tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. In this chapter you will learn how to work with tibbles using the dplyr package which is a part of the tidyverse. 8.1 Learning outcomes By the end of this module, you are expected to be able to: Describe what tidy and wangling is. Apply the most common string functions Apply tidy operations to data Transform data Clean data 8.2 Working with data in the tidyverse An excellent introduction on how to transform data using the tidyverse is given in the interactive DataCamp course Data Manipulation with dplyr. Please complete the course before continuing. 8.3 Different learning paths We are all different and you may like different learning styles compared to others. As a result you may prefer a different learning path than suggested. Here is a list of possible different learning paths that may be useful for you. Roger Peng provide a good video giving an Introduction to the dplyr R package. Chapter 12 in Peng (2018) provides a nice introduction to dplyr. An alternative interactive DataCamp course is Working with Data in the Tidyverse which may be good to take if you need more training. The ‘Data transformation with dplyr’ cheatsheet is very useful. Find the newest version in RStudio Help &gt; Cheatsheets. 8.4 Recap We considers transformation tidy data where data are stored using a tibble (data frame) where each column is a variable, and each row is an observation/case. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data. Transformation includes narrowing in on observations of interest (e.g. only observations from a specific year or warehouse), creating new variables based on existing variables (like the cost of using the machine that day given idle time). Tidying and transforming are called wrangling, because it can be a hard process to get your data in the right form. The package dplyr provide a consistent set of verbs that help you solve the most common data manipulation challenges: The filter function chooses rows (cases/observations) that meet a specific criteria. The select function chooses columns (variables) based on their names. The arrange function reorders the rows. The transmute function adds/modify columns (variables) and drops existing ones. The mutate function adds/modify columns (variables). The group_by function group variables for groupwise operations. The ungroup function remove the current grouping. The count function count rows based on a grouping. The summarise function reduces multiple values down to a single summary. The distinct function selects unique/distinct rows. The pull function can be use to extract columns as vectors (it is similar to $). Some nice to know functions to use inside e.g. summarise or mutate are The n() function count the number of rows in a group. The n_distinct count the number of unique rows in a group. The first function considers the first row in a group (remember to order it as needed). The slice_min and slice_max functions selects rows with highest or lowest values of a variable. The across function makes it easy to apply the same transformation to multiple columns. Use print(n = Inf) in a pipe to print all rows. Use the pipe operator %&gt;% to connect operations. Use functions glimpse, tail, head, View to have look at the data. The skim function in the skimr package provides an approach to summary statistics. Use as.character, as.numeric, etc. to convert data to a different type. Use nrow and ncol functions to get the number of rows and columns of the data. 8.5 Exercises Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck see the help page. Solutions to each exercise can be seen by pressing the button at each question. Beware you will not learn by giving up to early. Put some effort into finding a solution! 8.5.1 Exercise (gapminder) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The gapminder data set provides values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007 for 142 countries. The data can be loaded using the gapminder package: library(gapminder) gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows Let us try to examine the data set (use pipes %&gt;% as much as possible). &times; Solution gapminder %&gt;% glimpse() gapminder %&gt;% summary() gapminder %&gt;% tail() Close Solution Use glimpse, summary and tail to examine the data. Use count to count the number of &times; Solution gapminder %&gt;% count(country) %&gt;% nrow() Close Solution countries, continents, &times; Solution gapminder %&gt;% count(continent) %&gt;% nrow() Close Solution countries per continent. &times; Solution gapminder %&gt;% count(continent, country) %&gt;% count(continent) # or gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) Close Solution &times; Solution gapminder %&gt;% distinct(continent) %&gt;% pull(continent) %&gt;% as.character() Close Solution Retrieve a vector with all distinct continent values. Subset rows to find: all rows with life expectancy less that 29 years, &times; Solution gapminder %&gt;% filter(lifeExp &lt; 29) Close Solution all rows for Rwanda after year 1979, &times; Solution gapminder %&gt;% filter(country == &quot;Rwanda&quot;, year &gt; 1979) Close Solution all rows for Rwanda, Afghanistan or France. &times; Solution gapminder %&gt;% filter(country %in% c(&quot;Rwanda&quot;, &quot;Afghanistan&quot;, &quot;France&quot;)) Close Solution Select columns year and life expectancy, &times; Solution gapminder %&gt;% select(year, lifeExp) Close Solution country and GDP per capita. &times; Solution gapminder %&gt;% select(country, gdpPercap) Close Solution &times; Solution gapminder %&gt;% filter((gdpPercap &gt; 40000 &amp; continent == &quot;Europe&quot;) | (gdpPercap &lt; 400 &amp; continent == &quot;Africa&quot;)) %&gt;% # print(n=Inf) %&gt;% # if want to see the intermediate results select(continent, country, gdpPercap) # %&gt;% print(n=Inf) Close Solution Subset your data set to find all rows with GDP per capita greater than 40000 in Europe or with GDP per capita less than 500 in Africa. &times; Solution gapminder %&gt;% mutate(gdp = pop * gdpPercap) Close Solution Use mutate to calculate each country’s GDP (population times GDP per capita). In general GDP numbers are large and abstract. Let us try to calculate relative numbers. &times; Solution mean_dk &lt;- gapminder %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% pull(gdpPercap) %&gt;% mean() dat &lt;- gapminder %&gt;% mutate(gdpPercapRel = gdpPercap/mean_dk) dat %&gt;% filter(country == &quot;Denmark&quot;) %&gt;% select(country, year, gdpPercapRel) summary(dat$gdpPercapRel) The relative GDP per capita numbers are, in general, well below 1. We see that most of the countries covered by this dataset have substantially lower GDP per capita, relative to Denmark, across the entire time period. Close Solution Use mutate to calculate GDP per capita relative to mean GDP per capita in Denmark over the whole period (gdpPercap divided by the mean of Danish gdpPercap). Hint you first must calculate the mean of Danish gdpPercap and next use that to add a new column gdpPercapRel. Have a look at the calculated data for Denmark. Does the numbers seems reasonable? I perceive Denmark to be a “high GDP” country, so I predict that the distribution of gdpPercapRel is located below 1, possibly even well below. Check this intuition! Use arrange to order data by year then country, as opposed to current by country then year, &times; Solution gapminder %&gt;% arrange(year, country) Close Solution data from 2007, sorted on life expectancy, &times; Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(lifeExp) Close Solution data from 2007, sorted on life expectancy in descending order. Hint: use desc() inside arrange. &times; Solution gapminder %&gt;% filter(year == 2007) %&gt;% arrange(desc(lifeExp)) Close Solution Use select to rename year to yr and keep all other columns (the select helper everything may be used), &times; Solution gapminder %&gt;% select(yr = year, everything()) Close Solution remove pop &times; Solution gapminder %&gt;% select(-pop) Close Solution reorder columns in order year, pop, … (remaining). &times; Solution gapminder %&gt;% select(year, pop, everything()) Close Solution Use group_by and summarize to find the number of observations per continent &times; Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n()) Close Solution number of countries per continent (use n_distinct inside summarize to count the number of distinct observations), &times; Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(n = n(), n_countries = n_distinct(country)) Close Solution average life expectancy by continent, &times; Solution gapminder %&gt;% group_by(continent) %&gt;% summarize(avg_lifeExp = mean(lifeExp)) Close Solution minimum and maximum life expectancies seen by year in Asia &times; Solution gapminder %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% group_by(year) %&gt;% summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp)) Close Solution &times; Solution gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = lifeExp - first(lifeExp)) %&gt;% filter(year &lt; 1963) # just for nice printing Close Solution Sometimes you don’t want to collapse the \\(n\\) rows for each group into one row. That is, you don’t want to use summarize but mutate within your groups. Try to make a new variable that is the years of life expectancy gained (lost) relative to 1952, for each individual country. You code should look like this gapminder %&gt;% group_by(country) %&gt;% # group by country select(country, year, lifeExp) %&gt;% # select relevant columns arrange(year, .by_group = TRUE) %&gt;% # make sure that data is sorted correct mutate(lifeExp_gain = ___) %&gt;% # define new variable filter(year &lt; 1963) # just for nice printing The first function may be helpful to extract the first value from a vector in each group. &times; Solution gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% group_by(continent, country) %&gt;% mutate(le_delta = lifeExp - lag(lifeExp)) %&gt;% summarize(worst_le_delta = min(le_delta, na.rm = TRUE)) %&gt;% slice_min(worst_le_delta) %&gt;% arrange(worst_le_delta) Mostly you are seeing what genocide looks like in dry statistics on average life expectancy. Close Solution Which country experienced the sharpest 5-year drop in life expectancy in each continent? Recall that the Gapminder data only has data every five years, e.g. for 1952, 1957, etc. So this really means looking at life expectancy changes between adjacent timepoints. Here the lag function is useful to select the value in the previous row. Your code should look like: gapminder %&gt;% select(country, year, continent, lifeExp) %&gt;% # select relevant columns group_by(continent, country) %&gt;% # group mutate(le_delta = ___) %&gt;% # within country, take (lifeExp in year i) - (lifeExp in year i - 1) summarize(worst_le_delta = min(___, na.rm = TRUE)) %&gt;% # find lowest value slice_min(worst_le_delta) %&gt;% # find min in each continent arrange(worst_le_delta) # arrange Positive values of le_delta means lifeExp went up, negative means it went down. Break the code into pieces, starting at the top, and inspect the intermediate results. These commands are built up gradually, with lots of errors and refinements along the way. 8.5.2 Exercise (babynames) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). The package babynames contains the dataset babynames provided by the USA social security administration. For each year from 1880 to 2017, the number of children of each sex given each name. All names with more than 5 uses are given (source: http://www.ssa.gov/oact/babynames/limits.html). Install it using install.packages(&quot;babynames&quot;) We will use the skimr package to get an overview over babynames: library(babynames) library(skimr) skim(babynames) Table 8.1: Data summary Name babynames Number of rows 1924665 Number of columns 5 _______________________ Column type frequency: character 2 numeric 3 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace sex 0 1 1 1 0 2 0 name 0 1 2 15 0 97310 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist year 0 1 1975 34 1880 1951 1985 2003 2017.00 ▁▂▃▅▇ n 0 1 181 1533 5 7 12 32 99686.00 ▇▁▁▁▁ prop 0 1 0 0 0 0 0 0 0.08 ▇▁▁▁▁ &times; Solution The last line only selects the n column. Close Solution Which of these is NOT a way to select the name and n columns together? select(babynames, -c(year, sex, prop)) select(babynames, name:n) select(babynames, starts_with(&quot;n&quot;)) select(babynames, ends_with(&quot;n&quot;)) Use filter and the logical operators to find: &times; Solution babynames %&gt;% filter(prop &gt;= 0.08) Close Solution All of the names where prop is greater than or equal to 0.08 &times; Solution babynames %&gt;% filter(name == &quot;Sea&quot;) Close Solution All of the children named “Sea” Use Boolean operators to return only the rows that contain: Boys named Sue, &times; Solution babynames %&gt;% filter(name == &quot;Sue&quot;, sex == &quot;M&quot;) Close Solution Names that were used by exactly 5 or 6 children in 1880, &times; Solution babynames %&gt;% filter(year == 1880, n == 5 | n == 6) Close Solution Names that are one of Acura, Lexus, or Yugo. &times; Solution babynames %&gt;% filter(name %in% c(&quot;Acura&quot;, &quot;Lexus&quot;, &quot;Yugo&quot;)) Close Solution &times; Solution min(babynames$n) max(babynames$n) Close Solution What is the smallest value of n? What is the largest? &times; Solution babynames %&gt;% filter(sex == &quot;F&quot;, year == 2017) %&gt;% select(name, n) %&gt;% arrange(desc(n)) Close Solution Write a sequence of functions that filters babynames to just the girls that were born in 2017, then selects the name and n columns, then, arranges the results so that the most popular names are near the top. &times; Solution babynames %&gt;% filter(sex == &quot;M&quot;, name == &quot;Lars&quot;) Close Solution Trim babynames to just the rows that contain your name and your sex. &times; Solution babynames %&gt;% filter(name == &quot;Khaleesi&quot;) %&gt;% summarise(total = sum(n), first = min(year)) Close Solution &times; Hint babynames ___ filter(____) ___ ____(total = ___, first = ___) Close Hint Extract the rows where name == \"Khaleesi\". Then use summarise() to find the total number of children named Khaleesi and the first year Khaleesi appeared in the data. &times; Solution babynames %&gt;% group_by(name, sex) %&gt;% summarize(total = sum(n)) %&gt;% arrange(desc(total)) Close Solution &times; Hint babynames %&gt;% _______(name, sex) %&gt;% _______(total = _____(n)) %&gt;% _______(desc(_____)) Close Hint Use group_by(), summarise(), and arrange() to display the ten most popular names. Compute popularity as the total number of children of a single gender given a name. &times; Solution babynames %&gt;% group_by(year) %&gt;% summarise(total = sum(n)) Close Solution Use group_by() to calculate the total number of children born each year over time. &times; Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% arrange(year, sex, desc(prop)) The same results if you use n since in the same order. Close Solution &times; Hint babynames %&gt;% group_by(___, ___) %&gt;% ___(rank = ___(desc(___))) %&gt;% arrange(year, sex, desc(prop)) Close Hint Column prop denote the proportion given year and sex. Use mutate() and min_rank() to rank each row in babynames from largest prop to lowest prop given year and sex. What happens if you do the same using the n column? &times; Solution babynames %&gt;% group_by(year, sex) %&gt;% mutate(rank = min_rank(desc(n))) %&gt;% filter(rank == 1, year &gt; 2009) Close Solution Filter the results to find all names with rank == 1 after 2009. 8.5.3 Exercise (profit) Use the exercise R markdown template to solve this exercise (File &gt; New File &gt; R Markdown…, select From template and then TFA Exercise). Consider the dataset profit containing quarterly financial records for each costumer, product, etc.: library(skimr) path &lt;- system.file(&quot;extdata/profit_raw.csv&quot;, package = &quot;tfa&quot;) profit &lt;- read_csv(path) skim(profit) Table 8.2: Data summary Name profit Number of rows 24546 Number of columns 9 _______________________ Column type frequency: character 9 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace Quarter 0 1 1 2 0 12 0 Channel 0 1 3 3 0 10 0 Customer ID 0 1 3 3 0 18 0 Country 0 1 3 14 0 47 0 Product Line 0 1 14 25 0 6 0 Revenue 63 1 1 7 0 1210 0 Product Cost 61 1 3 6 0 1139 0 Customer Service Cost 10 1 1 6 0 464 0 Profit 0 1 3 7 0 966 0 Note that it seems that the dataset need to be cleaned. All columns are strings (some should be numbers) and there seems to be missing values. You may start by having a view of the dataset using View(profit) First focus on column Quarter which currently has 12 distinct values profit %&gt;% distinct(Quarter) #&gt; # A tibble: 12 x 1 #&gt; Quarter #&gt; &lt;chr&gt; #&gt; 1 Q3 #&gt; 2 1 #&gt; 3 Q4 #&gt; 4 Q1 #&gt; 5 Q2 #&gt; 6 2 #&gt; 7 4 #&gt; 8 q1 #&gt; 9 q4 #&gt; 10 q3 #&gt; 11 q2 #&gt; 12 3 You would like it to be a numeric with values 1-4. &times; Solution profit &lt;- profit %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) Close Solution &times; Hint profit &lt;- profit %&gt;% mutate(Quarter = str_remove(___, &quot;q&quot;) %&gt;% str_remove(___) %&gt;% as.numeric()) profit %&gt;% distinct(Quarter) Close Hint Use mutate, str_remove and as.numeric to convert the column to a numeric by removing all ‘q’ and ‘Q’ values. Let us look at the next columns profit %&gt;% distinct(Channel) %&gt;% pull() #&gt; [1] &quot;ATM&quot; &quot;BRH&quot; &quot;INT&quot; &quot;MAL&quot; &quot;EML&quot; &quot;CCT&quot; &quot;TEL&quot; &quot;MOP&quot; &quot;DSA&quot; &quot;EVE&quot; profit %&gt;% distinct(`Customer ID`) %&gt;% pull() #&gt; [1] &quot;FRT&quot; &quot;MRT&quot; &quot;PBI&quot; &quot;MAM&quot; &quot;EBP&quot; &quot;RPB&quot; &quot;WEB&quot; &quot;WEM&quot; &quot;HEC&quot; &quot;STF&quot; &quot;IAS&quot; &quot;CRE&quot; &quot;INB&quot; &quot;CAM&quot; &quot;AGR&quot; &quot;SBE&quot; #&gt; [17] &quot;AFF&quot; &quot;MFN&quot; profit %&gt;% distinct(Country) %&gt;% pull() #&gt; [1] &quot;USA&quot; &quot;Canada&quot; &quot;Great Britain&quot; &quot;Finland&quot; &quot;New Zealand&quot; #&gt; [6] &quot;Brazil&quot; &quot;Mexico&quot; &quot;Germany&quot; &quot;Puerto Rico&quot; &quot;Hong Kong&quot; #&gt; [11] &quot;Japan&quot; &quot;Columbia&quot; &quot;Switzerland&quot; &quot;Uruguay&quot; &quot;Netherlands&quot; #&gt; [16] &quot;Korea&quot; &quot;Venezuela&quot; &quot;Panama&quot; &quot;Sweden&quot; &quot;China&quot; #&gt; [21] &quot;Guatemala&quot; &quot;South Africa&quot; &quot;Malaysia&quot; &quot;Nigeria&quot; &quot;Denmark&quot; #&gt; [26] &quot;France&quot; &quot;India&quot; &quot;Taiwan&quot; &quot;Norway&quot; &quot;Chile&quot; #&gt; [31] &quot;Indonesia&quot; &quot;Ireland&quot; &quot;Thailand&quot; &quot;Peru&quot; &quot;Spain&quot; #&gt; [36] &quot;Belgium&quot; &quot;Poland&quot; &quot;Ecuador&quot; &quot;Costa Rica&quot; &quot;Australia&quot; #&gt; [41] &quot;Israel&quot; &quot;Guam&quot; &quot;Oman&quot; &quot;Singapore&quot; &quot;Argentina&quot; #&gt; [46] &quot;Czechoslovakia&quot; &quot;Philippines&quot; profit %&gt;% distinct(`Product Line`) %&gt;% pull() #&gt; [1] &quot;Credit Products&quot; &quot;Deposit Products&quot; &quot;Revolving Credit Products&quot; #&gt; [4] &quot;Other Products&quot; &quot;Third Party Products&quot; &quot;Fee Based Products&quot; These seems to be okay. The last columns should be numbers. Let us consider Revenue. profit %&gt;% distinct(Revenue) %&gt;% pull() %&gt;% head(n = 100) #&gt; [1] &quot;$ 6044&quot; &quot;$ 4686&quot; &quot;$ 6063&quot; &quot;$ 4682&quot; &quot;$ 6320&quot; &quot;$ 2993&quot; &quot;$ 3355&quot; &quot;$ 5716&quot; &quot;$ 3347&quot; #&gt; [10] &quot;$ 2624&quot; &quot;$ 3629&quot; &quot;$ 5612&quot; &quot;$ 4618&quot; &quot;$ 2080&quot; &quot;$ 2788&quot; &quot;$ 2829&quot; &quot;$ 2898&quot; &quot;$ 5232&quot; #&gt; [19] &quot;$ 2949&quot; &quot;$ 5565&quot; &quot;$ 2153&quot; &quot;$ 3097&quot; &quot;$ 1920&quot; &quot;$ 4041&quot; &quot;$ 5931&quot; &quot;$ 1605&quot; &quot;$ 2026&quot; #&gt; [28] &quot;$ 1687&quot; &quot;$ 5075&quot; &quot;$ 4223&quot; &quot;$ 2456&quot; &quot;$ 1924&quot; &quot;$ 1578&quot; &quot;$ 3235&quot; &quot;$ 5123&quot; &quot;$ 1560&quot; #&gt; [37] &quot;$ 1945&quot; &quot;$ 6060&quot; &quot;$ 1222&quot; &quot;$ 1660&quot; &quot;$ 3000&quot; &quot;$ 2970&quot; &quot;$ 1631&quot; &quot;$ 1215&quot; &quot;$ 1759&quot; #&gt; [46] &quot;$ 3285&quot; &quot;$ 2048&quot; &quot;$ 2173&quot; &quot;$ 3353&quot; &quot;$ 1162&quot; &quot;$ 1232&quot; &quot;$ 1561&quot; &quot;$ 1123&quot; &quot;$ 1794&quot; #&gt; [55] &quot;$ 1202&quot; &quot;$ 1510&quot; &quot;$ 4472&quot; &quot;$ 2370&quot; &quot;$ 2581&quot; &quot;$ 2761&quot; &quot;$ 6371&quot; &quot;$ 1972&quot; &quot;$ 1562&quot; #&gt; [64] &quot;$ 2742&quot; &quot;$ 4598&quot; &quot;$ 5322&quot; &quot;$ 3411&quot; NA &quot;$ 1569&quot; &quot;$ 2852&quot; &quot;$ 1622&quot; &quot;$ 2505&quot; #&gt; [73] &quot;$ 1596&quot; &quot;$ 1447&quot; &quot;$ 1690&quot; &quot;$ 2448&quot; &quot;$ 1593&quot; &quot;$ 1876&quot; &quot;$ 6591&quot; &quot;$ 1611&quot; &quot;$ 1254&quot; #&gt; [82] &quot;Unknown&quot; &quot;$ 842&quot; &quot;$ 1529&quot; &quot;$ 1439&quot; &quot;$ 762&quot; &quot;$ 1959&quot; &quot;$ 4382&quot; &quot;$ 1407&quot; &quot;$ 909&quot; #&gt; [91] &quot;$ 1549&quot; &quot;$ 2161&quot; &quot;$ 1331&quot; &quot;$ 727&quot; &quot;$ 1462&quot; &quot;$ 1067&quot; &quot;$ 833&quot; &quot;$ 1675&quot; &quot;$ 1524&quot; #&gt; [100] &quot;$ 1285&quot; Most values start with a dollar sign. Let us have a look at the other ones: profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 95 x 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 INT MAM USA Deposit Produ… Unknown $ 1008 $ 246 #&gt; 2 3 MAL RPB USA Credit Produc… ? $ 1420 $ 347 #&gt; 3 1 MAL WEM Great … Other Products ? $ 87 $ 19 #&gt; 4 3 ATM MFN Germany Fee Based Pro… unknown $ 47 $ 6 #&gt; 5 3 ATM PBI Costa … Third Party P… Unknown $ 51 $ 9 #&gt; 6 1 ATM PBI Chile Deposit Produ… Unknown $ 58 $ 7 #&gt; 7 4 CCT MRT Great … Revolving Cre… ? $ 27 $ 5 #&gt; 8 4 ATM MAM Taiwan Third Party P… unknown $ 55 $ 9 #&gt; 9 4 MAL WEB Japan Other Products unknown $ 40 $ 7 #&gt; 10 2 CCT MAM Nether… Credit Produc… unknown $ 14 $ 3 #&gt; # … with 85 more rows, and 1 more variable: Profit &lt;chr&gt; na_values &lt;- profit %&gt;% filter(!str_starts(Revenue, fixed(&quot;$&quot;))) %&gt;% distinct(Revenue) %&gt;% pull(Revenue) na_values #&gt; [1] &quot;Unknown&quot; &quot;?&quot; &quot;unknown&quot; The expression is a bit complex. Let us break it up. Function fixed just return the fixed string ‘$’. This is necessary since the dollar sign have a special meaning in regular expressions (beyond the scope here). Function str_starts check if the string starts with a dollar sign. We use the logical negation (NOT) to find the complementary set. Note that different strings have been used to indicate NA values (Unknown, ?, unknown). Let us first use a single value to indicate NA (a question mark): profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) Next, we replace all ? with NA: profit &lt;- profit %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) profit %&gt;% # check filter(!str_starts(Revenue, fixed(&quot;$&quot;))) #&gt; # A tibble: 0 x 9 #&gt; # … with 9 variables: Quarter &lt;dbl&gt;, Channel &lt;chr&gt;, `Customer ID` &lt;chr&gt;, Country &lt;chr&gt;, `Product #&gt; # Line` &lt;chr&gt;, Revenue &lt;chr&gt;, `Product Cost` &lt;chr&gt;, `Customer Service Cost` &lt;chr&gt;, Profit &lt;chr&gt; Finally, we remove all dollar signs: profit &lt;- profit %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) profit #&gt; # A tibble: 24,546 x 9 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 ATM FRT USA Credit Produc… 6044 $ 3998 $ 413 #&gt; 2 1 ATM MRT USA Credit Produc… 4686 $ 3229 $ 643 #&gt; 3 4 ATM PBI USA Deposit Produ… 6063 $ 7440 $ 1842 #&gt; 4 1 ATM PBI USA Deposit Produ… 4682 $ 6127 $ 1118 #&gt; 5 4 ATM MRT USA Deposit Produ… 6320 $ 7913 $ 1854 #&gt; 6 3 BRH MAM USA Deposit Produ… 2993 $ 1034 $ 242 #&gt; 7 4 BRH PBI USA Revolving Cre… 3355 $ 4355 $ 1027 #&gt; 8 3 ATM FRT USA Revolving Cre… 5716 $ 5617 $ 876 #&gt; 9 4 BRH PBI USA Deposit Produ… 3347 $ 4229 $ 425 #&gt; 10 1 BRH PBI USA Credit Produc… 2624 $ 1960 $ 264 #&gt; # … with 24,536 more rows, and 1 more variable: Profit &lt;chr&gt; As one pipe: profit &lt;- profit %&gt;% mutate(Revenue = str_replace_all(Revenue, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;))) %&gt;% mutate(Revenue = na_if(Revenue, &quot;?&quot;)) %&gt;% mutate(Revenue = str_remove(Revenue, fixed(&quot;$ &quot;)) %&gt;% as.numeric()) Convert the remaining columns to numeric like shown for Revenue above. &times; Solution profit &lt;- read_csv(path) profit &lt;- profit %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) profit Close Solution Use the across function to apply the operations in Question 2 for a set of columns. Hint: see the examples on the help page of across. The code should look like: r profit &lt;- read_csv(path) %&gt;% mutate(across(___:___, ~str_replace_all(.x, c(\"unknown\" = \"?\", \"Unknown\" = \"?\")) )) %&gt;% mutate(across(___:___, ~na_if(.x, \"?\") )) %&gt;% mutate(across(___:___, ~str_remove(.x, fixed(\"$ \")) %&gt;% as.numeric() )) profit &times; Solution profit &lt;- read_csv(path) %&gt;% mutate(Quarter = str_remove(Quarter, &quot;q&quot;) %&gt;% str_remove(&quot;Q&quot;) %&gt;% as.numeric()) %&gt;% mutate(across(Revenue:Profit, ~str_replace_all(.x, c(&quot;unknown&quot; = &quot;?&quot;, &quot;Unknown&quot; = &quot;?&quot;)) )) %&gt;% mutate(across(Revenue:Profit, ~na_if(.x, &quot;?&quot;) )) %&gt;% mutate(across(Revenue:Profit, ~str_remove(.x, fixed(&quot;$ &quot;)) %&gt;% as.numeric() )) skim(profit) Close Solution Write one pipe that do all the cleaning &times; Solution profit &lt;- profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% mutate(Profit = if_else(Diff &gt; 0 &amp; Diff &lt;= 1, Profit_calc, Profit, missing = Profit) ) profit %&gt;% filter(Diff == 1, is.na(Profit_calc)) # check Close Solution Validate that revenue - product costs - customer service cost equals profit. If you see small rounding errors (less than or equal 1) then recalculate the profit. &times; Solution profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% mutate(Revenue = if_else(is.na(Revenue) &amp; c_na == 1, Profit + `Product Cost` + `Customer Service Cost`, Revenue, Revenue), `Product Cost` = if_else(is.na(`Product Cost`) &amp; c_na == 1, - Profit + Revenue - `Customer Service Cost`, `Product Cost`), `Customer Service Cost` = if_else(is.na(`Customer Service Cost`) &amp; c_na == 1, - Profit + Revenue - `Product Cost`, `Customer Service Cost`)) %&gt;% select(Quarter:Profit) # check - do numbers match profit %&gt;% mutate(Profit_calc = Revenue - `Product Cost` - `Customer Service Cost`, Diff = abs(Profit - Profit_calc)) %&gt;% filter(Diff &gt; 0) # check - find NA values profit %&gt;% rowwise() %&gt;% mutate(c_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% filter(c_na &gt; 0) Close Solution Recalculate values in columns Revenue - Profit if possible. Hint: recall that profit = revenue - product costs - customer service cost; that is, if a single value of these are missing then the value can be calculated using the other ones. To find the number of missing values (NA) you can create a new column counting the number of missing values: profit &lt;- profit %&gt;% rowwise() %&gt;% mutate(ct_na = sum(is.na(c_across(Revenue:Profit)))) %&gt;% ungroup() profit %&gt;% filter(ct_na &gt;= 1) #&gt; # A tibble: 312 x 12 #&gt; Quarter Channel `Customer ID` Country `Product Line` Revenue `Product Cost` `Customer Servi… #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 MAL FRT USA Credit Produc… NA 1579 244 #&gt; 2 2 ATM EBP USA Revolving Cre… 3629 1705 NA #&gt; 3 3 INT MAM USA Deposit Produ… NA 1008 246 #&gt; 4 4 ATM CRE USA Deposit Produ… 833 357 NA #&gt; 5 3 MAL RPB USA Credit Produc… NA 1420 347 #&gt; 6 3 MAL WEB USA Other Products 252 NA 43 #&gt; 7 1 INT WEM USA Other Products 371 NA 106 #&gt; 8 1 BRH STF USA Revolving Cre… NA 368 70 #&gt; 9 2 EML INB USA Credit Produc… 408 441 NA #&gt; 10 4 ATM CAM USA Other Products NA 83 10 #&gt; # … with 302 more rows, and 4 more variables: Profit &lt;dbl&gt;, Profit_calc &lt;dbl&gt;, Diff &lt;dbl&gt;, #&gt; # ct_na &lt;int&gt; You can now recalculate values using a code like: profit &lt;- profit %&gt;% mutate(Revenue = if_else(is.na(Revenue) &amp; c_na == 1, Profit + `Product Cost` + `Customer Service Cost`, Revenue, Revenue), `Product Cost` = if_else(___, ___, ___), `Customer Service Cost` = if_else(___, ___, ___)) You can check you calculations using your code from Question 5. &times; Solution profit %&gt;% group_by(Quarter) %&gt;% slice_max(Profit, n = 2) Close Solution Find the two best rows with highest profit in each quarter. &times; Solution profit %&gt;% group_by(Quarter, `Customer ID`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit, n = 2) The results are not the same with group rows now. Close Solution Find the two best customers with highest profit in each quarter. Is the results the same as in Question 7? &times; Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(Profit = sum(Profit)) %&gt;% slice_max(Profit) # ... repeat # Using a function summarise_profit &lt;- function(data, group_var, summarise_var) { data %&gt;% group_by(across({{ group_var }})) %&gt;% summarise(across({{ summarise_var }}, sum)) %&gt;% slice_max(Profit) } summarise_profit(profit, `Product Line`, Profit) summarise_profit(profit, `Customer ID`, Profit) # ... repeat # Using purrr package to get a single tibble (if intested in the purrr package) val &lt;- names(profit)[1:5] max_profit &lt;- map_df( val, ~{ tmp &lt;- profit %&gt;% group_by(.data[[.x]]) %&gt;% summarise(Profit = sum(Profit), .groups = &quot;drop&quot;) %&gt;% slice_max(Profit) tibble(by = .x, best = as.character(tmp[[1,1]]), profit = tmp[[1,2]] ) } ) max_profit Close Solution Find the product line, customer, channel, country and quarter with the highest profit. &times; Solution profit %&gt;% group_by(`Customer ID`) %&gt;% distinct(Country) %&gt;% count(`Customer ID`) Close Solution Is there rows with the same customer in different countries? &times; Solution profit %&gt;% arrange(desc(Profit), desc(Revenue)) Close Solution Sort the data decreasing with respect to profit and next revenue. &times; Solution profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost` + `Customer Service Cost`)) %&gt;% # print() %&gt;% # if want a peek before slicing slice_max(cost) profit %&gt;% group_by(`Product Line`) %&gt;% summarise(cost = sum(`Product Cost`)) %&gt;% slice_min(cost) Close Solution Which product line has the highest and lowest total cost? &times; Solution profit %&gt;% mutate(cust_cost_new = `Customer Service Cost` * 1.05, profit_new = Revenue - cust_cost_new - `Product Cost`) %&gt;% group_by(`Product Line`) %&gt;% summarise(cust_cost = sum(`Customer Service Cost`), profit = sum(Profit), cust_cost_new = sum(cust_cost_new), profit_new = sum(profit_new), profit_decrease = profit_new - profit) Close Solution Assume that customer service cost increase with 5%. How will that affect the profit for each product line? References "],
["sec-plot.html", "Module 9 Plotting using ggplot 9.1 Learning outcomes", " Module 9 Plotting using ggplot 9.1 Learning outcomes By the end of this module, you are expected to: Know how to create basic plots using ggplot [MORE TO COME] "],
["sec-maps.html", "Module 10 Spartial data and maps 10.1 Learning outcomes", " Module 10 Spartial data and maps 10.1 Learning outcomes By the end of this module, you are expected to be able to: Calculate shortest paths between places using the Google and Bing API. Geocode an address using the Google and Bing API. Calculate crow-flight distances. Plot a map with markers. Add lines between markers. [MORE TO COME] "],
["sec-project.html", "Module 11 Mandatory R project 11.1 Learning outcomes", " Module 11 Mandatory R project 11.1 Learning outcomes By the end of this module, you are expected to have: Know how your group report is handed in. Know how to peergrade other groups report Collected the data needed for the report. Know the different elements the report must contain. [MORE TO COME] "],
["sec-r-excel.html", "Module 12 Using R in Excel and Excel in R", " Module 12 Using R in Excel and Excel in R [Possible topic on the to do list] https://bert-toolkit.com/ "],
["sec-opl.html", "Module 13 Run an OPL model from R", " Module 13 Run an OPL model from R [Possible topic on the to do list] "],
["sec-simulation.html", "Module 14 Simulation in R", " Module 14 Simulation in R [Possible topic on the to do list] .tNone { text-transform:none; } "],
["groups.html", "A Working in groups R project structure Using Git together with GitHub", " A Working in groups During the course you have been allocated into groups. You are expected to solve the R exercises and write the R project report in these groups. Before you start, it is a good idea to agree on a set of group rules. First, agree on a coding convention. Most people in the R community use snake case but camel case is also okay. Next, setup rules on when to meet and how you will organize the work. For instance, it is a good idea that all try to solve some of the exercises before you meet and you then discuss the answers, problems etc. Finally, it is a good idea to have a common place for your code. You have different options: Use a cloud storage services such as Dropbox, OneDrive or Google Drive. Use a version control system such as Git together with GitHub. GitHub is a code sharing and publishing service and may be seen as a social networking site for programmers. The benefit of a cloud storage service is that it is well known to you and easy to setup. Cons are that you cannot work on the same file simultaneously. The benefit of Git and GitHub is that it manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Here you can work on files simultaneously. Moreover, it can be used from within RStudio. Cons are that it is harder to setup and learn. For a detailed description see Why Git? Why GitHub?. I recommend that you use Git and GitHub. However, if you find the learning curve to high just use a cloud storage service. The Using Git together with GitHub section gives a tutorial on how to setup Git and GitHub. Skip it if you use a cloud storage service. R project structure I suggest to have one common R project with subfolders joint, [student1 name], [student2 name], …, [student5 name]. Student folders contain files only a single student work on (good when you do some exercises before class). Folder joint contains joint work. That could for instance be a joint answer of an exercise (based on the work you did in the student folders) and a sub-folder with the project report. Using Git together with GitHub Git is a version control system. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. GitHub provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of it as DropBox but much, much better. It allows other people to see your stuff, sync up with you, and perhaps even make changes. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. To configure your computer go though the following steps: Register a free GitHub account Sign-up at GitHub. Some thoughts about your username: Incorporate your actual name! People like to know who they’re dealing with. Also makes your username easier for people to guess or remember. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Be as unique as possible in as few characters as possible. In some settings GitHub auto-completes or suggests usernames. Make it timeless. Don’t highlight your current university, employer, or place of residence, e.g. JennyFromTheBlock. Avoid the use of upper vs. lower case to separate words. We highly recommend all lowercase. GitHub treats usernames in a case insensitive way, but using all lowercase is kinder to people doing downstream regular expression work with usernames, in various languages. A better strategy for word separation is to use a hyphen - or underscore _. Install Git Find installation instructions below for your operating system. Windows Install Git from the web. Windows prefers for Git to be installed below C:/Program Files and this appears to be the default. This implies, for example, that the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention. If asked about “Adjusting your PATH environment”, make sure to select “Git from the command line and also from 3rd-party software”. macOS Option 1 (highly recommended): Install the Xcode command line tools (not all of Xcode), which includes Git. Go to the shell and enter one of these commands to elicit an offer to install developer command line tools: git --version git config Accept the offer! Click on “Install”. Here’s another way to request this installation, more directly: xcode-select --install We just happen to find this Git-based trigger apropos. Note also that, after upgrading macOS, you might need to re-do the above and/or re-agree to the Xcode license agreement. We have seen this cause the RStudio Git pane to disappear on a system where it was previously working. Use commands like those above to tickle Xcode into prompting you for what it needs, then restart RStudio. Option 2 (recommended): Install Git from here: http://git-scm.com/downloads. This arguably sets you up the best for the future. It will certainly get you the latest version of Git of all approaches described here. The GitHub home for the macOS installer is here: https://github.com/timcharper/git_osx_installer. At that link, you can find more info if something goes wrong or you are working on an old version of macOS. Option 3 (recommended): If you anticipate getting heavily into scientific computing, you’re going to be installing and updating lots of software. You should check out Homebrew, “the missing package manager for OS X”. Among many other things, it can install Git for you. Once you have Homebrew installed, do this in the shell: brew install git Linux Install Git via your distro’s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux Check your installation Quit and re-launch RStudio if there’s any doubt in your mind about whether you opened RStudio before or after installing Git. You can set your Git user name and email from within R using the usethis package: ## install if needed (do this exactly once): ## install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) What user name should you give to Git? This does not have to be your GitHub user name, although it can be. Another good option is your actual first name and last name. If you commit from different machines, sometimes people work that info into the user name. Your commits will be labelled with this user name, so make it informative to potential collaborators and future you. What email should you give to Git? This must be the email associated with your GitHub account. These commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list from a shell. An easy way to get into a shell from RStudio is **Tools &gt; Terminal* or *Tools &gt; Shell**. If you have any problems go though Chapters 4-14 on the Happy Git site. Setup projects using Git and GitHub You have different options depending on how you start you project. I will only highlight the prefererd one. New project, GitHub first Here we create a project with “GitHub first, then RStudio” sequence: Step 1: Go to GitHub and make sure you are logged in. Click green “New repository” button. Or, if you are on your own profile page, click on “Repositories”, then click the green “New” button. Repository name: test (or whatever you wish) Public YES Initialize this repository with a README Click the big green button “Create repository.” Copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. Step 2: In RStudio, start a new Project: File &gt; New Project &gt; Version Control &gt; Git. In the “repository URL” paste the URL of your new GitHub repository. It will be something like this https://github.com/[you-username]/test.git. Be intentional about where you create this Project. Suggest you “Open in new session”. Click “Create Project” to create a new directory, which will be all of these things: a directory or “folder” on your computer a Git repository, linked to a remote GitHub repository an RStudio Project In the absence of other constraints, I suggest that all of your R projects have exactly this set-up. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio’s file browser pane for the README.md file. There’s a big advantage to the “GitHub first, then RStudio” workflow: the remote GitHub repo is added as a remote for your local repo and your local master branch is now tracking master on GitHub. This is a technical but important point about Git. The practical implication is that you are now set up to push and pull. No need to fanny around setting up Git remotes and tracking branches on the command line. Step 3: Make local changes, save, commit. Do this every time you finish a valuable chunk of work, probably many times a day. From RStudio, modify the README.md file, e.g., by adding the line “This is a line from RStudio”. Save your changes. Commit these changes to your local repo. How? Click the “Git” tab in upper right pane Check “Staged” box for any files whose existence or modifications you want to commit. To see more detail on what’s changed in file since the last commit, click on “Diff” for a Git pop-up If you’re not already in the Git pop-up, click “Commit” Type a message in “Commit message”, such as “Commit from RStudio”. Click “Commit” Step 4: Push your local changes to GitHub Do this a few times a day, but possibly less often than you commit. You have new work in your local Git repository, but the changes are not online yet. This will seem counterintuitive, but first let’s stop and pull from GitHub. Why? Establish this habit for the future! If you make changes to the repo in the browser or from another machine or (one day) a collaborator has pushed, you will be happier if you pull those changes in before you attempt to push. Click the blue “Pull” button in the “Git” tab in RStudio. I doubt anything will happen, i.e. you’ll get the message “Already up-to-date.” This is just to establish a habit. Click the green “Push” button to send your local changes to GitHub. You should see some message along these lines. [master dc671f0] blah 3 files changed, 22 insertions(+) create mode 100644 .gitignore create mode 100644 myrepo.Rproj Step 5: Confirm the local change propagated to the GitHub remote Go back to the browser. I assume we’re still viewing your new GitHub repo. Refresh. You should see the new “This is a line from RStudio” in the README. If you click on “commits,” you should see one with the message “Commit from RStudio”. Step 6: Make a change on GitHub Click on README.md in the file listing on GitHub. In the upper right corner, click on the pencil for “Edit this file”. Add a line to this file, such as “Line added from GitHub.” Edit the commit message in “Commit changes” or accept the default. Click the big green button “Commit changes.” Step 7: Pull from GitHub Back in RStudio locally … Inspect your README.md. It should NOT have the line “Line added from GitHub”. It should be as you left it. Verify that. Click the blue Pull button. Look at README.md again. You should now see the new line there. The end Now just repeat these operations when you do group work. Do work somewhere. Commit it. Push it or pull it depending on where you did it, but get local and remote “synced up”. Repeat. Note that in general (and especially in future when collaborating with other developers) you will usually need to pull changes from the remote (GitHub) before pushing the local changes you have made. For this reason, it’s a good idea to try and get into the habit of pulling before you attempt to push. If you have to type in your password over and over again, this can be avoided. Have a look at Chapter 10 of Happy Git. Existing project, GitHub first See details in Chapter 16 of Happy Git. Existing project, GitHub last See details in Chapter 17 of Happy Git. "],
["annotate.html", "B Annotate the course notes", " B Annotate the course notes I recommend using hypothes.is to annotate the online course notes. You can create both private and public annotations. Collaborative annotation helps people connect to each other and what they’re reading, even when they’re keeping their distance. You may also use public notes to help me indicate spell errors, unclear content etc. in the notes. "],
["help.html", "C Getting help Study café", " C Getting help We all get stuck sometimes and need some help. Below are some advises on how to help yourself and ask for help: First try to understand the error message and solve the problem. You may try to debug your code by inserting browser() in your code. See Chapter 11 in Bryan and H (n.d.) for further details. Google is your friend. This is always the first step. Try searches like “r dplyr filter”, “r tidyverse”, “r subset vector”, etc. Do you need help for a specific function in R then try ?[function-name] such as ?geom_line, ?mutate, etc. Mostly, focus on the last section with examples. Moreover, some packages may have written vignettes try browseVignettes(package = \"package_name\") to check. Have a look at Help &gt; Cheatsheets in RStudio. If you can’t find an answer then it is time to ask on-line. I recommend asking a question at stackoverflow. To make your question effective, the idea is to make things as easy as possible for someone to answer. This stack overflow thread How to make a great R reproducible example? give you some good hints. The process of providing a good minimal reproducible example (reprex) often causes you to answer your own question! See also Stack Exchange’s ‘How to ask’ and How to make a reprex at tidyverse. If you have a more course related question then ask it at our course forum and we will try to answer your question asap. Students are also welcome in helping each other. You can also try to annotate the online course notes if something is unclear. I will try to answer asap. You can get help from our TAs at study cafés for more information see the next section. Study café Need help - ask a question Do you need help during a study café time-slot then fill out the form below and a TA will join your Zoom meeting asap. The current queue can be seen in the next section. Current queue Below you can see the current help queue for study café time-slots (refresh you browser window may be a good idea). If it is empty the TAs have nothing to do … so ask some questions :-) References "],
["learning-goals.html", "D Learning goals", " D Learning goals The purpose of this course is to give students a knowledge about IT tools for Analytics which requires the analyst to be qualified in handling tools beyond e.g. basic Excel. After having participated in the course, the student must, in addition to achieving general academic skills, demonstrate: Knowledge of how a computer works at a basic level. basic programming such as variables, arrays, loops, functions and procedures. what an algorithm is. how to implement an algorithm based on a description. different programming languages. how to manage a code in a collaborative working environment. Skills to handle data such as import, tidy, transform, visualize and export. develop well-structured code. perform testing and debugging. implement/code selected algorithms. apply analytical techniques on data. apply relevant methods, algorithms and techniques from this course in order to solve a specific problem. Competences to independently handle data given a problem. independently analyse data given a relevant research question. compare different programming languages. compare different algorithms solving a problem and discuss their advantages and disadvantages. interpret and discuss results based on a data analysis in relation to the relevant academic literature. communicate results from applied research in a scientific way, e.g. using literate programming. "],
["sec-ba.html", "E Business Analytics", " E Business Analytics Business Analytics (BA) refers to the scientific process of transforming data into insight for making better decisions in business. BA can both be seen as the complete decision making process for solving a business problem or as a set of methodologies that enable the creation of business value. As a process it can be characterized by descriptive, predictive, and prescriptive model building using “big” data sources. Descriptive Analytics: A set of technologies and processes that use data to understand and analyze business performance. Descriptive analytics are the most commonly used and most well understood type of analytics. Descriptive analytics categorizes, characterizes, consolidates, and classifies data. Examples are standard reporting and dashboards (KPIs, what happened or is happening now?) and ad-hoc reporting (how many/often?). Descriptive analytics often serves as a first step in the successful application of predictive or prescriptive analytics. Predictive Analytics: The use of data and statistical techniques to make predictions about future outputs/outcomes, identify patterns or opportunities for business performance. Examples of techniques are data mining (what data is correlated with other data?), pattern recognition and alerts (when should I take action to correct/adjust a spare part?), Monte-Carlo simulation (what could happen?), neural networks (which customer group are best?) and forecasting (what if these trends continue?). Prescriptive Analytics: The use of optimization and other decision modelling techniques using the results of descriptive and predictive analytics to suggest decision options with the goal of improving business performance. Prescriptive analytics attempt to quantify the effect of future decisions in order to advise on possible outcomes before the decisions are actually made. Prescriptive analytics predicts not only what will happen, but also why it will happen and provides recommendations regarding actions that will take advantage of the predictions. Prescriptive analytics are relatively complex to administer, and most companies are not yet using it in their daily course of business. However, when implemented correctly, it can have a huge impact on business performance and how businesses make decisions. Examples on prescriptive analytics are optimization in production planning and scheduling, inventory management, the supply chain and transportation planning. Companies who use BA focus on fact-based management to drive decision making and treats data and information as a strategic asset that is shared within the company. This enterprise approach generates a companywide respect for applying descriptive, predictive and prescriptive analytics in areas such as supply chain, marketing and human resources. Related areas: In the past Business Intelligence traditionally focuses on querying, reporting, online analytical processing, i.e. descriptive analytics. However, a more modern definition of Business Intelligence is the union of descriptive and predictive analytics. Operations Research or Management Science deals with the application of advanced analytical methods to help make better decisions and can hence be seen as prescriptive analytics. However, traditionally it has been taking a more theoretical approach and focusing on problem-driven research while BA takes a more data-driven approach. Logistics is a cross-functional area focusing on the effective and efficient flows of goods and services, and the related flows of information and cash. Supply Chain Management adds a process-oriented and cross-company perspective. Both can be seen as prescriptive analytics with a more problem-driven research focus. Advanced Analytics is often used as a classification of both predictive and prescriptive analytics. Data science is an interdisciplinary field about scientific methods, processes, and systems to extract knowledge or insights from data in various forms, either structured or unstructured and can be seen as Business analytics applied to a wider range of data. Resources http://analytics-magazine.org/the-analytics-journey/ https://en.wikipedia.org/wiki/Business_analytics http://connect.informs.org/analytics/home https://www.or-exchange.org/questions/5645/informs-analytics-definition https://en.wikipedia.org/wiki/Prescriptive_analytics https://en.wikipedia.org/wiki/Predictive_analytics "],
["colophon.html", "F Colophon", " F Colophon This book was written in bookdown inside RStudio. This version of the book was built with: #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.0.2 (2020-06-22) #&gt; os macOS Catalina 10.15.6 #&gt; system x86_64, darwin17.0 #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; ctype en_US.UTF-8 #&gt; tz UTC #&gt; date 2020-10-05 Along with these packages: Bryan, J. 2017. STAT 545 - Data Wrangling, Exploration, and Analysis with R. https://stat545.com/. Bryan, J., and J. H. n.d. What They Forgot to Teach You About R. https://rstats.wtf/. Bryan, J., the STAT 545 TAs, and J. Hester. 2020. Happy Git and Github for the useR. https://happygitwithr.com/. Irizarry, R. A. 2020. Introduction to Data Science - Data Analysis and Prediction Algorithms with R. https://rafalab.github.io/dsbook/. Ismay, C., and P. C. Kennedy. 2019. Getting Used to R, Rstudio, and R Markdown. https://rbasics.netlify.app. Ismay, C., and A. Y. Kim. 2020. Statistical Inference via Data Science. ModernDrive. https://moderndive.netlify.app/. Peng, R. D. 2018. R Programming for Data Science. https://bookdown.org/rdpeng/rprogdatascience/. Stauffer, R., T. Simon, and A. Zeileis. 2020. Introduction to Programming with R. https://eeecon.uibk.ac.at/~discdown/rprogramming. Wickham, H. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz/. Wickham, Hadley. 2015. R Packages: Organize, Test, Document, and Share Your Code. O’Reilly Media. http://r-pkgs.had.co.nz/. Wøhlk, S. 2010. VBA Programming in Business Economics. DJØF Publishing. "]
]
